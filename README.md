# GPT-SoVITS & LlamaCPP Projects

æ—¥æœ¬èªéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ (GPT-SoVITS)ã¨ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ (LlamaCPP)ã®Dockerçµ±åˆç’°å¢ƒ

## ğŸš€ Quick Start

### 1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
```bash
git clone https://github.com/gdysaugs/gpts.git
cd gpts
```

### 2. è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Ÿè¡Œ
```bash
chmod +x setup.sh
./setup.sh
```

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒä»¥ä¸‹ã‚’è‡ªå‹•å®Ÿè¡Œã—ã¾ã™ï¼š
- ç’°å¢ƒè‡ªå‹•æ¤œå‡ºï¼ˆWSL2 vs ãƒã‚¤ãƒ†ã‚£ãƒ–Linuxï¼‰
- å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
- GPT-SoVITSãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- LlamaCPPãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- Dockerç’°å¢ƒç¢ºèª
- å®Ÿè¡Œæ¨©é™è¨­å®š
- ç’°å¢ƒåˆ¥ã‚³ãƒãƒ³ãƒ‰ä¾‹ã®ç”Ÿæˆï¼ˆdocker_commands.txtï¼‰

### 3. Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰

#### GPT-SoVITS
```bash
cd Gptsovits
DOCKER_BUILDKIT=1 docker build -t gpt-sovits:v4 .
```

#### LlamaCPP
```bash
cd llamacpp
DOCKER_BUILDKIT=1 docker build -t llama-cpp-python:cuda .
```

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

```
gpts/
â”œâ”€â”€ setup.sh                    # ğŸ”§ ãƒ¡ã‚¤ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ CLAUDE_HOME.md               # ğŸ“ ãƒ›ãƒ¼ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ Gptsovits/                   # ğŸµ éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
â”‚   â”œâ”€â”€ CLAUDE.md               # GPT-SoVITSè¨­å®š
â”‚   â”œâ”€â”€ Dockerfile              # Dockerç’°å¢ƒ
â”‚   â”œâ”€â”€ docker-compose.yml      # Composeè¨­å®š
â”‚   â”œâ”€â”€ scripts/                # ã‚¹ã‚¯ãƒªãƒ—ãƒˆç¾¤
â”‚   â”‚   â”œâ”€â”€ download_models.sh  # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
â”‚   â”‚   â”œâ”€â”€ test_voice_clone.py # æ¨™æº–v2ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â””â”€â”€ test_voice_clone_ja_complete.py # æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ models/                 # ãƒ¢ãƒ‡ãƒ«é…ç½® (gitignoreæ¸ˆ)
â”‚   â”œâ”€â”€ input/                  # å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ output/                 # ç”ŸæˆéŸ³å£°
â”‚   â””â”€â”€ logs/                   # å®Ÿè¡Œãƒ­ã‚°
â””â”€â”€ llamacpp/                   # ğŸ¤– LLMãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
    â”œâ”€â”€ CLAUDE.md               # LlamaCPPè¨­å®š
    â”œâ”€â”€ Dockerfile              # Dockerç’°å¢ƒ
    â”œâ”€â”€ docker-compose.yml      # Composeè¨­å®š
    â”œâ”€â”€ src/                    # ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    â”‚   â”œâ”€â”€ api_server.py       # FastAPI RESTã‚µãƒ¼ãƒãƒ¼
    â”‚   â””â”€â”€ llm_engine.py       # LLMæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
    â”œâ”€â”€ scripts/                # CLIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    â”‚   â”œâ”€â”€ setup_model.sh      # ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    â”‚   â”œâ”€â”€ chat_cli.py         # ç›´æ¥CLIä¼šè©±
    â”‚   â”œâ”€â”€ api_chat_cli.py     # APIçµŒç”±CLIä¼šè©±
    â”‚   â””â”€â”€ test_api.py         # APIç·åˆãƒ†ã‚¹ãƒˆ
    â”œâ”€â”€ models/                 # LLMãƒ¢ãƒ‡ãƒ«é…ç½® (gitignoreæ¸ˆ)
    â”œâ”€â”€ config/                 # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    â””â”€â”€ logs/                   # å®Ÿè¡Œãƒ­ã‚°
```

## ğŸµ GPT-SoVITS éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°

### ç‰¹å¾´
- **æ—¥æœ¬èªç‰¹åŒ–**: æ„Ÿæƒ…è¡¨ç¾è±Šã‹ãªéŸ³å£°ç”Ÿæˆ
- **GPUåŠ é€Ÿ**: WSL2 + Dockerç’°å¢ƒã§RTX 3050æœ€é©åŒ–
- **2ã¤ã®ãƒ¢ãƒ‡ãƒ«**: æ¨™æº–v2ãƒ¢ãƒ‡ãƒ«ã¨æ—¥æœ¬èªå°‚ç”¨ãƒ¢ãƒ‡ãƒ«

### æ¨å¥¨ä½¿ç”¨æ–¹æ³•

#### â­ FastAPIã‚µãƒ¼ãƒãƒ¼ï¼ˆæ¨å¥¨ãƒ»æœ¬æ ¼åˆ©ç”¨ï¼‰
**ç‰¹å¾´**: åˆæœŸåŒ–1å›ã®ã¿ã€ä»¥é™3ç§’/å›ã®é«˜é€Ÿå¿œç­”
```bash
cd Gptsovits

# 1. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆåˆæœŸåŒ–20ç§’ã€1å›ã®ã¿ï¼‰
docker run --gpus all -d -p 8000:8000 --privileged --name gpt-sovits-api \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/scripts:/app/scripts \
  -v $(pwd)/models/v4/GPT-SoVITS/gpt-sovits-ja-h:/app/GPT_SoVITS/pretrained_models/gpt-sovits-ja-h \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 bash -c "pip install fastapi uvicorn python-multipart && python /app/scripts/fastapi_voice_server.py"

# 2. APIå‘¼ã³å‡ºã—ï¼ˆ3ç§’ã§å®Œäº†ï¼‰
curl -G "http://localhost:8000/clone-voice-simple" \
  --data-urlencode "ref_text=ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™" \
  --data-urlencode "target_text=FastAPIã§é«˜é€ŸéŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆã§ã™" > output/fastapi_result.wav

# 3. ã‚µãƒ¼ãƒãƒ¼åœæ­¢
docker stop gpt-sovits-api && docker rm gpt-sovits-api
```

#### CLIç‰ˆï¼ˆé–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰

##### æ¨™æº–v2ãƒ¢ãƒ‡ãƒ«
```bash
cd Gptsovits
docker run --gpus all --rm \
  --privileged \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 python /app/scripts/test_voice_clone.py \
  --ref-audio /app/input/reference_5sec.wav \
  --ref-text "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™" \
  --target-text "ã“ã‚“ã«ã¡ã¯ã€ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆéŸ³å£°ã§ã™" \
  --output /app/output/cloned_voice.wav
```

##### æ—¥æœ¬èªå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæ„Ÿæƒ…è¡¨ç¾ï¼‰
```bash
docker run --gpus all --rm \
  --privileged \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/models/v4/GPT-SoVITS/gpt-sovits-ja-h:/app/GPT_SoVITS/pretrained_models/gpt-sovits-ja-h \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 python /app/scripts/test_voice_clone_ja_complete.py \
  --ref-audio /app/input/reference_5sec.wav \
  --ref-text "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™" \
  --target-text "ã‚ã‚ã‚ã‚ï¼ã™ã”ã„ï¼æœ¬å½“ã«ç´ æ™´ã‚‰ã—ã„çµæœã§ã™ï¼" \
  --sovits-model "/app/GPT_SoVITS/pretrained_models/gpt-sovits-ja-h/hscene-e17.ckpt" \
  --output /app/output/emotional_result.wav
```

##### Warm-upæœ€é©åŒ–ç‰ˆï¼ˆé€£ç¶šå‡¦ç†ç”¨ï¼‰
```bash
docker run --gpus all --rm \
  --privileged \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/scripts:/app/scripts \
  -v $(pwd)/models/v4/GPT-SoVITS/gpt-sovits-ja-h:/app/GPT_SoVITS/pretrained_models/gpt-sovits-ja-h \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 python /app/scripts/test_voice_clone_warmup.py \
  --ref-audio /app/input/reference_5sec.wav \
  --ref-text "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™" \
  --target-text "Warm-upæœ€é©åŒ–ç‰ˆã®ãƒ†ã‚¹ãƒˆã§ã™" \
  --output /app/output/warmup_result.wav
```

## ğŸ¤– LlamaCPP ãƒ­ãƒ¼ã‚«ãƒ«LLM

### ç‰¹å¾´
- **é«˜é€Ÿæ¨è«–**: FP16æœ€é©åŒ–ã§1.03ç§’/å›ç­”
- **ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: ç›´æ¥CLIãƒ»FastAPI RESTã‚µãƒ¼ãƒãƒ¼
- **GPUæœ€é©åŒ–**: CUDA 12.1 + é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«(Q4_K_S)ã§4GB VRAMåŠ¹ç‡

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

#### ç›´æ¥CLIä¼šè©±ï¼ˆæœ€é«˜é€Ÿï¼‰
```bash
cd llamacpp
docker run --gpus all --rm -it \
  --privileged \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/config:/app/config \
  -v $(pwd)/logs:/app/logs \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  llama-cpp-python:cuda python /app/scripts/chat_cli.py
```

#### FastAPI RESTã‚µãƒ¼ãƒãƒ¼èµ·å‹•
```bash
docker run --gpus all --rm -it \
  --privileged \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/config:/app/config \
  -v $(pwd)/logs:/app/logs \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -p 8000:8000 \
  llama-cpp-python:cuda python /app/src/api_server.py
```

API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://localhost:8000/docs

#### APIçµŒç”±CLIä¼šè©±
```bash
docker run --gpus all --rm -it \
  --network host \
  llama-cpp-python:cuda python /app/scripts/api_chat_cli.py
```

## âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

### å¿…é ˆç’°å¢ƒ
- **OS**: Linux (Ubuntu 22.04æ¨å¥¨ã€WSL2å¯¾å¿œ)
- **GPU**: NVIDIA GPU + CUDA 12.1ä»¥ä¸Šå¯¾å¿œ
- **VRAM**: 4GBä»¥ä¸Šï¼ˆ8GBæ¨å¥¨ï¼‰
- **RAM**: 16GBä»¥ä¸Šæ¨å¥¨
- **Storage**: 50GBä»¥ä¸Šã®ç©ºãå®¹é‡

### å¿…è¦ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 1. Dockerç’°å¢ƒ
- **Dockerï¼ˆWSL2å†…ã€Docker Desktopã§ã¯ãªã„ï¼‰**
- **NVIDIA Container Toolkit**ï¼ˆGPUã‚¢ã‚¯ã‚»ã‚¹å¿…é ˆï¼‰
- **Git LFS**ï¼ˆGPT-SoVITSãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰

#### 2. NVIDIA Container Toolkit ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †
```bash
# 1. GPGã‚­ãƒ¼ã¨ãƒªãƒã‚¸ãƒˆãƒªè¿½åŠ 
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# 2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
sudo apt update
sudo apt install -y nvidia-container-toolkit

# 3. Dockerå†èµ·å‹•
sudo systemctl restart docker

# 4. å‹•ä½œç¢ºèª
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 nvidia-smi
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ğŸš¨ ä»Šå›ã®è©°ã¾ã£ãŸãƒã‚¤ãƒ³ãƒˆã¨è§£æ±ºç­–

#### âŒ NVIDIA Container Toolkitæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
**ç—‡çŠ¶**: `docker: Error response from daemon: could not select device driver with capabilities: [[gpu]]`
```bash
# è§£æ±ºç­–: ä¸Šè¨˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ã‚’å®Ÿè¡Œ
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
# ä»¥ä¸‹ã€ä¸Šè¨˜æ‰‹é †é€šã‚Šå®Ÿè¡Œ
```

#### âŒ ä¸æ­£ãªCUDAã‚¤ãƒ¡ãƒ¼ã‚¸å
**ç—‡çŠ¶**: `manifest for nvidia/cuda:12.1-runtime-ubuntu20.04 not found`
```bash
# âŒ å¤±æ•—ä¾‹
docker run --gpus all --rm nvidia/cuda:12.1-runtime-ubuntu20.04 nvidia-smi

# âœ… æ­£è§£: ãƒ“ãƒ«ãƒ‰æ¸ˆã¿ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ç¢ºèª
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 nvidia-smi
```

#### âŒ WSL2 GPU ã‚¢ã‚¯ã‚»ã‚¹è¨­å®šä¸å‚™
**ç—‡çŠ¶**: `RuntimeError: Unexpected error from cudaGetDeviceCount()`
```bash
# å¿…é ˆãƒ•ãƒ©ã‚°ï¼ˆå…¨ã¦å¿…è¦ï¼‰
--privileged                          # WSL2æ¨©é™
-v /usr/lib/wsl:/usr/lib/wsl         # WSL2ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚¦ãƒ³ãƒˆ
-e LD_LIBRARY_PATH=/usr/lib/wsl/lib  # WSL2ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ‘ã‚¹
```

#### âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è¦‹ã¤ã‹ã‚‰ãªã„
**ç—‡çŠ¶**: `can't open file '/app/scripts/test_voice_clone_ja_complete.py'`
```bash
# è§£æ±ºç­–: scriptsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ãƒã‚¦ãƒ³ãƒˆã™ã‚‹
-v $(pwd)/scripts:/app/scripts  # ã“ã®è¡Œã‚’è¿½åŠ 
```

### GPUèªè­˜å•é¡Œï¼ˆåŸºæœ¬ï¼‰
```bash
# GPUç¢ºèªï¼ˆRTX 3050ã®å ´åˆï¼‰
nvidia-smi  # ãƒ›ã‚¹ãƒˆã§ç¢ºèª

# Dockerå†…ã§GPUç¢ºèª
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  gpt-sovits:v4 nvidia-smi
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ
**ç—‡çŠ¶**: éŸ³å£°ç”ŸæˆãŒé…ã„ï¼ˆ20ç§’ä»¥ä¸Šï¼‰
```bash
# âœ… è§£æ±ºç­–: FastAPIã‚µãƒ¼ãƒãƒ¼ä½¿ç”¨ï¼ˆ3ç§’/å›ï¼‰
# ä¸Šè¨˜ã€ŒFastAPIã‚µãƒ¼ãƒãƒ¼ï¼ˆæ¨å¥¨ãƒ»æœ¬æ ¼åˆ©ç”¨ï¼‰ã€ã‚’å‚ç…§
```

### ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—
```bash
# GPT-SoVITS
cd Gptsovits && ./scripts/download_models.sh

# LlamaCPP
cd llamacpp && ./scripts/setup_model.sh
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆRTX 3050åŸºæº–ï¼‰

### GPT-SoVITS å®Ÿæ¸¬å€¤

| æ–¹å¼ | åˆæœŸåŒ–æ™‚é–“ | ç”Ÿæˆæ™‚é–“/å› | ç·æ™‚é–“ | ä½¿ç”¨å ´é¢ |
|------|------------|-------------|--------|----------|
| **FastAPI** | 20ç§’ï¼ˆ1å›ã®ã¿ï¼‰ | **3ç§’** | **3ç§’** | ğŸ¥‡ **æœ¬æ ¼åˆ©ç”¨æ¨å¥¨** |
| Warm-upç‰ˆ | 21ç§’ï¼ˆæ¯å›ï¼‰ | 2.7ç§’ | 35ç§’ | ğŸ¥ˆ é€£ç¶šå‡¦ç†ç”¨ |
| é€šå¸¸ç‰ˆ | 25ç§’ï¼ˆæ¯å›ï¼‰ | 20ç§’ | 45ç§’ | ğŸ¥‰ é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ |

#### FastAPIã‚µãƒ¼ãƒãƒ¼ã®åœ§å€’çš„å„ªä½æ€§
- **åˆæœŸåŒ–**: 20ç§’ï¼ˆèµ·å‹•æ™‚1å›ã®ã¿ï¼‰
- **ãƒ¬ã‚¹ãƒãƒ³ã‚¹**: 3ç§’/ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆ7.5å€é«˜é€ŸåŒ–ï¼‰
- **ä¸¦åˆ—å‡¦ç†**: è¤‡æ•°ãƒªã‚¯ã‚¨ã‚¹ãƒˆåŒæ™‚å‡¦ç†å¯èƒ½
- **RESTful API**: ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ç°¡å˜å‘¼ã³å‡ºã—

#### æŠ€è¡“ä»•æ§˜
- **VRAMä½¿ç”¨é‡**: 4-6GBï¼ˆFP16ã§2-3GBå¯èƒ½ï¼‰
- **éŸ³è³ª**: RMS=25-35, éç„¡éŸ³ç‡60-80%
- **å¯¾å¿œãƒ¢ãƒ‡ãƒ«**: æ¨™æº–v2ã€æ—¥æœ¬èªå°‚ç”¨ï¼ˆhscene-e17.ckptï¼‰
- **æœ€é©åŒ–**: TensorCore + Torch.compile + FP16

### LlamaCPP
- **å¿œç­”é€Ÿåº¦**: 1.03ç§’/è³ªå•ï¼ˆç›´æ¥CLIï¼‰
- **APIå¿œç­”**: ~2ç§’/è³ªå•ï¼ˆFastAPIçµŒç”±ï¼‰
- **VRAMä½¿ç”¨é‡**: 3.86GBï¼ˆ96.1%ä½¿ç”¨ç‡ï¼‰
- **ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ**: 20-30 tokens/sec

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/amazing-feature`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ (`git commit -m 'Add amazing feature'`)
4. ãƒ–ãƒ©ãƒ³ãƒã«ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/amazing-feature`)
5. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ†˜ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆï¼š
1. å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®`CLAUDE.md`ã§è©³ç´°ãªè¨­å®šã‚’ç¢ºèª
2. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«(`logs/`)ã‚’ç¢ºèª
3. GPUçŠ¶æ³ã‚’`nvidia-smi`ã§ç¢ºèª
4. Issuesã§å ±å‘Š

---

**é‡è¦**: dockerãƒ“ãƒ«ãƒ‰ã¯å¿…ãšã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ï¼ˆ`--no-cache`ç¦æ­¢ï¼‰ã€GPUæ¨è«–ã¯å¿…é ˆã§ã™ï¼