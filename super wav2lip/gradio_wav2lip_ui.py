#!/usr/bin/env python3
"""
Super Wav2Lip Gradio UI - Fixed Version
"""

import gradio as gr
import requests
import tempfile
import os
import time
import logging
import cv2
import numpy as np
from PIL import Image

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# API URLs
SOVITS_API_URL = "http://gpt-sovits-api:8000"
WAV2LIP_API_URL = "http://super-wav2lip-fixed:8002"
SADTALKER_API_URL = "http://sadtalker-api:8000"  # NEW: SadTalker for images (internal port)

def image_to_video(image_path, duration=3.0, fps=30):
    """ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ"""
    try:
        logger.info(f"ğŸ–¼ï¸ ç”»åƒã‹ã‚‰å‹•ç”»ç”Ÿæˆä¸­: {image_path}")
        
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        img = cv2.imread(image_path)
        if img is None:
            # PILã§è©¦ã™ï¼ˆWebPãªã©ä»–ã®å½¢å¼ï¼‰
            pil_img = Image.open(image_path)
            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        
        height, width, channels = img.shape
        
        # ä¸€æ™‚å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:
            temp_video_path = temp_video.name
        
        # VideoWriterã‚’è¨­å®š
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
        
        # æŒ‡å®šã•ã‚ŒãŸç§’æ•°åˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ›¸ãè¾¼ã¿
        total_frames = int(duration * fps)
        for i in range(total_frames):
            out.write(img)
        
        out.release()
        logger.info(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {temp_video_path}")
        return temp_video_path
        
    except Exception as e:
        logger.error(f"ç”»åƒâ†’å‹•ç”»å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def call_sadtalker_api(image_path, audio_path):
    """SadTalker APIå‘¼ã³å‡ºã—ï¼ˆç”»åƒå°‚ç”¨ï¼‰"""
    try:
        logger.info(f"ğŸ­ SadTalker APIå‘¼ã³å‡ºã—ä¸­... URL: {SADTALKER_API_URL}")
        logger.info(f"ğŸ–¼ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {image_path}")
        logger.info(f"ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {audio_path}")
        
        with open(image_path, 'rb') as img_file, open(audio_path, 'rb') as aud_file:
            files = {
                'image': (os.path.basename(image_path), img_file, 'image/jpeg'),
                'audio': (os.path.basename(audio_path), aud_file, 'audio/wav')
            }
            data = {
                'quality': 'high',
                'fp16': 'true',
                'still_mode': 'true',                         # é™æ­¢ãƒ¢ãƒ¼ãƒ‰å›ºå®š
                'expression_scale': '1.0',                    # è¡¨æƒ…å¼·åº¦1.0å›ºå®š
                'preprocess': 'crop',                         # å‰å‡¦ç†ãƒ¢ãƒ¼ãƒ‰cropå›ºå®š
                'face_detector': 'retinaface',                # RetinaFaceæ¤œå‡ºå™¨å›ºå®š
                'facerender_batch_size': '5',                 # å°ã•ã„ãƒãƒƒãƒã‚µã‚¤ã‚ºã§ç²¾å¯†å‡¦ç†
                'crop_coord': 'auto'                          # è‡ªå‹•ã‚¯ãƒ­ãƒƒãƒ—åº§æ¨™
            }
            
            logger.info(f"ğŸ“¡ POST {SADTALKER_API_URL}/generate")
            response = requests.post(
                f"{SADTALKER_API_URL}/generate", 
                files=files, 
                data=data, 
                timeout=180  # 3åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ56ç§’å‡¦ç†ï¼‰
            )
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                download_url = result.get('download_url')
                if download_url:
                    # ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    video_response = requests.get(f"{SADTALKER_API_URL}{download_url}")
                    if video_response.status_code == 200:
                        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video_orig:
                            temp_video_orig.write(video_response.content)
                            temp_video_orig_path = temp_video_orig.name
                        
                        # éŸ³å£°å“è³ªä¿®å¾©: å…ƒã®é«˜å“è³ªéŸ³å£°ã§ç½®ãæ›ãˆ
                        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video_fixed:
                            temp_video_fixed_path = temp_video_fixed.name
                        
                        # FFmpegã§ã‚¹ãƒˆãƒªãƒ¼ãƒ åˆ†é›¢ã—ã¦é«˜å“è³ªéŸ³å£°ã‚’ãƒãƒ¼ã‚¸
                        import subprocess
                        ffmpeg_cmd = [
                            'ffmpeg', '-y',
                            '-i', temp_video_orig_path,  # SadTalkerå‹•ç”»ï¼ˆæ˜ åƒã®ã¿ä½¿ç”¨ï¼‰
                            '-i', audio_path,            # å…ƒã®é«˜å“è³ªéŸ³å£°
                            '-map', '0:v:0',             # å‹•ç”»ã®æ˜ åƒã‚¹ãƒˆãƒªãƒ¼ãƒ 
                            '-map', '1:a:0',             # å…ƒéŸ³å£°ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ 
                            '-c:v', 'copy',              # æ˜ åƒã¯ç„¡å¤‰æ›
                            '-c:a', 'copy',              # éŸ³å£°ã¯ç„¡å¤‰æ›ï¼ˆå“è³ªä¿æŒï¼‰
                            '-shortest',                 # çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹
                            temp_video_fixed_path
                        ]
                        
                        try:
                            subprocess.run(ffmpeg_cmd, check=True, capture_output=True)
                            logger.info(f"âœ… éŸ³å£°å“è³ªä¿®å¾©å®Œäº†: å…ƒéŸ³å£°å“è³ªã‚’100%ä¿æŒ")
                            
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                            try:
                                os.unlink(temp_video_orig_path)
                            except:
                                pass
                            
                            return temp_video_fixed_path, f"SadTalkeré«˜å“è³ªå‹•ç”»ç”Ÿæˆå®Œäº†ï¼ˆéŸ³å£°ãƒã‚¤ã‚ºãƒ•ãƒªãƒ¼ï¼‰ ({result.get('processing_time', 0):.1f}ç§’)"
                            
                        except subprocess.CalledProcessError as e:
                            logger.error(f"âŒ éŸ³å£°ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®å‹•ç”»ã‚’è¿”ã™
                            return temp_video_orig_path, f"SadTalkerå‹•ç”»ç”Ÿæˆå®Œäº†ï¼ˆéŸ³å£°ä¿®å¾©å¤±æ•—ï¼‰ ({result.get('processing_time', 0):.1f}ç§’)"
            
            return None, f"SadTalkerã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown error')}"
        else:
            return None, f"SadTalker APIã‚¨ãƒ©ãƒ¼: {response.status_code}"
    
    except Exception as e:
        logger.error(f"âŒ SadTalker APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None, f"SadTalkeræ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"

def generate_complete_lipsync(text_input, media_file, ref_audio_file, enhancer="gfpgan", batch_size=8):
    """çµ±åˆå£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆ"""
    try:
        logger.info("ğŸ­ çµ±åˆå£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆé–‹å§‹")
        
        # 0. ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼è‡ªå‹•åˆ¤å®šã¨ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        if media_file:
            file_ext = os.path.splitext(media_file.lower())[1]
            is_image = file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
            
            if is_image:
                logger.info("ğŸ–¼ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º â†’ SadTalker APIã‚’ä½¿ç”¨")
                
                # 1. GPT-SoVITSã§éŸ³å£°ç”Ÿæˆ
                logger.info("ğŸ¤ éŸ³å£°ç”Ÿæˆä¸­...")
                with open(ref_audio_file, 'rb') as f:
                    files = {"ref_audio": f}
                    data = {"ref_text": "ã‚µãƒ³ãƒ—ãƒ«", "target_text": text_input}
                    sovits_response = requests.post(f"{SOVITS_API_URL}/clone-voice-simple", 
                                                  files=files, data=data, timeout=60)
                
                if sovits_response.status_code != 200:
                    return None, f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {sovits_response.status_code}"
                
                # éŸ³å£°ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
                    temp_audio.write(sovits_response.content)
                    temp_audio_path = temp_audio.name
                
                # 2. SadTalker APIã§ç”»åƒâ†’å‹•ç”»ç”Ÿæˆ
                logger.info("ğŸ­ SadTalkeré«˜å“è³ªå‹•ç”»ç”Ÿæˆä¸­ï¼ˆç´„56ç§’ï¼‰...")
                result_video, status_msg = call_sadtalker_api(media_file, temp_audio_path)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                try:
                    os.unlink(temp_audio_path)
                except:
                    pass
                
                return result_video, status_msg
            
            else:
                logger.info("ğŸ¬ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º â†’ Wav2Lip APIã‚’ä½¿ç”¨ï¼ˆé«˜é€Ÿå‡¦ç†ï¼‰")
                video_file_path = media_file
                
                # 1. éŸ³å£°ç”Ÿæˆï¼ˆå‹•ç”»ãƒ¢ãƒ¼ãƒ‰ï¼‰
                logger.info("ğŸ¤ éŸ³å£°ç”Ÿæˆä¸­...")
                
                with open(ref_audio_file, 'rb') as f:
                    files = {"ref_audio": f}
                    data = {"ref_text": "ã‚µãƒ³ãƒ—ãƒ«", "target_text": text_input}
                    
                    sovits_response = requests.post(f"{SOVITS_API_URL}/clone-voice-simple", 
                                                  files=files, data=data, timeout=60)
                
                if sovits_response.status_code != 200:
                    return None, f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {sovits_response.status_code}"
                
                # éŸ³å£°ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
                    temp_audio.write(sovits_response.content)
                    temp_audio_path = temp_audio.name
                
                # 2. Wav2Lipå£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆ
                logger.info("ğŸ¬ Wav2Lipå£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆä¸­...")
                
                with open(video_file_path, 'rb') as vf, open(temp_audio_path, 'rb') as af:
                    files = {
                        "video_file": vf,
                        "audio_file": af
                    }
                    data = {
                        "enhancer": enhancer,
                        "batch_size": batch_size
                    }
                    
                    wav2lip_response = requests.post(f"{WAV2LIP_API_URL}/generate-lipsync",
                                                   files=files, data=data, timeout=120)
                
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                os.unlink(temp_audio_path)
                
                if wav2lip_response.status_code == 200:
                    # çµæœå‹•ç”»ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_result_video:
                        temp_result_video.write(wav2lip_response.content)
                        result_video_path = temp_result_video.name
                    
                    logger.info("âœ… Wav2Lipå‹•ç”»å‡¦ç†å®Œäº†!")
                    return result_video_path, "Wav2Lipé«˜é€Ÿå£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆå®Œäº†!"
                else:
                    return None, f"Wav2Lipç”Ÿæˆã‚¨ãƒ©ãƒ¼: {wav2lip_response.status_code}"
            
    except Exception as e:
        logger.error(f"çµ±åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if 'temp_audio_path' in locals():
            try:
                os.unlink(temp_audio_path)
            except:
                pass
        if 'temp_video_path' in locals() and temp_video_path:
            try:
                os.unlink(temp_video_path)
            except:
                pass
        return None, f"ã‚¨ãƒ©ãƒ¼: {e}"

# Gradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
def create_interface():
    with gr.Blocks(title="Super Wav2Lip") as interface:
        gr.HTML("<h1>ğŸ­ Super Wav2Lip - AIéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³çµ±åˆå£ãƒ‘ã‚¯ã‚·ã‚¹ãƒ†ãƒ </h1>")
        
        with gr.Row():
            with gr.Column():
                text_input = gr.Textbox(
                    label="ğŸ“ ç”Ÿæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆ",
                    placeholder="ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚",
                    lines=3
                )
                
                media_file = gr.File(
                    label="ğŸ¬ å‹•ç”»ãƒ»ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«", 
                    file_types=[".mp4", ".avi", ".mov", ".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"]
                )
                
                ref_audio_file = gr.File(
                    label="ğŸµ å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«",
                    file_types=[".wav", ".mp3", ".m4a"]
                )
                
                with gr.Row():
                    enhancer = gr.Dropdown(
                        choices=["none", "gfpgan"],
                        value="none",
                        label="âœ¨ é¡”å¼·åŒ–",
                        info="gfpgan: å®Ÿå†™é¡”ç”¨ | none: ç„¡ã—"
                    )
                    
                    batch_size = gr.Slider(
                        minimum=1, maximum=16, value=8, step=1,
                        label="âš¡ ãƒãƒƒãƒã‚µã‚¤ã‚º"
                    )
                
                
                generate_btn = gr.Button("ğŸš€ å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆé–‹å§‹", variant="primary")
                
            with gr.Column():
                status_output = gr.Textbox(label="ğŸ“Š å‡¦ç†çŠ¶æ³", lines=2)
                video_output = gr.Video(label="ğŸ“º ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»")
        
        generate_btn.click(
            fn=generate_complete_lipsync,
            inputs=[text_input, media_file, ref_audio_file, enhancer, batch_size],
            outputs=[video_output, status_output]
        )
    
    return interface

if __name__ == "__main__":
    interface = create_interface()
    interface.launch(server_name="0.0.0.0", server_port=7860)