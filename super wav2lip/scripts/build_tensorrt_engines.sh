#!/bin/bash
# TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ä¸€æ‹¬æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ for Super Wav2Lip
# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œã—ã¦ONNX â†’ TensorRTå¤‰æ›
#
# ä½¿ç”¨ä¾‹:
# chmod +x scripts/build_tensorrt_engines.sh
# ./scripts/build_tensorrt_engines.sh

set -e  # ã‚¨ãƒ©ãƒ¼æ™‚ã«åœæ­¢

echo "ðŸš€ Super Wav2Lip TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰é–‹å§‹"
echo "================================================"

# ç’°å¢ƒãƒã‚§ãƒƒã‚¯
check_environment() {
    echo "ðŸ” ç’°å¢ƒãƒã‚§ãƒƒã‚¯ä¸­..."
    
    # GPU ãƒã‚§ãƒƒã‚¯
    if ! nvidia-smi > /dev/null 2>&1; then
        echo "âŒ NVIDIA GPU ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“"
        exit 1
    fi
    
    # TensorRT ãƒã‚§ãƒƒã‚¯
    python3 -c "import tensorrt; print(f'TensorRT version: {tensorrt.__version__}')" || {
        echo "âŒ TensorRT ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        echo "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install tensorrt"
        exit 1
    }
    
    # CUDA ãƒã‚§ãƒƒã‚¯
    python3 -c "import pycuda.driver; print('PyCUDA available')" || {
        echo "âŒ PyCUDA ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        echo "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install pycuda"
        exit 1
    }
    
    echo "âœ… ç’°å¢ƒãƒã‚§ãƒƒã‚¯å®Œäº†"
}

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
setup_directories() {
    echo "ðŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šä¸­..."
    
    mkdir -p /app/models/tensorrt
    mkdir -p /app/logs
    
    echo "âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šå®Œäº†"
}

# ONNX ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
check_onnx_models() {
    echo "ðŸ” ONNX ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ä¸­..."
    
    local missing_models=0
    
    # Wav2Lip ONNX
    if [ ! -f "/app/models/onnx/wav2lip_gan.onnx" ]; then
        echo "âš ï¸  wav2lip_gan.onnx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        missing_models=$((missing_models + 1))
    else
        echo "âœ… wav2lip_gan.onnx ç¢ºèª"
    fi
    
    # GFPGAN ONNX
    if [ ! -f "/app/src/enhancers/GFPGAN/GFPGANv1.4.onnx" ]; then
        echo "âš ï¸  GFPGANv1.4.onnx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        missing_models=$((missing_models + 1))
    else
        echo "âœ… GFPGANv1.4.onnx ç¢ºèª"
    fi
    
    if [ $missing_models -gt 0 ]; then
        echo "âš ï¸  $missing_models å€‹ã®ONNXãƒ¢ãƒ‡ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™ãŒã€ç¶šè¡Œã—ã¾ã™"
    fi
}

# TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰
build_engines() {
    echo "ðŸ”§ TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰ä¸­..."
    
    local log_file="/app/logs/tensorrt_build_$(date +%Y%m%d_%H%M%S).log"
    
    # Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
    python3 /app/scripts/tensorrt_engine_builder.py \
        --model both \
        --onnx-dir /app/models/onnx \
        --engine-dir /app/models/tensorrt \
        --dynamic \
        --precision fp16 \
        --optimize \
        --benchmark \
        --verbose 2>&1 | tee "$log_file"
    
    if [ $? -eq 0 ]; then
        echo "âœ… TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰æˆåŠŸ"
    else
        echo "âŒ TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰å¤±æ•—"
        echo "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: $log_file"
        exit 1
    fi
}

# ã‚¨ãƒ³ã‚¸ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
verify_engines() {
    echo "ðŸ” TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ç¢ºèªä¸­..."
    
    local engine_dir="/app/models/tensorrt"
    
    # Wav2Lip ã‚¨ãƒ³ã‚¸ãƒ³
    if [ -f "$engine_dir/wav2lip_gan.trt" ]; then
        local wav2lip_size=$(du -h "$engine_dir/wav2lip_gan.trt" | cut -f1)
        echo "âœ… wav2lip_gan.trt ($wav2lip_size)"
    else
        echo "âš ï¸  wav2lip_gan.trt ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    fi
    
    # GFPGAN ã‚¨ãƒ³ã‚¸ãƒ³
    if [ -f "$engine_dir/gfpgan_v1.4.trt" ]; then
        local gfpgan_size=$(du -h "$engine_dir/gfpgan_v1.4.trt" | cut -f1)
        echo "âœ… gfpgan_v1.4.trt ($gfpgan_size)"
    else
        echo "âš ï¸  gfpgan_v1.4.trt ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    fi
    
    # å…¨ä½“ã‚µã‚¤ã‚º
    if [ -d "$engine_dir" ]; then
        local total_size=$(du -sh "$engine_dir" | cut -f1)
        echo "ðŸ“Š TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ç·ã‚µã‚¤ã‚º: $total_size"
    fi
}

# çµ±åˆãƒ†ã‚¹ãƒˆ
integration_test() {
    echo "ðŸ§ª çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­..."
    
    # TensorRT æŽ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ
    python3 -c "
import sys
sys.path.append('/app/scripts')
try:
    from tensorrt_inference_engine import TensorRTInference
    
    # GFPGAN ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ
    if os.path.exists('/app/models/tensorrt/gfpgan_v1.4.trt'):
        engine = TensorRTInference('/app/models/tensorrt/gfpgan_v1.4.trt')
        print('âœ… GFPGAN TensorRT ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿æˆåŠŸ')
        
        # ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯
        results = engine.benchmark((1, 3, 512, 512), iterations=10)
        print(f'   å¹³å‡å®Ÿè¡Œæ™‚é–“: {results[\"avg_time_ms\"]:.2f}ms')
        print(f'   FPS: {results[\"fps\"]:.1f}')
    else:
        print('âš ï¸  GFPGAN TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        
except Exception as e:
    print(f'âŒ çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}')
    sys.exit(1)
" 2>/dev/null

    if [ $? -eq 0 ]; then
        echo "âœ… çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ"
    else
        echo "âš ï¸  çµ±åˆãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆã‚¨ãƒ³ã‚¸ãƒ³ã¯ç”Ÿæˆæ¸ˆã¿ï¼‰"
    fi
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
main() {
    echo "é–‹å§‹æ™‚åˆ»: $(date)"
    
    check_environment
    setup_directories
    check_onnx_models
    build_engines
    verify_engines
    integration_test
    
    echo ""
    echo "ðŸŽ‰ TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰å®Œäº†!"
    echo "================================================"
    echo "æ§‹ç¯‰ã•ã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³:"
    ls -la /app/models/tensorrt/*.trt 2>/dev/null || echo "ã‚¨ãƒ³ã‚¸ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    echo ""
    echo "ä½¿ç”¨æ–¹æ³•:"
    echo "1. FastAPI ã§è‡ªå‹•çš„ã« TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ãŒä½¿ç”¨ã•ã‚Œã¾ã™"
    echo "2. æ‰‹å‹•ä½¿ç”¨: from scripts.tensorrt_inference_engine import TensorRTInference"
    echo ""
    echo "çµ‚äº†æ™‚åˆ»: $(date)"
}

# Docker ã‚³ãƒ³ãƒ†ãƒŠå†…å®Ÿè¡Œç”¨
if [ "$1" = "--docker" ]; then
    # Docker ç’°å¢ƒã§ã®å®Ÿè¡Œ
    cd /app
    export PYTHONPATH=/app/src:/app/scripts:$PYTHONPATH
    main
else
    # ãƒ›ã‚¹ãƒˆç’°å¢ƒã§ã®å®Ÿè¡Œï¼ˆDocker çµŒç”±ï¼‰
    echo "ðŸ³ Docker ã‚³ãƒ³ãƒ†ãƒŠå†…ã§TensorRT ã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰ã‚’å®Ÿè¡Œã—ã¾ã™..."
    
    docker run --gpus all --rm \
        -v "$(pwd):/app" \
        -w /app \
        super-wav2lip:v1-gpu-ultimate \
        bash -c "
            pip install tensorrt pycuda >/dev/null 2>&1 || echo 'TensorRT/PyCUDA ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—'
            chmod +x /app/scripts/build_tensorrt_engines.sh
            /app/scripts/build_tensorrt_engines.sh --docker
        "
fi