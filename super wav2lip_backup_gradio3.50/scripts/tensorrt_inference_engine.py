#!/usr/bin/env python3
"""
TensorRT æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ for Super Wav2Lip
å‹•çš„è§£åƒåº¦å¯¾å¿œ TensorRTæ¨è«–ãƒ©ãƒƒãƒ‘ãƒ¼

ä½¿ç”¨ä¾‹:
from scripts.tensorrt_inference_engine import TensorRTInference
engine = TensorRTInference('models/tensorrt/gfpgan_v1.4.trt')
result = engine.infer(input_tensor, target_resolution=(512, 512))
"""

import os
import time
import logging
import numpy as np
from pathlib import Path
from typing import Tuple, Optional, Union
import cv2

try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    TENSORRT_AVAILABLE = True
except ImportError:
    TENSORRT_AVAILABLE = False

logger = logging.getLogger(__name__)

class TensorRTInference:
    """TensorRTæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆå‹•çš„è§£åƒåº¦å¯¾å¿œï¼‰"""
    
    def __init__(self, engine_path: str, logger_level=trt.Logger.WARNING):
        """
        TensorRTæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        
        Args:
            engine_path: TensorRTã‚¨ãƒ³ã‚¸ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            logger_level: TensorRTãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
        """
        if not TENSORRT_AVAILABLE:
            raise ImportError("TensorRT not available. Install with: pip install tensorrt")
            
        if not os.path.exists(engine_path):
            raise FileNotFoundError(f"TensorRT engine not found: {engine_path}")
            
        self.engine_path = engine_path
        self.trt_logger = trt.Logger(logger_level)
        self.runtime = trt.Runtime(self.trt_logger)
        
        # ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿
        with open(engine_path, 'rb') as f:
            self.engine = self.runtime.deserialize_cuda_engine(f.read())
            
        self.context = self.engine.create_execution_context()
        
        # ã‚¨ãƒ³ã‚¸ãƒ³æƒ…å ±å–å¾—
        self.num_bindings = self.engine.num_bindings
        self.input_names = []
        self.output_names = []
        self.input_shapes = {}
        self.output_shapes = {}
        
        for i in range(self.num_bindings):
            name = self.engine.get_binding_name(i)
            shape = self.engine.get_binding_shape(i)
            
            if self.engine.binding_is_input(i):
                self.input_names.append(name)
                self.input_shapes[name] = shape
            else:
                self.output_names.append(name)
                self.output_shapes[name] = shape
                
        # GPU ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ï¼ˆå‹•çš„ç¢ºä¿ï¼‰
        self.buffers = {}
        self.buffer_sizes = {}
        
        logger.info(f"âœ… TensorRT ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿å®Œäº†: {engine_path}")
        logger.info(f"   å…¥åŠ›: {self.input_names}")
        logger.info(f"   å‡ºåŠ›: {self.output_names}")
        
    def _allocate_buffers(self, input_shape: Tuple[int, ...], output_shape: Tuple[int, ...]):
        """å‹•çš„ãƒãƒƒãƒ•ã‚¡ç¢ºä¿"""
        input_size = np.prod(input_shape) * np.dtype(np.float32).itemsize
        output_size = np.prod(output_shape) * np.dtype(np.float32).itemsize
        
        # æ—¢å­˜ãƒãƒƒãƒ•ã‚¡ã‚ˆã‚Šå¤§ãã„å ´åˆã®ã¿å†ç¢ºä¿
        if input_size > self.buffer_sizes.get('input', 0):
            if 'input' in self.buffers:
                cuda.mem_free(self.buffers['input'])
            self.buffers['input'] = cuda.mem_alloc(input_size)
            self.buffer_sizes['input'] = input_size
            
        if output_size > self.buffer_sizes.get('output', 0):
            if 'output' in self.buffers:
                cuda.mem_free(self.buffers['output'])
            self.buffers['output'] = cuda.mem_alloc(output_size)
            self.buffer_sizes['output'] = output_size
            
    def set_dynamic_shape(self, input_name: str, shape: Tuple[int, ...]):
        """å‹•çš„å½¢çŠ¶è¨­å®š"""
        if not self.context.set_binding_shape(0, shape):  # 0ã¯å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            raise RuntimeError(f"Failed to set dynamic shape: {shape}")
            
        # å‡ºåŠ›å½¢çŠ¶ã‚’æ›´æ–°ï¼ˆæ¨è«–å®Ÿè¡Œå‰ã«å¿…è¦ï¼‰
        if not self.context.all_binding_shapes_specified:
            raise RuntimeError("Not all binding shapes specified")
            
    def preprocess_gfpgan(self, image: np.ndarray, target_size: Tuple[int, int] = (512, 512)) -> np.ndarray:
        """GFPGANç”¨å‰å‡¦ç†"""
        # ãƒªã‚µã‚¤ã‚º
        resized = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)
        
        # BGR â†’ RGB + æ­£è¦åŒ–
        rgb = resized[:, :, ::-1].astype(np.float32) / 255.0
        
        # HWC â†’ CHW
        chw = rgb.transpose((2, 0, 1))
        
        # [-1, 1] æ­£è¦åŒ–
        normalized = (chw - 0.5) / 0.5
        
        # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 
        batched = np.expand_dims(normalized, axis=0)
        
        return batched.astype(np.float32)
        
    def postprocess_gfpgan(self, output: np.ndarray, original_size: Tuple[int, int]) -> np.ndarray:
        """GFPGANç”¨å¾Œå‡¦ç†"""
        # ãƒãƒƒãƒæ¬¡å…ƒé™¤å»
        if output.ndim == 4:
            output = output[0]
            
        # CHW â†’ HWC
        hwc = output.transpose((1, 2, 0))
        
        # [-1, 1] â†’ [0, 255]
        denormalized = (hwc.clip(-1, 1) + 1) * 0.5 * 255
        
        # RGB â†’ BGR
        bgr = denormalized[:, :, ::-1]
        
        # å…ƒã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        resized = cv2.resize(bgr, original_size)
        
        return resized.clip(0, 255).astype(np.uint8)
        
    def infer_gfpgan(self, image: np.ndarray, target_resolution: Tuple[int, int] = (512, 512)) -> np.ndarray:
        """
        GFPGANæ¨è«–å®Ÿè¡Œï¼ˆå‹•çš„è§£åƒåº¦å¯¾å¿œï¼‰
        
        Args:
            image: å…¥åŠ›ç”»åƒ (H, W, 3) BGR
            target_resolution: å‡¦ç†è§£åƒåº¦
            
        Returns:
            enhanced_image: å¼·åŒ–æ¸ˆã¿ç”»åƒ (H, W, 3) BGR
        """
        original_size = (image.shape[1], image.shape[0])  # (W, H)
        
        # å‰å‡¦ç†
        input_tensor = self.preprocess_gfpgan(image, target_resolution)
        input_shape = input_tensor.shape  # (1, 3, H, W)
        output_shape = input_shape  # GFPGAN ã¯åŒã˜ã‚µã‚¤ã‚ºå‡ºåŠ›
        
        # å‹•çš„å½¢çŠ¶è¨­å®š
        self.set_dynamic_shape(self.input_names[0], input_shape)
        
        # ãƒãƒƒãƒ•ã‚¡ç¢ºä¿
        self._allocate_buffers(input_shape, output_shape)
        
        # GPU ãƒ¡ãƒ¢ãƒªè»¢é€
        cuda.memcpy_htod(self.buffers['input'], input_tensor)
        
        # æ¨è«–å®Ÿè¡Œ
        bindings = [int(self.buffers['input']), int(self.buffers['output'])]
        self.context.execute_v2(bindings)
        
        # çµæœå–å¾—
        output_tensor = np.empty(output_shape, dtype=np.float32)
        cuda.memcpy_dtoh(output_tensor, self.buffers['output'])
        
        # å¾Œå‡¦ç†
        enhanced_image = self.postprocess_gfpgan(output_tensor, original_size)
        
        return enhanced_image
        
    def infer_wav2lip(self, mel_spectrogram: np.ndarray, video_frames: np.ndarray) -> np.ndarray:
        """
        Wav2Lipæ¨è«–å®Ÿè¡Œ
        
        Args:
            mel_spectrogram: ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  (1, 1, 80, T)
            video_frames: å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ  (1, 6, 96, 96)
            
        Returns:
            generated_frames: ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ  (1, 3, 96, 96)
        """
        # å…¥åŠ›å½¢çŠ¶è¨­å®š
        mel_shape = mel_spectrogram.shape
        video_shape = video_frames.shape
        output_shape = (1, 3, 96, 96)  # Wav2Lipå‡ºåŠ›å½¢çŠ¶
        
        # å‹•çš„å½¢çŠ¶è¨­å®šï¼ˆãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼‰
        self.set_dynamic_shape(self.input_names[0], mel_shape)
        
        # ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ï¼ˆ2ã¤ã®å…¥åŠ› + 1ã¤ã®å‡ºåŠ›ï¼‰
        total_input_size = (np.prod(mel_shape) + np.prod(video_shape)) * np.dtype(np.float32).itemsize
        output_size = np.prod(output_shape) * np.dtype(np.float32).itemsize
        
        if total_input_size > self.buffer_sizes.get('input', 0):
            if 'input' in self.buffers:
                cuda.mem_free(self.buffers['input'])
            self.buffers['mel_input'] = cuda.mem_alloc(np.prod(mel_shape) * np.dtype(np.float32).itemsize)
            self.buffers['video_input'] = cuda.mem_alloc(np.prod(video_shape) * np.dtype(np.float32).itemsize)
            
        if output_size > self.buffer_sizes.get('output', 0):
            if 'output' in self.buffers:
                cuda.mem_free(self.buffers['output'])
            self.buffers['output'] = cuda.mem_alloc(output_size)
            self.buffer_sizes['output'] = output_size
            
        # GPU ãƒ¡ãƒ¢ãƒªè»¢é€
        cuda.memcpy_htod(self.buffers['mel_input'], mel_spectrogram)
        cuda.memcpy_htod(self.buffers['video_input'], video_frames)
        
        # æ¨è«–å®Ÿè¡Œ
        bindings = [
            int(self.buffers['mel_input']), 
            int(self.buffers['video_input']), 
            int(self.buffers['output'])
        ]
        self.context.execute_v2(bindings)
        
        # çµæœå–å¾—
        output_tensor = np.empty(output_shape, dtype=np.float32)
        cuda.memcpy_dtoh(output_tensor, self.buffers['output'])
        
        return output_tensor
        
    def benchmark(self, input_shape: Tuple[int, ...], iterations: int = 100) -> dict:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ç”Ÿæˆ
        dummy_input = np.random.randn(*input_shape).astype(np.float32)
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        for _ in range(10):
            if len(input_shape) == 4 and input_shape[1] == 3:  # GFPGAN
                dummy_image = (dummy_input[0].transpose(1, 2, 0) * 127.5 + 127.5).astype(np.uint8)
                self.infer_gfpgan(dummy_image, (input_shape[2], input_shape[3]))
                
        # æœ¬æ¸¬å®š
        cuda.Context.synchronize()
        start_time = time.time()
        
        for _ in range(iterations):
            if len(input_shape) == 4 and input_shape[1] == 3:  # GFPGAN
                dummy_image = (dummy_input[0].transpose(1, 2, 0) * 127.5 + 127.5).astype(np.uint8)
                self.infer_gfpgan(dummy_image, (input_shape[2], input_shape[3]))
                
        cuda.Context.synchronize()
        end_time = time.time()
        
        avg_time = (end_time - start_time) / iterations * 1000  # ms
        fps = 1000 / avg_time
        
        return {
            'avg_time_ms': avg_time,
            'fps': fps,
            'iterations': iterations,
            'input_shape': input_shape
        }
        
    def __del__(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        for buffer in self.buffers.values():
            if isinstance(buffer, cuda.DeviceAllocation):
                cuda.mem_free(buffer)

class DynamicResolutionManager:
    """å‹•çš„è§£åƒåº¦ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_resolution: int = 512, min_resolution: int = 256, max_resolution: int = 1024):
        self.base_resolution = base_resolution
        self.min_resolution = min_resolution
        self.max_resolution = max_resolution
        self.current_resolution = base_resolution
        self.performance_history = []
        
    def adjust_resolution(self, processing_time: float, target_fps: float = 30.0) -> int:
        """
        å‡¦ç†æ™‚é–“ã«åŸºã¥ã„ã¦è§£åƒåº¦ã‚’å‹•çš„èª¿æ•´
        
        Args:
            processing_time: å‰å›ã®å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
            target_fps: ç›®æ¨™FPS
            
        Returns:
            èª¿æ•´å¾Œã®è§£åƒåº¦
        """
        current_fps = 1.0 / processing_time if processing_time > 0 else target_fps
        
        # æ€§èƒ½å±¥æ­´ã«è¿½åŠ 
        self.performance_history.append(current_fps)
        if len(self.performance_history) > 10:
            self.performance_history.pop(0)
            
        # å¹³å‡FPSã§åˆ¤å®š
        avg_fps = np.mean(self.performance_history)
        
        if avg_fps < target_fps * 0.8:  # ç›®æ¨™ã®80%æœªæº€
            # è§£åƒåº¦ã‚’ä¸‹ã’ã‚‹
            self.current_resolution = max(self.min_resolution, 
                                        int(self.current_resolution * 0.9))
        elif avg_fps > target_fps * 1.2:  # ç›®æ¨™ã®120%è¶…é
            # è§£åƒåº¦ã‚’ä¸Šã’ã‚‹
            self.current_resolution = min(self.max_resolution,
                                        int(self.current_resolution * 1.1))
            
        # 32ã®å€æ•°ã«èª¿æ•´ï¼ˆGPUåŠ¹ç‡åŒ–ï¼‰
        self.current_resolution = (self.current_resolution // 32) * 32
        
        return self.current_resolution
        
    def get_optimal_resolution(self, face_size: Tuple[int, int]) -> int:
        """é¡”ã‚µã‚¤ã‚ºã«åŸºã¥ãæœ€é©è§£åƒåº¦ç®—å‡º"""
        face_area = face_size[0] * face_size[1]
        
        if face_area < 64 * 64:
            return max(self.min_resolution, 256)
        elif face_area < 128 * 128:
            return max(self.min_resolution, 384)
        elif face_area < 256 * 256:
            return max(self.min_resolution, 512)
        else:
            return min(self.max_resolution, 768)

def create_tensorrt_engines():
    """TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ä¸€æ‹¬ä½œæˆ"""
    script_path = Path(__file__).parent / "tensorrt_engine_builder.py"
    
    # å…¨ãƒ¢ãƒ‡ãƒ«ã‚’ FP16 + å‹•çš„å½¢çŠ¶ã§æ§‹ç¯‰
    cmd = f"python {script_path} --model both --dynamic --precision fp16 --optimize --benchmark"
    
    logger.info(f"ğŸš€ TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ä¸€æ‹¬ä½œæˆå®Ÿè¡Œ: {cmd}")
    os.system(cmd)

if __name__ == "__main__":
    # TensorRT ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
    create_tensorrt_engines()