#!/usr/bin/env python3
"""
Dynamic Shapeå¯¾å¿œTensorRTæ€§èƒ½ãƒ†ã‚¹ãƒˆ
"""

import time
import numpy as np
import onnxruntime as ort

def test_tensorrt_dynamic():
    """Dynamic TensorRTæ¨è«–ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸš€ Dynamic TensorRT æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # TensorRTãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šï¼ˆå‹•çš„å½¢çŠ¶å¯¾å¿œï¼‰
    providers = [
        ('TensorrtExecutionProvider', {
            'device_id': 0,
            'trt_max_workspace_size': 4 * 1024 * 1024 * 1024,  # 4GB
            'trt_fp16_enable': True,
            'trt_engine_cache_enable': True,
            'trt_engine_cache_path': '/app/models/onnx/trt_dynamic_cache',
            'trt_builder_optimization_level': 5,
            'trt_auxiliary_streams': 2,
            # Dynamic shape profiles
            'trt_profile_min_shapes': 'mel_spectrogram:1x1x80x16|video_frames:1x6x96x96',
            'trt_profile_opt_shapes': 'mel_spectrogram:1x1x80x16|video_frames:1x6x96x96',
            'trt_profile_max_shapes': 'mel_spectrogram:4x1x80x64|video_frames:4x6x384x384'
        }),
        'CUDAExecutionProvider'
    ]
    
    try:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        print("ğŸ“Š TensorRTã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆä¸­...")
        session = ort.InferenceSession(
            '/app/models/onnx/wav2lip_gan.onnx',
            providers=providers
        )
        print(f"âœ… ä½¿ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {session.get_providers()}")
        
        # ãƒ†ã‚¹ãƒˆå…¥åŠ›
        batch_size = 1
        mel_input = np.random.randn(batch_size, 1, 80, 16).astype(np.float32)
        video_input = np.random.randn(batch_size, 6, 96, 96).astype(np.float32)
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        print("\nğŸ”¥ ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä¸­...")
        for _ in range(5):
            _ = session.run(None, {
                'mel_spectrogram': mel_input,
                'video_frames': video_input
            })
        
        # æ€§èƒ½æ¸¬å®š
        print("\nâš¡ æ€§èƒ½æ¸¬å®šé–‹å§‹...")
        iterations = 100
        
        start = time.time()
        for _ in range(iterations):
            output = session.run(None, {
                'mel_spectrogram': mel_input,
                'video_frames': video_input
            })
        end = time.time()
        
        avg_ms = (end - start) / iterations * 1000
        fps = 1000 / avg_ms
        
        print(f"\nğŸ“ˆ çµæœ:")
        print(f"   å¹³å‡æ¨è«–æ™‚é–“: {avg_ms:.2f}ms")
        print(f"   æ¨è«–FPS: {fps:.1f}")
        print(f"   ç†è«–ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {fps * 96 * 96 / 1000000:.2f} Mpixels/sec")
        
        # ç•°ãªã‚‹è§£åƒåº¦ã§ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š è§£åƒåº¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ:")
        resolutions = [(96, 96), (192, 192), (256, 256)]
        
        for h, w in resolutions:
            video_test = np.random.randn(1, 6, h, w).astype(np.float32)
            
            start = time.time()
            for _ in range(10):
                try:
                    _ = session.run(None, {
                        'mel_spectrogram': mel_input,
                        'video_frames': video_test
                    })
                except Exception as e:
                    print(f"   {h}x{w}: âŒ ã‚¨ãƒ©ãƒ¼ - {str(e)[:50]}...")
                    break
            else:
                elapsed = time.time() - start
                avg_ms = elapsed / 10 * 1000
                print(f"   {h}x{w}: {avg_ms:.1f}ms/frame ({1000/avg_ms:.1f} FPS)")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # CUDAãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print("\nğŸ“Š CUDAãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã®æ€§èƒ½:")
        session = ort.InferenceSession(
            '/app/models/onnx/wav2lip_gan.onnx',
            providers=['CUDAExecutionProvider']
        )
        
        start = time.time()
        for _ in range(100):
            _ = session.run(None, {
                'mel_spectrogram': mel_input,
                'video_frames': video_input
            })
        end = time.time()
        
        avg_ms = (end - start) / 100 * 1000
        fps = 1000 / avg_ms
        print(f"   å¹³å‡æ¨è«–æ™‚é–“: {avg_ms:.2f}ms")
        print(f"   æ¨è«–FPS: {fps:.1f}")

if __name__ == "__main__":
    test_tensorrt_dynamic()