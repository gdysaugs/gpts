#!/usr/bin/env python3
"""
API Test Script
FastAPI LLMã‚µãƒ¼ãƒãƒ¼ã®ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import httpx
import json
import time
from typing import Dict, Any

class APITester:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=60.0)
    
    async def test_health(self) -> Dict[str, Any]:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ¥ Testing health endpoint...")
        response = await self.client.get(f"{self.base_url}/health")
        result = response.json()
        print(f"âœ… Health: {result}")
        return result
    
    async def test_model_info(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ¤– Testing model info endpoint...")
        response = await self.client.get(f"{self.base_url}/model-info")
        result = response.json()
        print(f"âœ… Model Info: {result}")
        return result
    
    async def test_chat(self) -> Dict[str, Any]:
        """ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸ’¬ Testing chat endpoint...")
        
        chat_request = {
            "message": "ã“ã‚“ã«ã¡ã¯ï¼èª¿å­ã¯ã©ã†ï¼Ÿ",
            "use_history": True,
            "stream": False
        }
        
        start_time = time.time()
        response = await self.client.post(
            f"{self.base_url}/chat",
            json=chat_request
        )
        api_time = time.time() - start_time
        
        result = response.json()
        print(f"âœ… Chat Response: {result['response']}")
        print(f"â±ï¸ API Time: {api_time:.2f}s, Inference Time: {result.get('inference_time', 'N/A')}s")
        return result
    
    async def test_chat_stream(self) -> None:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸŒŠ Testing streaming chat endpoint...")
        
        chat_request = {
            "message": "çŸ­ã„è©©ã‚’ä½œã£ã¦ï¼",
            "use_history": True,
            "stream": True
        }
        
        print("ğŸ“ Streaming response:")
        async with self.client.stream(
            "POST",
            f"{self.base_url}/chat/stream",
            json=chat_request
        ) as response:
            response_text = ""
            async for chunk in response.aiter_text():
                if chunk.startswith("data: "):
                    data_str = chunk[6:].strip()
                    if data_str:
                        try:
                            data = json.loads(data_str)
                            if "token" in data:
                                print(data["token"], end="", flush=True)
                                response_text += data["token"]
                            elif "done" in data:
                                print("\nâœ… Streaming complete!")
                                break
                            elif "error" in data:
                                print(f"\nâŒ Streaming error: {data['error']}")
                                break
                        except json.JSONDecodeError:
                            continue
        
        return {"response": response_text}
    
    async def test_system_prompt(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸ­ Testing system prompt endpoints...")
        
        # ãƒ„ãƒ³ãƒ‡ãƒ¬ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š
        response = await self.client.post(f"{self.base_url}/presets/tsundere")
        result1 = response.json()
        print(f"âœ… Tsundere preset: {result1}")
        
        # ãƒ„ãƒ³ãƒ‡ãƒ¬ã§ä¼šè©±ãƒ†ã‚¹ãƒˆ
        chat_response = await self.client.post(
            f"{self.base_url}/chat",
            json={"message": "æ‰‹ä¼ã£ã¦ãã‚Œã‚‹ï¼Ÿ", "use_history": False}
        )
        tsundere_result = chat_response.json()
        print(f"âœ… Tsundere response: {tsundere_result['response']}")
        
        return {"preset_result": result1, "chat_result": tsundere_result}
    
    async def test_generation_config(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¨­å®šãƒ†ã‚¹ãƒˆ"""
        print("âš™ï¸ Testing generation config endpoint...")
        
        config_request = {
            "temperature": 0.9,
            "top_p": 0.8,
            "max_tokens": 100
        }
        
        response = await self.client.post(
            f"{self.base_url}/generation-config",
            json=config_request
        )
        result = response.json()
        print(f"âœ… Config update: {result}")
        
        # è¨­å®šå¤‰æ›´å¾Œã®ä¼šè©±ãƒ†ã‚¹ãƒˆ
        chat_response = await self.client.post(
            f"{self.base_url}/chat",
            json={"message": "å‰µé€ çš„ãªè©±ã‚’ã—ã¦ï¼", "use_history": False}
        )
        chat_result = chat_response.json()
        print(f"âœ… High creativity response: {chat_result['response'][:100]}...")
        
        return {"config_result": result, "chat_result": chat_result}
    
    async def test_history(self) -> Dict[str, Any]:
        """å±¥æ­´ç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“š Testing history endpoints...")
        
        # å±¥æ­´ç¢ºèª
        response = await self.client.get(f"{self.base_url}/history")
        history_result = response.json()
        print(f"âœ… Current history: {history_result['count']} messages")
        
        # å±¥æ­´ã‚¯ãƒªã‚¢
        clear_response = await self.client.delete(f"{self.base_url}/history")
        clear_result = clear_response.json()
        print(f"âœ… History cleared: {clear_result}")
        
        # ã‚¯ãƒªã‚¢å¾Œã®å±¥æ­´ç¢ºèª
        response = await self.client.get(f"{self.base_url}/history")
        final_history = response.json()
        print(f"âœ… History after clear: {final_history['count']} messages")
        
        return {"history": history_result, "clear": clear_result, "final": final_history}
    
    async def run_all_tests(self):
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("ğŸš€ Starting API Tests")
        print("=" * 50)
        
        try:
            # åŸºæœ¬ãƒ†ã‚¹ãƒˆ
            await self.test_health()
            await self.test_model_info()
            
            # ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            await self.test_chat()
            await self.test_chat_stream()
            
            # é«˜åº¦ãªæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            await self.test_system_prompt()
            await self.test_generation_config()
            await self.test_history()
            
            print("\n" + "=" * 50)
            print("ğŸ‰ All tests completed successfully!")
            
        except Exception as e:
            print(f"\nâŒ Test failed: {e}")
            raise
        finally:
            await self.client.aclose()

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ§ª FastAPI LLM Server Test Suite")
    print("Make sure the server is running on http://localhost:8000")
    print()
    
    tester = APITester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())