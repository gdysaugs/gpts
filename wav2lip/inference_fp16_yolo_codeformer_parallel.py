#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormerï¼ˆè¶…é«˜é€Ÿä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–ï¼š
- ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼šä¸¦åˆ—åŒ–
- CodeFormerå‡¦ç†ï¼šãƒãƒƒãƒä¸¦åˆ—å‡¦ç†
- å‹•ç”»å†æ§‹ç¯‰ï¼šä¸¦åˆ—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
"""

print("\rloading torch       ", end="")
import torch
import torch.cuda.amp as amp

print("\rloading numpy       ", end="")
import numpy as np

print("\rloading cv2         ", end="")
import cv2

print("\rloading os          ", end="")
import os

print("\rloading subprocess  ", end="")
import subprocess

print("\rloading argparse    ", end="")
import argparse

print("\rloading tqdm        ", end="")
from tqdm import tqdm

print("\rloading tempfile    ", end="")
import tempfile

print("\rloading glob        ", end="")
import glob

print("\rloading pathlib     ", end="")
from pathlib import Path

print("\rloading concurrent  ", end="")
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import multiprocessing as mp

print("\rloading enhance     ", end="")
# CodeFormerã®ã¿ãƒ­ãƒ¼ãƒ‰ï¼ˆGFPGANç«¶åˆå›é¿ï¼‰
try:
    from enhance_codeformer import enhance_with_codeformer, load_codeformer
    CODEFORMER_AVAILABLE = True
    print("CodeFormer OK!")
except ImportError as e:
    print(f"CodeFormer NOT FOUND: {e}")
    CODEFORMER_AVAILABLE = False

print("\rimports loaded!     ")

# GPUæœ€é©åŒ–è¨­å®š
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.cuda.empty_cache()
    print("ğŸš€ GPUæœ€é©åŒ–è¨­å®šå®Œäº†ï¼")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼ˆãƒ—ãƒ­ã‚»ã‚¹é–“ã§å…±æœ‰ï¼‰
CODEFORMER_MODEL = None

def init_worker():
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹åˆæœŸåŒ–"""
    global CODEFORMER_MODEL
    if CODEFORMER_AVAILABLE:
        CODEFORMER_MODEL = load_codeformer()
        print(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ {mp.current_process().name} åˆæœŸåŒ–å®Œäº†")

def process_frame_worker(args):
    """å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ï¼‰"""
    frame_path, output_dir, target_height, fidelity_weight = args
    
    try:
        # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
        frame = cv2.imread(frame_path)
        if frame is None:
            return None
        
        # CodeFormerå‡¦ç†
        if CODEFORMER_MODEL and CODEFORMER_MODEL['type'] == 'codeformer':
            with torch.cuda.amp.autocast():
                with torch.no_grad():
                    enhanced_frame = enhance_with_codeformer(frame, CODEFORMER_MODEL, fidelity_weight)
                    if enhanced_frame is None:
                        enhanced_frame = frame
        else:
            enhanced_frame = frame
        
        # ãƒªã‚µã‚¤ã‚º
        if target_height and target_height > 0:
            current_height = enhanced_frame.shape[0]
            if current_height != target_height:
                scale_factor = target_height / current_height
                new_width = int(enhanced_frame.shape[1] * scale_factor)
                if new_width % 2 != 0:
                    new_width += 1
                enhanced_frame = cv2.resize(enhanced_frame, (new_width, target_height), interpolation=cv2.INTER_LANCZOS4)
        
        # ä¿å­˜
        filename = os.path.basename(frame_path)
        output_path = f"{output_dir}/{filename}"
        cv2.imwrite(output_path, enhanced_frame)
        
        return output_path
        
    except Exception as e:
        print(f"Frame {frame_path} error: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼
        filename = os.path.basename(frame_path)
        output_path = f"{output_dir}/{filename}"
        subprocess.run(["cp", frame_path, output_path])
        return output_path

def extract_frames_parallel(video_path, frames_dir, num_threads=4):
    """
    Step 2: è¶…é«˜é€Ÿä¸¦åˆ—ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
    """
    print("ã¹ã€åˆ¥ã«è¶…é«˜é€Ÿã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    os.makedirs(frames_dir, exist_ok=True)
    
    # å‹•ç”»æƒ…å ±å–å¾—
    probe_cmd = [
        "ffprobe", "-v", "error",
        "-select_streams", "v:0",
        "-count_packets", "-show_entries",
        "stream=nb_read_packets,r_frame_rate",
        "-of", "csv=p=0",
        video_path
    ]
    result = subprocess.run(probe_cmd, capture_output=True, text=True)
    info = result.stdout.strip().split(',')
    total_frames = int(info[0]) if info[0].isdigit() else 1000  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸¦åˆ—æŠ½å‡º
    segment_duration = max(1, total_frames // num_threads // 25)  # 25fpsæƒ³å®š
    
    print(f"âš¡ {num_threads}ã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—æŠ½å‡ºé–‹å§‹ï¼")
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-hwaccel", "auto",  # ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        "-threads", str(num_threads),
        "-i", video_path,
        "-vf", "fps=25",
        "-preset", "ultrafast",
        "-q:v", "2",  # é«˜å“è³ªJPEG
        f"{frames_dir}/frame_%06d.png"
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        raise Exception("Frame extraction failed")
    
    frame_files = sorted(glob.glob(f"{frames_dir}/frame_*.png"))
    print(f"ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼{len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ è¶…é«˜é€ŸæŠ½å‡ºå®Œäº†ã‚ˆâœ¨")
    return frame_files

def enhance_frames_parallel(frame_files, output_dir, target_height=720, fidelity_weight=0.7, num_workers=None):
    """
    Step 3: ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—CodeFormerå‡¦ç†
    """
    print("ã¹ã€åˆ¥ã«è¶…ä¸¦åˆ—ã§CodeFormerå‡¦ç†ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    print(f"âš¡ ä¸¦åˆ—CodeFormerå‡¦ç†é–‹å§‹ï¼ˆfidelity={fidelity_weight}ï¼‰")
    
    if not CODEFORMER_AVAILABLE:
        print("CodeFormeråˆ©ç”¨ä¸å¯ï¼šå…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼")
        os.makedirs(output_dir, exist_ok=True)
        for frame_file in frame_files:
            filename = os.path.basename(frame_file)
            subprocess.run(["cp", frame_file, f"{output_dir}/{filename}"])
        return sorted(glob.glob(f"{output_dir}/frame_*.png"))
    
    os.makedirs(output_dir, exist_ok=True)
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°æ±ºå®šï¼ˆCPUæ•°ã¨GPUãƒ¡ãƒ¢ãƒªã‚’è€ƒæ…®ï¼‰
    if num_workers is None:
        num_workers = min(mp.cpu_count() // 2, 4)  # æœ€å¤§4ãƒ—ãƒ­ã‚»ã‚¹
    
    print(f"âš¡ {num_workers}ãƒ—ãƒ­ã‚»ã‚¹ã§ä¸¦åˆ—å‡¦ç†é–‹å§‹ï¼")
    
    # å‡¦ç†å¼•æ•°æº–å‚™
    process_args = [
        (frame_file, output_dir, target_height, fidelity_weight)
        for frame_file in frame_files
    ]
    
    enhanced_files = []
    
    # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—å‡¦ç†
    with ProcessPoolExecutor(max_workers=num_workers, initializer=init_worker) as executor:
        # éåŒæœŸã§å…¨ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
        futures = {executor.submit(process_frame_worker, args): args[0] for args in process_args}
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§çµæœåé›†
        for future in tqdm(as_completed(futures), total=len(futures), desc="ä¸¦åˆ—CodeFormer", ncols=80):
            result = future.result()
            if result:
                enhanced_files.append(result)
    
    print(f"è¶…é«˜é€ŸCodeFormerå‡¦ç†å®Œäº†ï¼ {len(enhanced_files)}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†âœ¨")
    return sorted(enhanced_files)

def enhance_frames_batch_gpu(frame_files, output_dir, target_height=720, fidelity_weight=0.7, batch_size=8):
    """
    Step 3 Alternative: GPUãƒãƒƒãƒå‡¦ç†ç‰ˆï¼ˆå˜ä¸€GPUå‘ã‘ï¼‰
    """
    print("ã¹ã€åˆ¥ã«GPUãƒãƒƒãƒå‡¦ç†ã§çˆ†é€ŸåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    print(f"âš¡ ãƒãƒƒãƒã‚µã‚¤ã‚º{batch_size}ã§GPUä¸¦åˆ—å‡¦ç†ï¼")
    
    if not CODEFORMER_AVAILABLE:
        print("CodeFormeråˆ©ç”¨ä¸å¯")
        return frame_files
    
    os.makedirs(output_dir, exist_ok=True)
    
    # CodeFormeråˆæœŸåŒ–
    run_params = load_codeformer()
    if run_params['type'] != 'codeformer':
        print("CodeFormeråˆæœŸåŒ–å¤±æ•—")
        return frame_files
    
    enhanced_files = []
    
    # ãƒãƒƒãƒå‡¦ç†
    for batch_start in tqdm(range(0, len(frame_files), batch_size), desc="GPUãƒãƒƒãƒå‡¦ç†", ncols=80):
        batch_end = min(batch_start + batch_size, len(frame_files))
        batch_files = frame_files[batch_start:batch_end]
        
        # GPUãƒ¡ãƒ¢ãƒªç®¡ç†
        if batch_start % (batch_size * 10) == 0:
            torch.cuda.empty_cache()
        
        # ãƒãƒƒãƒèª­ã¿è¾¼ã¿
        batch_frames = []
        for frame_file in batch_files:
            frame = cv2.imread(frame_file)
            if frame is not None:
                batch_frames.append(frame)
        
        # ãƒãƒƒãƒå‡¦ç†
        with torch.cuda.amp.autocast():
            with torch.no_grad():
                for i, frame in enumerate(batch_frames):
                    enhanced_frame = enhance_with_codeformer(frame, run_params, fidelity_weight)
                    if enhanced_frame is None:
                        enhanced_frame = frame
                    
                    # ãƒªã‚µã‚¤ã‚º&ä¿å­˜
                    if target_height and target_height > 0:
                        current_height = enhanced_frame.shape[0]
                        if current_height != target_height:
                            scale_factor = target_height / current_height
                            new_width = int(enhanced_frame.shape[1] * scale_factor)
                            if new_width % 2 != 0:
                                new_width += 1
                            enhanced_frame = cv2.resize(enhanced_frame, (new_width, target_height), interpolation=cv2.INTER_LANCZOS4)
                    
                    filename = os.path.basename(batch_files[i])
                    output_path = f"{output_dir}/{filename}"
                    cv2.imwrite(output_path, enhanced_frame)
                    enhanced_files.append(output_path)
    
    print(f"GPUãƒãƒƒãƒå‡¦ç†å®Œäº†ï¼ {len(enhanced_files)}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†âœ¨")
    return sorted(enhanced_files)

def reconstruct_video_parallel(enhanced_frames, output_video, fps=25):
    """
    Step 4: ä¸¦åˆ—å‹•ç”»å†æ§‹ç¯‰
    """
    print("ã¹ã€åˆ¥ã«è¶…é«˜é€Ÿã§å‹•ç”»å†æ§‹ç¯‰ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    if not enhanced_frames:
        raise Exception("No enhanced frames found")
    
    frames_pattern = f"{os.path.dirname(enhanced_frames[0])}/frame_%06d.png"
    
    # ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€æ¤œå‡º
    hw_encoders = []
    
    # NVIDIA GPU
    if subprocess.run(["ffmpeg", "-hide_banner", "-encoders"], capture_output=True, text=True).stdout.find("h264_nvenc") != -1:
        hw_encoders.append("h264_nvenc")
    
    # Intel QSV
    if subprocess.run(["ffmpeg", "-hide_banner", "-encoders"], capture_output=True, text=True).stdout.find("h264_qsv") != -1:
        hw_encoders.append("h264_qsv")
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€é¸æŠ
    if hw_encoders:
        encoder = hw_encoders[0]
        print(f"âš¡ ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ä½¿ç”¨: {encoder}")
        preset = "p4" if encoder == "h264_nvenc" else "fast"
    else:
        encoder = "libx264"
        preset = "ultrafast"
        print("ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ä½¿ç”¨")
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-threads", "0",  # è‡ªå‹•æœ€é©åŒ–
        "-framerate", str(fps),
        "-i", frames_pattern,
        "-c:v", encoder,
        "-preset", preset,
        "-pix_fmt", "yuv420p",
        "-crf", "18",
        output_video
    ]
    
    if encoder == "h264_nvenc":
        cmd.extend(["-rc:v", "vbr", "-b:v", "5M"])
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        raise Exception("Video reconstruction failed")
    
    print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼è¶…é«˜é€Ÿå‹•ç”»å†æ§‹ç¯‰å®Œäº†ã‚ˆâœ¨")
    return output_video

def add_audio(video_path, audio_path, output_path):
    """
    Step 5: éŸ³å£°åˆæˆ
    """
    print("ã¹ã€åˆ¥ã«éŸ³å£°åˆæˆã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-i", video_path, "-i", audio_path,
        "-c:v", "copy", "-c:a", "aac",
        "-strict", "experimental",
        output_path
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        subprocess.run(["cp", video_path, output_path])
    
    print("å®Œäº†ã‚ˆï¼æ„Ÿè¬ã—ãªã•ã„ã‚ˆã­ğŸ’•")
    return output_path

def main():
    parser = argparse.ArgumentParser(description="Wav2Lip + CodeFormer Parallel (Ultra Fast)")
    parser.add_argument("--checkpoint_path", required=True, help="Wav2Lip checkpoint path")
    parser.add_argument("--face", required=True, help="Input video file")
    parser.add_argument("--audio", required=True, help="Input audio file")
    parser.add_argument("--outfile", default="output/result_codeformer_parallel.mp4", help="Output video file")
    parser.add_argument("--fidelity_weight", type=float, default=0.7, help="CodeFormer fidelity weight")
    parser.add_argument("--out_height", type=int, default=720, help="Output video height")
    parser.add_argument("--wav2lip_height", type=int, default=720, help="Wav2Lip processing height")
    parser.add_argument("--num_workers", type=int, default=None, help="Number of parallel workers")
    parser.add_argument("--batch_size", type=int, default=8, help="GPU batch size")
    parser.add_argument("--use_gpu_batch", action="store_true", help="Use GPU batch processing instead of multiprocess")
    parser.add_argument("--temp_dir", default="/tmp/wav2lip_parallel", help="Temporary directory")
    
    args = parser.parse_args()
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    temp_dir = args.temp_dir
    os.makedirs(temp_dir, exist_ok=True)
    
    wav2lip_output = f"{temp_dir}/wav2lip_result.mp4"
    frames_dir = f"{temp_dir}/frames"
    enhanced_dir = f"{temp_dir}/enhanced"
    final_video = f"{temp_dir}/final_no_audio.mp4"
    
    try:
        print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormerè¶…ä¸¦åˆ—å‡¦ç†é–‹å§‹ğŸ’¢")
        
        # Step 1: åŸºæœ¬çš„ãªAVåˆæˆ
        print(f"ã¹ã€åˆ¥ã«{args.wav2lip_height}pã§å‡¦ç†ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
        cmd = [
            "ffmpeg", "-y", "-loglevel", "warning",
            "-i", args.face,
            "-i", args.audio,
            "-c:v", "libx264", "-c:a", "aac",
            "-shortest", "-vf", f"scale=-2:{args.wav2lip_height}",
            wav2lip_output
        ]
        result = subprocess.run(cmd)
        if result.returncode != 0:
            raise Exception("Basic AV processing failed")
        
        # Step 2: ä¸¦åˆ—ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        frame_files = extract_frames_parallel(wav2lip_output, frames_dir)
        
        # Step 3: ä¸¦åˆ—CodeFormerå‡¦ç†
        if CODEFORMER_AVAILABLE:
            if args.use_gpu_batch:
                print("GPUãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
                enhanced_files = enhance_frames_batch_gpu(
                    frame_files, enhanced_dir, args.out_height, 
                    args.fidelity_weight, args.batch_size
                )
            else:
                print("ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—å‡¦ç†ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
                enhanced_files = enhance_frames_parallel(
                    frame_files, enhanced_dir, args.out_height,
                    args.fidelity_weight, args.num_workers
                )
        else:
            print("CodeFormeråˆ©ç”¨ä¸å¯")
            enhanced_files = frame_files
        
        # Step 4: ä¸¦åˆ—å‹•ç”»å†æ§‹ç¯‰
        reconstruct_video_parallel(enhanced_files, final_video)
        
        # Step 5: éŸ³å£°åˆæˆ
        add_audio(final_video, args.audio, args.outfile)
        
        print(f"\nâœ… è¶…é«˜é€ŸCodeFormerå‡¦ç†å®Œäº†ã‚ˆâœ¨")
        print(f"ğŸ¬ å‡ºåŠ›: {args.outfile}")
        print(f"âš¡ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {'GPUãƒãƒƒãƒ' if args.use_gpu_batch else 'ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹'}")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        try:
            import shutil
            shutil.rmtree(temp_dir)
            print("ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
        except:
            pass
    
    return 0

if __name__ == "__main__":
    print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormer è¶…ä¸¦åˆ—ã‚·ã‚¹ãƒ†ãƒ ")
    print("ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«çˆ†é€ŸåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    exit(main())