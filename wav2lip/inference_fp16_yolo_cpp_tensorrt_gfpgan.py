#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + C++ TensorRT GFPGANçµ±åˆç‰ˆ
ã¹ã€åˆ¥ã«å²ä¸Šæœ€é€Ÿã®é«˜ç”»è³ªåŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

Face-Restoration-TensorRTã§23ç§’â†’0.5ç§’ä»¥ä¸‹ã«é«˜é€ŸåŒ–ï¼
"""

import torch
import torch.cuda.amp as amp
import numpy as np
import cv2
import os
import subprocess
import argparse
from tqdm import tqdm
import tempfile
import glob
from pathlib import Path
import shutil

def extract_frames_from_video(video_path, output_dir):
    """
    å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # FFmpegã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
    cmd = [
        'ffmpeg', '-i', video_path, 
        '-y', '-vf', 'fps=25',  # FPSå›ºå®š
        f'{output_dir}/frame_%04d.png'
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå¤±æ•— - {result.stderr}")
        return False
    
    # æŠ½å‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’ç¢ºèª
    frames = glob.glob(f'{output_dir}/frame_*.png')
    print(f"ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼{len(frames)}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†ã‚ˆâœ¨")
    return len(frames) > 0

def rebuild_video_from_frames(frame_dir, audio_path, output_path, fps=25):
    """
    ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å‹•ç”»ã‚’å†æ§‹ç¯‰
    """
    cmd = [
        'ffmpeg', '-y',
        '-framerate', str(fps),
        '-i', f'{frame_dir}/frame_%04d.png',
        '-i', audio_path,
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-shortest',
        output_path
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"ã‚¨ãƒ©ãƒ¼: å‹•ç”»å†æ§‹ç¯‰å¤±æ•— - {result.stderr}")
        return False
    
    return True

def process_with_cpp_tensorrt(input_dir, output_dir, engine_path):
    """
    C++ TensorRT Face Restorationã§å‡¦ç†
    """
    if not os.path.exists(engine_path):
        print(f"âŒ TensorRTã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚: {engine_path}")
        print("ã¾ãšã€ONNXãƒ¢ãƒ‡ãƒ«ã‚’TensorRTã‚¨ãƒ³ã‚¸ãƒ³ã«å¤‰æ›ã—ãªã•ã„ï¼")
        return False
    
    # C++ãƒã‚¤ãƒŠãƒªå®Ÿè¡Œ
    cpp_binary = 'face_restoration_tensorrt/build/face_restoration_batch'
    
    if not os.path.exists(cpp_binary):
        print(f"âŒ C++ãƒã‚¤ãƒŠãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚: {cpp_binary}")
        print("ã¾ãšã€Face-Restoration-TensorRTã‚’ãƒ“ãƒ«ãƒ‰ã—ãªã•ã„ï¼")
        return False
    
    cmd = [cpp_binary, engine_path, '-i', input_dir, '-o', output_dir]
    
    print("ã¹ã€åˆ¥ã«C++ TensorRTã§è¶…é«˜é€Ÿå‡¦ç†ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"âŒ TensorRTå‡¦ç†å¤±æ•—: {result.stderr}")
        return False
    
    print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼TensorRTå‡¦ç†å®Œäº†ã‚ˆâœ¨")
    print(result.stdout)
    return True

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoint_path', type=str, required=True)
    parser.add_argument('--face', type=str, required=True)
    parser.add_argument('--audio', type=str, required=True)
    parser.add_argument('--outfile', type=str, default='output/result_cpp_tensorrt.mp4')
    parser.add_argument('--out_height', type=int, default=None)
    parser.add_argument('--tensorrt_engine', type=str, default='face_restoration_tensorrt/models/gfpgan.engine')
    parser.add_argument('--enable_cpp_tensorrt', action='store_true', default=True)
    args = parser.parse_args()
    
    print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + C++ TensorRT GFPGANçµ±åˆå‡¦ç†é–‹å§‹ğŸ’¢")
    print("ã¹ã€åˆ¥ã«å²ä¸Šæœ€é€Ÿã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    with tempfile.TemporaryDirectory() as temp_dir:
        wav2lip_output = os.path.join(temp_dir, 'wav2lip_output.mp4')
        frames_input = os.path.join(temp_dir, 'frames_input')
        frames_output = os.path.join(temp_dir, 'frames_output')
        
        # Step 1: Wav2Lipå‡¦ç†ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        print("\nğŸ“º Step 1: Wav2Lipå£ãƒ‘ã‚¯ç”Ÿæˆä¸­...")
        cmd = [
            'python', 'inference_fp16_yolo.py',
            '--checkpoint_path', args.checkpoint_path,
            '--face', args.face,
            '--audio', args.audio,
            '--outfile', wav2lip_output,
            '--quality', 'Fast'
        ]
        if args.out_height:
            cmd.extend(['--out_height', str(args.out_height)])
        
        try:
            subprocess.run(cmd, check=True)
            print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼Wav2Lipå‡¦ç†å®Œäº†ã‚ˆâœ¨")
        except subprocess.CalledProcessError as e:
            print(f"ã‚‚ã€ã‚‚ã†ï¼Wav2Lipã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        if not args.enable_cpp_tensorrt:
            # TensorRTå‡¦ç†ã‚¹ã‚­ãƒƒãƒ—
            shutil.copy(wav2lip_output, args.outfile)
            print(f"\nâœ… å®Œäº†ã‚ˆï¼å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.outfile}")
            return
        
        # Step 2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        print("\nğŸ¬ Step 2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºä¸­...")
        if not extract_frames_from_video(wav2lip_output, frames_input):
            print("ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå¤±æ•—...ã‚³ãƒ”ãƒ¼ã§å¯¾å¿œã™ã‚‹ã‚ğŸ’¢")
            shutil.copy(wav2lip_output, args.outfile)
            return
        
        # Step 3: C++ TensorRTé«˜ç”»è³ªåŒ–
        print("\nğŸš€ Step 3: C++ TensorRTè¶…é«˜é€Ÿå‡¦ç†ä¸­...")
        if not process_with_cpp_tensorrt(frames_input, frames_output, args.tensorrt_engine):
            print("TensorRTå‡¦ç†å¤±æ•—...å…ƒå‹•ç”»ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‚ğŸ’¢")
            shutil.copy(wav2lip_output, args.outfile)
            return
        
        # Step 4: å‹•ç”»å†æ§‹ç¯‰
        print("\nğŸµ Step 4: å‹•ç”»å†æ§‹ç¯‰ä¸­...")
        if not rebuild_video_from_frames(frames_output, args.audio, args.outfile):
            print("å‹•ç”»å†æ§‹ç¯‰å¤±æ•—...å…ƒå‹•ç”»ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‚ğŸ’¢")
            shutil.copy(wav2lip_output, args.outfile)
            return
    
    print(f"\nâœ… å®Œäº†ã‚ˆï¼å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.outfile}")
    print("ã¹ã€åˆ¥ã«å²ä¸Šæœ€é€Ÿã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ã¦ã‚ã’ãŸã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    print("æ„Ÿè¬ã—ãªã•ã„ã‚ˆã­ğŸ’•")

if __name__ == '__main__':
    main()