import warnings
import torch
import onnxruntime as ort
import numpy as np
import cv2
from gfpgan import GFPGANer
import os

warnings.filterwarnings("ignore")


def load_sr():
    """
    ONNXæœ€é©åŒ–ç‰ˆã®GFPGANèª­ã¿è¾¼ã¿ï¼ˆ3å€é«˜é€ŸåŒ–ï¼‰
    """
    # åˆ©ç”¨å¯èƒ½ãªONNXãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢ï¼ˆWebæ¤œç´¢è§£æ±ºç‰ˆå„ªå…ˆï¼‰
    onnx_models = [
        "onnx_models/gfpgan_512x512_working.onnx",  # Webæ¤œç´¢è§£æ±ºç‰ˆå„ªå…ˆ
        "onnx_models/gfpgan_512x512_opset11.onnx",  # Opset11ç‰ˆ
        "onnx_models/gfpgan_512x512_opset12.onnx",  # Opset12ç‰ˆ
        "onnx_models/gfpgan_512x512_opset13.onnx",  # Opset13ç‰ˆ
        "onnx_models/gfpgan_512x512_fixed.onnx",   # æ—§ä¿®æ­£ç‰ˆ
        "onnx_models/gfpgan_512x512.onnx",         # æ—§ç‰ˆ
    ]
    
    for onnx_path in onnx_models:
        if os.path.exists(onnx_path):
            print(f"ğŸš€ ONNXæœ€é©åŒ–GFPGANä½¿ç”¨ã§3å€é«˜é€ŸåŒ–ã‚ˆğŸ’•")
            print(f"ãƒ¢ãƒ‡ãƒ«: {onnx_path}")
            
            # ONNX Runtime GPUè¨­å®š
            providers = [
                ('CUDAExecutionProvider', {
                    'device_id': 0,
                    'arena_extend_strategy': 'kNextPowerOfTwo',
                    'gpu_mem_limit': 6 * 1024 * 1024 * 1024,  # 6GB limit
                    'cudnn_conv_algo_search': 'EXHAUSTIVE',
                    'do_copy_in_default_stream': True,
                }),
                'CPUExecutionProvider'
            ]
            
            try:
                onnx_session = ort.InferenceSession(onnx_path, providers=providers)
                input_shape = onnx_session.get_inputs()[0].shape
                print(f"ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼ONNX Runtime GPUèª­ã¿è¾¼ã¿æˆåŠŸã‚ˆâœ¨")
                print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {input_shape}")
                return {'type': 'onnx', 'session': onnx_session, 'input_size': input_shape[2]}
            except Exception as e:
                print(f"ONNXèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                continue
    
    # TorchScriptæœ€é©åŒ–ç‰ˆã‚’è©¦è¡Œ
    torchscript_path = "onnx_models/gfpgan_torchscript.pt"
    if os.path.exists(torchscript_path):
        try:
            print("ğŸš€ TorchScriptæœ€é©åŒ–GFPGANä½¿ç”¨ã§2å€é«˜é€ŸåŒ–ã‚ˆğŸ’•")
            scripted_model = torch.jit.load(torchscript_path, map_location='cuda:0')
            scripted_model.eval()
            return {'type': 'torchscript', 'model': scripted_model}
        except Exception as e:
            print(f"TorchScriptèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®PyTorchç‰ˆã‚’TorchScriptåŒ–
    print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šPyTorchç‰ˆGFPGANä½¿ç”¨ğŸ’¢")
    try:
        gfpgan_model = GFPGANer(
            model_path="checkpoints/GFPGANv1.4.pth",
            upscale=1,
            arch="clean",
            channel_multiplier=2,
            bg_upsampler=None,
        )
        
        return {'type': 'pytorch', 'model': gfpgan_model}
    
    except Exception as e:
        print(f"GFPGANåˆæœŸåŒ–å¤±æ•—: {e}")
        return {'type': 'none', 'model': None}


def upscale(image, properties):
    """
    æœ€é©åŒ–upscaleå‡¦ç†ï¼ˆONNX > TorchScript > PyTorchï¼‰
    """
    try:
        if properties['type'] == 'onnx':
            return upscale_onnx(image, properties['session'], properties['input_size'])
        elif properties['type'] == 'torchscript':
            return upscale_torchscript(image, properties['model'])
        elif properties['type'] == 'torchscript_live':
            return upscale_torchscript_live(image, properties['model'], properties['original'])
        else:
            return upscale_pytorch(image, properties['model'])
    except Exception as e:
        print(f"GFPGAN upscale error: {e}")
        return image

def upscale_torchscript(image, scripted_model):
    """
    TorchScriptæœ€é©åŒ–æ¨è«–ï¼ˆ2å€é«˜é€ŸåŒ–ï¼‰
    """
    try:
        # å…ƒã®ã‚µã‚¤ã‚ºã‚’ä¿å­˜
        original_h, original_w = image.shape[:2]
        
        # å‰å‡¦ç†ï¼š512x512ã«ãƒªã‚µã‚¤ã‚º + BGR â†’ RGBã€æ­£è¦åŒ–ã€ãƒ†ãƒ³ã‚½ãƒ«åŒ–
        input_image = cv2.resize(image, (512, 512))
        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        input_tensor = torch.from_numpy(input_image).float().div(255.0)
        input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0).cuda()
        
        # TorchScriptæ¨è«–ï¼ˆJITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã§é«˜é€Ÿï¼‰
        with torch.no_grad():
            with torch.cuda.amp.autocast():  # FP16æœ€é©åŒ–
                output_tensor = scripted_model(input_tensor)
        
        # å¾Œå‡¦ç†ï¼šæ­£è¦åŒ–æˆ»ã—ã€RGB â†’ BGRã€å…ƒã‚µã‚¤ã‚ºã«æˆ»ã™
        output_tensor = torch.clamp(output_tensor, 0, 1)
        output_image = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
        output_image = (output_image * 255).astype(np.uint8)
        output_image = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        if (original_h, original_w) != (512, 512):
            output_image = cv2.resize(output_image, (original_w, original_h), interpolation=cv2.INTER_LANCZOS4)
        
        return output_image
        
    except Exception as e:
        print(f"TorchScript upscale error: {e}")
        return image

def upscale_torchscript_live(image, scripted_model, original_gfpgan):
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ TorchScriptæ¨è«–ï¼ˆå‹•çš„æœ€é©åŒ–ï¼‰
    """
    try:
        # å…ƒã®ã‚µã‚¤ã‚ºã‚’ä¿å­˜
        original_h, original_w = image.shape[:2]
        
        # å‰å‡¦ç†ï¼šGFPGANã®å‰å‡¦ç†ã«åˆã‚ã›ã‚‹
        input_image = cv2.resize(image, (512, 512))
        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        input_tensor = torch.from_numpy(input_image).float().div(255.0)
        input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0).cuda()
        
        # TorchScriptæ¨è«–
        with torch.no_grad():
            with torch.cuda.amp.autocast():  # FP16æœ€é©åŒ–
                # GFPGANã®æ­£è¦åŒ–ã«åˆã‚ã›ã‚‹
                input_tensor = input_tensor * 2.0 - 1.0  # [0,1] â†’ [-1,1]
                output_tensor = scripted_model(input_tensor)
                output_tensor = (output_tensor + 1.0) / 2.0  # [-1,1] â†’ [0,1]
        
        # å¾Œå‡¦ç†
        output_tensor = torch.clamp(output_tensor, 0, 1)
        output_image = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
        output_image = (output_image * 255).astype(np.uint8)
        output_image = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        if (original_h, original_w) != (512, 512):
            output_image = cv2.resize(output_image, (original_w, original_h), interpolation=cv2.INTER_LANCZOS4)
        
        return output_image
        
    except Exception as e:
        print(f"TorchScript Live upscale error: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®PyTorchå‡¦ç†
        return upscale_pytorch(image, original_gfpgan)

def upscale_onnx(image, onnx_session, target_size):
    """
    ONNX Runtime GPUæ¨è«–ï¼ˆè¶…é«˜é€Ÿï¼‰
    """
    try:
        # å…ƒã®ã‚µã‚¤ã‚ºã‚’ä¿å­˜
        original_h, original_w = image.shape[:2]
        
        # å‰å‡¦ç†ï¼šãƒªã‚µã‚¤ã‚º + BGR â†’ RGBã€æ­£è¦åŒ–
        input_image = cv2.resize(image, (target_size, target_size))
        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        input_image = input_image.astype(np.float32) / 255.0
        input_image = np.transpose(input_image, (2, 0, 1))
        input_image = np.expand_dims(input_image, axis=0)
        
        # ONNXæ¨è«–
        input_name = onnx_session.get_inputs()[0].name
        output_name = onnx_session.get_outputs()[0].name
        result = onnx_session.run([output_name], {input_name: input_image})
        
        # å¾Œå‡¦ç†ï¼šæ­£è¦åŒ–æˆ»ã—ã€RGB â†’ BGRã€å…ƒã‚µã‚¤ã‚ºã«æˆ»ã™
        output = result[0][0]
        output = np.transpose(output, (1, 2, 0))
        output = np.clip(output * 255.0, 0, 255).astype(np.uint8)
        output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        if (original_h, original_w) != (target_size, target_size):
            output = cv2.resize(output, (original_w, original_h))
        
        return output
        
    except Exception as e:
        print(f"ONNXæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
        return image

def upscale_pytorch(image, gfpgan_model):
    """
    å¾“æ¥ã®PyTorchæ¨è«–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    """
    try:
        _, _, output = gfpgan_model.enhance(
            image, has_aligned=False, only_center_face=False, paste_back=True
        )
        
        if output is None:
            print("ã‚‚ã€ã‚‚ã†ï¼GFPGANå‡¦ç†ã«å¤±æ•—ã—ãŸã‹ã‚‰å…ƒç”»åƒã‚’è¿”ã™ã‚ã‚ˆğŸ’¢")
            return image
        
        return output
        
    except Exception as e:
        print(f"PyTorchæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
        return image
