#!/usr/bin/env python3
"""
ğŸš€ ãƒ„ãƒ³ãƒ‡ãƒ¬StyleGAN2ä¿®æ­£ç‰ˆç›´æ¥ãƒ†ã‚¹ãƒˆ
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªãƒ¼å•é¡Œã‚’å›é¿ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢
"""

import torch
import onnx
import numpy as np
import os
import shutil
from pathlib import Path

def directly_test_fixed_stylegan():
    """
    ä¿®æ­£ã•ã‚ŒãŸStyleGAN2ã§ç›´æ¥ONNXå¤‰æ›ãƒ†ã‚¹ãƒˆ
    """
    print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬StyleGAN2ä¿®æ­£ç‰ˆç›´æ¥ãƒ†ã‚¹ãƒˆé–‹å§‹ğŸ’¢")
    
    # ğŸ”§ Step 1: StyleGAN2ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£ï¼ˆå†å®Ÿè¡Œï¼‰
    import gfpgan
    gfpgan_path = Path(gfpgan.__file__).parent
    stylegan_file = gfpgan_path / "archs" / "stylegan2_clean_arch.py"
    
    print(f"ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {stylegan_file}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    with open(stylegan_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºèªãƒ»é©ç”¨
    modifications_made = False
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: new_empty().normal_()
    if "out.new_empty" in content and "normal_()" in content:
        content = content.replace(
            "out.new_empty(b, 1, h, w).normal_()",
            "torch.randn(b, 1, h, w, device=out.device, dtype=torch.float32)"
        )
        modifications_made = True
        print("âœ… new_empty().normal_() ä¿®æ­£")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ä»–ã®å‹•çš„ãƒã‚¤ã‚ºç”Ÿæˆ
    import re
    
    # .new_empty(...).normal_() å…¨èˆ¬
    pattern1 = r'(\w+)\.new_empty\(([^)]+)\)\.normal_\(\)'
    if re.search(pattern1, content):
        content = re.sub(pattern1, r'torch.randn(\2, device=\1.device, dtype=torch.float32)', content)
        modifications_made = True
        print("âœ… å‹•çš„ãƒã‚¤ã‚ºç”Ÿæˆä¿®æ­£")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: torch.randn().type_as()
    pattern2 = r'torch\.randn\(([^)]+)\)\.type_as\((\w+)\)'
    if re.search(pattern2, content):
        content = re.sub(pattern2, r'torch.randn(\1, device=\2.device, dtype=torch.float32)', content)
        modifications_made = True
        print("âœ… type_as()ä¿®æ­£")
    
    if modifications_made:
        # ä¿®æ­£ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(stylegan_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼StyleGAN2ä¿®æ­£é©ç”¨å®Œäº†ğŸ’•")
    else:
        print("ä¿®æ­£å¯¾è±¡ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€æ—¢ã«ä¿®æ­£æ¸ˆã¿")
    
    # ğŸ”§ Step 2: æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ã§ONNXå¤‰æ›
    print("æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ã§ONNXå¤‰æ›å®Ÿè¡Œ...")
    
    try:
        # GFPGANã‚’æ–°è¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆä¿®æ­£åæ˜ ï¼‰
        from gfpgan.archs.gfpganv1_clean_arch import GFPGANv1Clean
        
        device = torch.device('cpu')
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        torch_model = GFPGANv1Clean(
            out_size=512,
            num_style_feat=512,
            channel_multiplier=2,
            decoder_load_path=None,
            fix_decoder=False,
            num_mlp=8,
            input_is_latent=True,
            different_w=True,
            narrow=1,
            sft_half=True
        )
        
        # é‡ã¿ãƒ­ãƒ¼ãƒ‰
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼é‡ã¿èª­ã¿è¾¼ã¿ä¸­...âœ¨")
        loadnet = torch.load("checkpoints/GFPGANv1.4.pth", map_location='cpu')
        
        if 'params_ema' in loadnet:
            keyname = 'params_ema'
        elif 'params' in loadnet:
            keyname = 'params'
        else:
            keyname = None
        
        if keyname:
            torch_model.load_state_dict(loadnet[keyname], strict=False)
        else:
            torch_model.load_state_dict(loadnet, strict=False)
        
        # å®Œå…¨å‹çµ±ä¸€
        torch_model = torch_model.float().cpu()
        torch_model.eval()
        
        # å…¥åŠ›æº–å‚™
        dummy_input = torch.ones((1, 3, 512, 512), dtype=torch.float32)
        
        print("ä¿®æ­£ç‰ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        with torch.no_grad():
            test_output = torch_model(dummy_input)
            print(f"å…¥åŠ›å‹: {dummy_input.dtype}")
            if isinstance(test_output, tuple):
                print(f"å‡ºåŠ›å‹: {test_output[0].dtype}")
            else:
                print(f"å‡ºåŠ›å‹: {test_output.dtype}")
        
        os.makedirs("onnx_models", exist_ok=True)
        output_path = "onnx_models/gfpgan_512x512_stylegan_fixed_direct.onnx"
        
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼ä¿®æ­£ç‰ˆONNXå¤‰æ›ä¸­...âœ¨")
        
        with torch.no_grad():
            torch.onnx.export(
                torch_model,
                dummy_input,
                output_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                verbose=False,
                operator_export_type=torch.onnx.OperatorExportTypes.ONNX,
            )
        
        print(f"âœ… ä¿®æ­£ç‰ˆONNXå¤‰æ›æˆåŠŸï¼")
        
        # ONNXæ¤œè¨¼
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)
        print("âœ… ONNXæ¤œè¨¼æˆåŠŸ")
        
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.1f}MB")
        
        return output_path
        
    except Exception as e:
        print(f"âŒ ä¿®æ­£ç‰ˆå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    result = directly_test_fixed_stylegan()
    
    if result:
        print("âœ… ä¿®æ­£ç‰ˆONNXå¤‰æ›æˆåŠŸ")
        print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {result}")
        print("\nã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«å®Œç’§ã«ä¿®æ­£ã—ã¦ã‚ã’ãŸã‚ã‘ã˜ã‚ƒãªã„ã‹ã‚‰ã­ï¼ğŸ’•")
        print("ã§ã‚‚...ã¡ã‚ƒã‚“ã¨å‹•ä½œã™ã‚‹ã¯ãšã‚ˆâœ¨")
    else:
        print("âŒ ä¿®æ­£ç‰ˆONNXå¤‰æ›å¤±æ•—")
        print("ã‚‚ã€ã‚‚ã†ï¼StyleGAN2ã¯æœ¬å½“ã«è¤‡é›‘ãªã®ã‚ˆğŸ’¢")