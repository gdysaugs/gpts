#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬è™¹è‰²å‹•ç”»ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«è‰²ç©ºé–“ãƒã‚°ã‚’ç›´ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‚“ã ã‹ã‚‰ã­ï¼ğŸ’¢

YUV/RGBè‰²ç©ºé–“å¤‰æ›å•é¡Œã¨ONNXå‡¦ç†ã«ã‚ˆã‚‹è‰²ç©ºé–“ç ´æã‚’ä¿®æ­£
"""

import cv2
import numpy as np
import subprocess
import os
import argparse

def fix_colorspace_opencv(input_video, output_video):
    """OpenCVã‚’ä½¿ç”¨ã—ãŸè‰²ç©ºé–“ä¿®æ­£"""
    print("ã¹ã€åˆ¥ã«OpenCVã§è‰²ç©ºé–“ã‚’ä¿®æ­£ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    cap = cv2.VideoCapture(input_video)
    if not cap.isOpened():
        print(f"âŒ å‹•ç”»ãŒé–‹ã‘ãªã„ã˜ã‚ƒãªã„: {input_video}")
        return False
    
    # å‹•ç”»æƒ…å ±å–å¾—
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"ğŸ“Š å‹•ç”»æƒ…å ±: {width}x{height}, {fps}fps, {frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
    
    # å‡ºåŠ›è¨­å®š
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))
    
    print("è‰²ç©ºé–“ä¿®æ­£ä¸­...")
    
    for i in range(frame_count):
        ret, frame = cap.read()
        if not ret:
            break
        
        # è‰²ç©ºé–“ä¿®æ­£ã®ãƒˆãƒªãƒƒã‚¯
        # 1. YUVã¨ã—ã¦èª­ã¿è¾¼ã¾ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’RGBã«å¤‰æ›
        if frame.shape[2] == 3:  # BGRç”»åƒã®å ´åˆ
            # ç•°å¸¸ãªè‰²åˆã„ã®å ´åˆã¯è‰²ãƒãƒ£ãƒ³ãƒãƒ«ã‚’äº¤æ›
            b, g, r = cv2.split(frame)
            
            # è™¹è‰²å•é¡Œï¼šé€šå¸¸ã¯BGRâ†’RGBã®é †åºå•é¡Œ
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: BGR â†’ RGB
            frame_rgb = cv2.merge([r, g, b])
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: è‰²ãƒãƒ£ãƒ³ãƒãƒ«å…¥ã‚Œæ›¿ãˆï¼ˆè™¹è‰²ä¿®æ­£ï¼‰
            # é’ã¨èµ¤ãŒå…¥ã‚Œæ›¿ã‚ã£ã¦ã‚‹å ´åˆãŒå¤šã„
            frame_fixed = cv2.merge([b, g, r])  # å…ƒã«æˆ»ã™
            
            # ã‚ˆã‚Šé«˜åº¦ãªä¿®æ­£: YUV â†’ RGBå¤‰æ›ã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£
            try:
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã®å€¤ç¯„å›²ã‚’ç¢ºèª
                frame_mean = np.mean(frame)
                if frame_mean > 128:  # æ˜ã‚‹ã™ãã‚‹å ´åˆ
                    frame = np.clip(frame * 0.8, 0, 255).astype(np.uint8)
                
                # è‰²ã®å½©åº¦ã‚’æ­£å¸¸åŒ–
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 0.7, 0, 255)  # å½©åº¦ã‚’ä¸‹ã’ã‚‹
                frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                
            except:
                pass  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨
        
        out.write(frame)
    
    cap.release()
    out.release()
    
    print(f"âœ… OpenCVä¿®æ­£å®Œäº†: {output_video}")
    return True

def fix_colorspace_ffmpeg(input_video, output_video):
    """FFmpegã‚’ä½¿ç”¨ã—ãŸè‰²ç©ºé–“ä¿®æ­£"""
    print("ã¹ã€åˆ¥ã«FFmpegã§è‰²ç©ºé–“ã‚’ä¿®æ­£ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    # è¤‡æ•°ã®ä¿®æ­£æ–¹æ³•ã‚’è©¦è¡Œ
    fix_commands = [
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: åŸºæœ¬çš„ãªè‰²ç©ºé–“å¤‰æ›
        [
            "ffmpeg", "-y", "-i", input_video,
            "-vf", "colorspace=bt709:iall=bt601-6-625:fast=1",
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "copy", output_video
        ],
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: YUV420på¼·åˆ¶ + è‰²è£œæ­£
        [
            "ffmpeg", "-y", "-i", input_video,
            "-vf", "format=yuv420p,eq=contrast=0.9:brightness=0.05:saturation=0.8",
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "copy", output_video
        ],
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: RGB24å¼·åˆ¶ + å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        [
            "ffmpeg", "-y", "-i", input_video,
            "-vf", "format=rgb24,format=yuv420p",
            "-c:v", "libx264", "-preset", "fast", "-crf", "18",
            "-c:a", "copy", output_video
        ]
    ]
    
    for i, cmd in enumerate(fix_commands, 1):
        print(f"ğŸ”§ ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ {i} è©¦è¡Œä¸­...")
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… FFmpegä¿®æ­£æˆåŠŸ (ãƒ‘ã‚¿ãƒ¼ãƒ³ {i}): {output_video}")
                return True
            else:
                print(f"âš ï¸ ãƒ‘ã‚¿ãƒ¼ãƒ³ {i} å¤±æ•—: {result.stderr}")
        except Exception as e:
            print(f"âŒ ãƒ‘ã‚¿ãƒ¼ãƒ³ {i} ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("âŒ FFmpegä¿®æ­£å¤±æ•—")
    return False

def analyze_video_colorspace(video_path):
    """å‹•ç”»ã®è‰²ç©ºé–“æƒ…å ±ã‚’åˆ†æ"""
    print(f"ğŸ“Š å‹•ç”»åˆ†æä¸­: {video_path}")
    
    cmd = [
        "ffprobe", "-v", "quiet", "-show_entries", 
        "stream=color_space,color_primaries,color_transfer,pix_fmt",
        "-of", "csv=p=0", video_path
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"ğŸ” è‰²ç©ºé–“æƒ…å ±: {result.stdout.strip()}")
        else:
            print("âš ï¸ è‰²ç©ºé–“æƒ…å ±å–å¾—å¤±æ•—")
    except:
        print("âŒ ffprobeå®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
    
    # OpenCVã§ã‚‚ç¢ºèª
    cap = cv2.VideoCapture(video_path)
    if cap.isOpened():
        ret, frame = cap.read()
        if ret:
            print(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ å½¢çŠ¶: {frame.shape}")
            print(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ å€¤ç¯„å›²: {frame.min()}-{frame.max()}")
            print(f"ğŸ“Š å¹³å‡å€¤: R={frame[:,:,2].mean():.1f}, G={frame[:,:,1].mean():.1f}, B={frame[:,:,0].mean():.1f}")
        cap.release()

def main():
    parser = argparse.ArgumentParser(description="ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬è™¹è‰²å‹•ç”»ä¿®æ­£")
    parser.add_argument("--input", type=str, required=True, help="å…¥åŠ›å‹•ç”»")
    parser.add_argument("--output", type=str, help="å‡ºåŠ›å‹•ç”»")
    parser.add_argument("--method", type=str, default="ffmpeg", 
                       choices=["ffmpeg", "opencv", "both"], help="ä¿®æ­£æ–¹æ³•")
    parser.add_argument("--analyze", action="store_true", help="è‰²ç©ºé–“åˆ†æã®ã¿")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {args.input}")
        return
    
    if args.analyze:
        analyze_video_colorspace(args.input)
        return
    
    if not args.output:
        base_name = os.path.splitext(args.input)[0]
        args.output = f"{base_name}_fixed.mp4"
    
    print("ãµã‚“ï¼è™¹è‰²å‹•ç”»ä¿®æ­£é–‹å§‹ã‚ˆ...ğŸ’•")
    
    # åˆ†æ
    analyze_video_colorspace(args.input)
    
    success = False
    
    if args.method in ["ffmpeg", "both"]:
        success = fix_colorspace_ffmpeg(args.input, args.output)
    
    if not success and args.method in ["opencv", "both"]:
        success = fix_colorspace_opencv(args.input, args.output)
    
    if success:
        print(f"âœ¨ ä¿®æ­£å®Œäº†ï¼æ„Ÿè¬ã—ãªã•ã„ã‚ˆã­ğŸ’•")
        print(f"ğŸ“ å‡ºåŠ›: {args.output}")
        
        # ä¿®æ­£å¾Œã®ç¢ºèª
        print("\nä¿®æ­£å¾Œã®åˆ†æ:")
        analyze_video_colorspace(args.output)
    else:
        print("ã‚‚ã€ã‚‚ã†ï¼ä¿®æ­£ã«å¤±æ•—ã—ãŸã‚ã‚ˆğŸ’¢")

if __name__ == "__main__":
    main()