#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬CodeFormer é«˜é€Ÿçµ±åˆç‰ˆ
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«CodeFormerã‚’å®Ÿè£…ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

CodeFormerã‚’ä½¿ç”¨ã—ãŸé¡”ç”»è³ªå‘ä¸Šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
langzizhixin/Wav2Lip-CodeFormer ã¨ sczhou/CodeFormer ã‚’å‚è€ƒã«ã—ãŸå®Ÿè£…
"""

import warnings
import torch
import torch.nn as nn
import torch.nn.functional as F
import onnxruntime as ort
import numpy as np
import cv2
import os
import sys
import math
from pathlib import Path
from typing import Optional, Tuple

warnings.filterwarnings("ignore")


# CodeFormeré–¢é€£ã®import
try:
    from basicsr.utils import imwrite, img2tensor, tensor2img
    from basicsr.utils.download_util import load_file_from_url
    from basicsr.utils.registry import ARCH_REGISTRY
    from facelib.utils.face_restoration_helper import FaceRestoreHelper
    from facelib.utils.misc import is_gray
    
    # gpu_is_availableãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ä»£æ›¿
    try:
        from basicsr.utils.misc import gpu_is_available, get_device
    except ImportError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼štorchç‰ˆã‚’ä½¿ç”¨
        def gpu_is_available():
            return torch.cuda.is_available()
        
        def get_device():
            return torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    CODEFORMER_AVAILABLE = True
    print("ğŸš€ CodeFormerä¾å­˜é–¢ä¿‚OKï¼")
except ImportError as e:
    print(f"âŒ CodeFormerä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {e}")
    try:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šGFPGANã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from gfpgan import GFPGANer
        GFPGAN_AVAILABLE = True
        CODEFORMER_AVAILABLE = False
        print("ğŸš€ GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ©ç”¨å¯èƒ½")
    except ImportError:
        CODEFORMER_AVAILABLE = False
        GFPGAN_AVAILABLE = False
        print("âŒ CodeFormer/GFPGANä¸¡æ–¹ãŒåˆ©ç”¨ä¸å¯")

# CodeFormerãƒ¢ãƒ‡ãƒ«URL
pretrain_model_url = {
    'restoration': 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth'
}

def load_codeformer():
    """
    CodeFormerãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆGPUæœ€é©åŒ–ï¼‰
    """
    if not CODEFORMER_AVAILABLE:
        print("âŒ CodeFormeråˆ©ç”¨ä¸å¯ï¼šä¾å­˜é–¢ä¿‚ãŒä¸è¶³")
        # GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œ
        if 'GFPGAN_AVAILABLE' in globals() and GFPGAN_AVAILABLE:
            return load_gfpgan_fallback()
        return {'type': 'none', 'model': None}
    
    try:
        print("ğŸš€ CodeFormeråˆæœŸåŒ–ä¸­...ï¼ˆGPUæœ€é©åŒ–ï¼‰ğŸ’•")
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        device = get_device()
        print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")
        
        # CodeFormerãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–
        net = ARCH_REGISTRY.get('CodeFormer')(
            dim_embd=512, 
            codebook_size=1024, 
            n_head=8, 
            n_layers=9, 
            connect_list=['32', '64', '128', '256']
        ).to(device)
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰/ãƒ­ãƒ¼ãƒ‰
        model_dir = '/app/checkpoints/CodeFormer'
        os.makedirs(model_dir, exist_ok=True)
        
        ckpt_path = load_file_from_url(
            url=pretrain_model_url['restoration'], 
            model_dir=model_dir, 
            progress=True,
            file_name='codeformer.pth'
        )
        
        if not os.path.exists(ckpt_path):
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹
            fallback_paths = [
                '/app/checkpoints/CodeFormer/codeformer.pth',
                '/app/checkpoints/codeformer.pth',
                '/app/models/CodeFormer/codeformer.pth',
                'checkpoints/CodeFormer/codeformer.pth',
                'checkpoints/codeformer.pth',
                'models/CodeFormer/codeformer.pth'
            ]
            for path in fallback_paths:
                if os.path.exists(path):
                    ckpt_path = path
                    break
            else:
                print("âŒ CodeFormerãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                return load_gfpgan_fallback()
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        checkpoint = torch.load(ckpt_path, map_location=device)
        net.load_state_dict(checkpoint['params_ema'])
        net.eval()
        
        # é¡”æ¤œå‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼åˆæœŸåŒ–ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰ï¼‰
        face_helper = FaceRestoreHelper(
            upscale_factor=1,
            face_size=512,
            crop_ratio=(1, 1),
            det_model='retinaface_resnet50',
            save_ext='png',
            use_parse=True,
            device=device
        )
        
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼CodeFormeråˆæœŸåŒ–å®Œäº†ã‚ˆâœ¨")
        
        return {
            'type': 'codeformer',
            'model': net,
            'face_helper': face_helper,
            'device': device
        }
        
    except Exception as e:
        print(f"âŒ CodeFormeråˆæœŸåŒ–å¤±æ•—: {e}")
        print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šGFPGANä½¿ç”¨")
        return load_gfpgan_fallback()

def load_gfpgan_fallback():
    """
    GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–
    """
    try:
        from gfpgan import GFPGANer
        print("ğŸš€ GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–ä¸­...ğŸ’¢")
        
        gfpgan_model = GFPGANer(
            model_path="/app/checkpoints/GFPGANv1.4.pth",
            upscale=1,
            arch="clean",
            channel_multiplier=2,
            bg_upsampler=None,
        )
        
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸã‚ˆâœ¨")
        return {'type': 'gfpgan_fallback', 'model': gfpgan_model}
        
    except Exception as e:
        print(f"âŒ GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: {e}")
        print("ã‚‚ã€ã‚‚ã†ï¼ã©ã¡ã‚‰ã‚‚ä½¿ãˆãªã„ã˜ã‚ƒãªã„ğŸ’¢")
        return {'type': 'none', 'model': None}


def enhance_with_codeformer(image, run_params, fidelity_weight=0.7):
    """
    CodeFormerã§é¡”ç”»è³ªå‘ä¸Šï¼ˆGFPGANä»£æ›¿ï¼‰
    """
    if run_params['type'] != 'codeformer':
        if run_params['type'] == 'gfpgan_fallback':
            print("GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            return enhance_gfpgan_fallback(image, run_params['model'])
        else:
            print("CodeFormeræœªåˆæœŸåŒ–ï¼šå…ƒç”»åƒã‚’è¿”å´")
            return image
    
    try:
        net = run_params['model']
        face_helper = run_params['face_helper']
        device = run_params['device']
        
        # å…ƒã®ã‚µã‚¤ã‚ºä¿å­˜
        original_h, original_w = image.shape[:2]
        
        # é¡”æ¤œå‡º
        face_helper.clean_all()
        
        # OpenCVã®BGRå½¢å¼ã‚’RGBå½¢å¼ã«å¤‰æ›
        if len(image.shape) == 3:
            if is_gray(image):
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
            input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            input_img = image
        
        face_helper.read_image(input_img)
        face_helper.get_face_landmarks_5(only_center_face=False, resize=640, eye_dist_threshold=5)
        face_helper.align_warp_face()
        
        # é¡”ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã¯å…ƒç”»åƒã‚’è¿”ã™
        if len(face_helper.cropped_faces) == 0:
            print("é¡”ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸï¼šå…ƒç”»åƒã‚’è¿”å´")
            return image
        
        # æ¤œå‡ºã•ã‚ŒãŸå…¨ã¦ã®é¡”ã‚’å‡¦ç†
        for idx, cropped_face in enumerate(face_helper.cropped_faces):
            # å‰å‡¦ç†ï¼šãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›ã¨æ­£è¦åŒ–
            cropped_face_t = img2tensor(cropped_face / 255., bgr2rgb=True, float32=True)
            # CodeFormerã®æ­£è¦åŒ–ï¼š[-1, 1]
            cropped_face_t = cropped_face_t.unsqueeze(0).to(device)
            # æ­£è¦åŒ–
            cropped_face_t = (cropped_face_t - 0.5) / 0.5
            
            try:
                # CodeFormeræ¨è«–ï¼ˆGPUæœ€é©åŒ–ï¼‰
                with torch.no_grad():
                    with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):
                        output = net(cropped_face_t, w=fidelity_weight, adain=True)[0]
                        # æ­£è¦åŒ–ã‚’æˆ»ã™ï¼š[-1, 1] -> [0, 1]
                        output = (output + 1) / 2
                        restored_face = tensor2img(output, rgb2bgr=True, min_max=(0, 1))
                        del output
                        torch.cuda.empty_cache()
                
            except Exception as e:
                print(f"CodeFormeræ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
                restored_face = cropped_face
            
            face_helper.add_restored_face(restored_face, cropped_face)
        
        # çµæœã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã«è²¼ã‚Šä»˜ã‘
        face_helper.get_inverse_affine(None)
        restored_img = face_helper.paste_faces_to_input_image()
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        if restored_img.shape[:2] != (original_h, original_w):
            restored_img = cv2.resize(restored_img, (original_w, original_h), interpolation=cv2.INTER_LANCZOS4)
        
        # RGB -> BGR å¤‰æ›ï¼ˆOpenCVå½¢å¼ï¼‰
        if len(restored_img.shape) == 3:
            restored_img = cv2.cvtColor(restored_img, cv2.COLOR_RGB2BGR)
        
        return restored_img
        
    except Exception as e:
        print(f"âŒ CodeFormerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return image

def enhance_gfpgan_fallback(image, gfpgan_model):
    """
    GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆCodeFormerä»£æ›¿ï¼‰
    """






    try:
        # GFPGANå‡¦ç†
        _, _, output = gfpgan_model.enhance(
            image, has_aligned=False, only_center_face=False, paste_back=True
        )
        
        if output is None:
            print("ã‚‚ã€ã‚‚ã†ï¼GFPGANå‡¦ç†ã«å¤±æ•—ã—ãŸã‹ã‚‰å…ƒç”»åƒã‚’è¿”ã™ã‚ã‚ˆğŸ’¢")
            return image
        
        return output
        
    except Exception as e:
        print(f"GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return image


def upscale_codeformer(image, properties, fidelity_weight=0.7):
    """
    CodeFormerç”»è³ªå‘ä¸Šå‡¦ç†ï¼ˆäº’æ›æ€§é–¢æ•°ï¼‰
    """
    return enhance_with_codeformer(image, properties, fidelity_weight)


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
def load_sr():
    """
    å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆGFPGAN -> CodeFormerï¼‰
    """
    return load_codeformer()


def upscale(image, properties):
    """
    å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆGFPGAN -> CodeFormerï¼‰
    """
    return enhance_with_codeformer(image, properties)


def normalize(tensor, mean, std, inplace=False):
    """ãƒ†ãƒ³ã‚½ãƒ«æ­£è¦åŒ–ï¼ˆCodeFormerç”¨ï¼‰"""
    if not inplace:
        tensor = tensor.clone()
    
    dtype = tensor.dtype
    mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
    std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
    tensor.sub_(mean[None, :, None, None]).div_(std[None, :, None, None])
    return tensor


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ­ CodeFormerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    run_params = load_codeformer()
    if run_params['type'] == 'codeformer':
        print("âœ… CodeFormerèª­ã¿è¾¼ã¿æˆåŠŸ")
    elif run_params['type'] == 'gfpgan_fallback':
        print("âœ… GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ")
    else:
        print("âŒ é¡”ç”»è³ªå‘ä¸Šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ããªã„")
    
    print("ğŸ­ CodeFormerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†")