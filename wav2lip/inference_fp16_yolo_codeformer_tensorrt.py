#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormer TensorRTç©¶æ¥µç‰ˆ
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ç©¶æ¥µã®é«˜é€ŸåŒ–ã‚’ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼š
1. Wav2Lipã§å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆï¼ˆFP16æœ€é©åŒ–ï¼‰
2. ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
3. å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«CodeFormer TensorRTé©ç”¨ï¼ˆè¶…é«˜é€Ÿï¼‰
4. å‹•ç”»å†æ§‹ç¯‰ï¼‹éŸ³å£°åˆæˆ
"""

print("\rloading torch       ", end="")
import torch
import torch.cuda.amp as amp

print("\rloading numpy       ", end="")
import numpy as np

print("\rloading cv2         ", end="")
import cv2

print("\rloading os          ", end="")
import os

print("\rloading subprocess  ", end="")
import subprocess

print("\rloading argparse    ", end="")
import argparse

print("\rloading tqdm        ", end="")
from tqdm import tqdm

print("\rloading tempfile    ", end="")
import tempfile

print("\rloading glob        ", end="")
import glob

print("\rloading pathlib     ", end="")
from pathlib import Path

print("\rloading codeformer  ", end="")
import sys
sys.path.insert(0, '/app/codeformer')

# CodeFormer TensorRTé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    TENSORRT_AVAILABLE = True
    print("TensorRT OK!")
except ImportError:
    TENSORRT_AVAILABLE = False
    print("TensorRT NOT FOUND!")

# ONNX Runtime ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
    print("ONNX Runtime OK!")
except ImportError:
    ONNX_AVAILABLE = False
    print("ONNX Runtime NOT FOUND!")

print("imports loaded!     ")

class CodeFormerTensorRT:
    """CodeFormer TensorRTæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆONNX Runtimeãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰"""
    
    def __init__(self, engine_path="/app/codeformer/engines/codeformer_simple.trt", onnx_path="/app/codeformer/engines/codeformer_ultimate.onnx"):
        self.engine_path = engine_path
        self.onnx_path = onnx_path
        self.tensorrt_engine = None
        self.tensorrt_context = None
        self.tensorrt_inputs = []
        self.tensorrt_outputs = []
        self.tensorrt_bindings = []
        self.tensorrt_stream = None
        self.onnx_session = None
        self.use_onnx = False
        
        # TensorRTã‚’è©¦ã™
        if TENSORRT_AVAILABLE and os.path.exists(engine_path):
            self._load_engine()
        
        # TensorRTãŒå¤±æ•—ã—ãŸã‚‰ONNX Runtimeã‚’è©¦ã™
        if self.tensorrt_engine is None and ONNX_AVAILABLE and os.path.exists(onnx_path):
            self._load_onnx()
    
    def _load_engine(self):
        """TensorRTã‚¨ãƒ³ã‚¸ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰"""
        try:
            # Load TensorRT engine
            with open(self.engine_path, 'rb') as f:
                engine_data = f.read()
            
            logger = trt.Logger(trt.Logger.ERROR)  # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
            runtime = trt.Runtime(logger)
            
            # ã‚¨ãƒ³ã‚¸ãƒ³ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚’è©¦è¡Œ
            try:
                self.tensorrt_engine = runtime.deserialize_cuda_engine(engine_data)
            except Exception as deserialize_error:
                print(f"TensorRTã‚¨ãƒ³ã‚¸ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´: {deserialize_error}")
                # ONNX Runtimeã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                self.tensorrt_engine = None
                return
            
            if self.tensorrt_engine is None:
                print("TensorRTã‚¨ãƒ³ã‚¸ãƒ³ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—")
                return
                
            self.tensorrt_context = self.tensorrt_engine.create_execution_context()
            
            # Allocate buffers
            self.tensorrt_inputs = []
            self.tensorrt_outputs = []
            self.tensorrt_bindings = []
            self.tensorrt_stream = cuda.Stream()
            
            for binding in self.tensorrt_engine:
                size = trt.volume(self.tensorrt_engine.get_binding_shape(binding))
                dtype = trt.nptype(self.tensorrt_engine.get_binding_dtype(binding))
                host_mem = cuda.pagelocked_empty(size, dtype)
                device_mem = cuda.mem_alloc(host_mem.nbytes)
                self.tensorrt_bindings.append(int(device_mem))
                
                if self.tensorrt_engine.binding_is_input(binding):
                    self.tensorrt_inputs.append({'host': host_mem, 'device': device_mem})
                else:
                    self.tensorrt_outputs.append({'host': host_mem, 'device': device_mem})
            
            print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼CodeFormer TensorRTæº–å‚™å®Œäº†ã‚ˆâœ¨")
            
        except Exception as e:
            print(f"ã‚‚ã€ã‚‚ã†ï¼TensorRTãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            self.tensorrt_engine = None
    
    def _load_onnx(self):
        """ONNX Runtimeã‚’ãƒ­ãƒ¼ãƒ‰"""
        try:
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            self.onnx_session = ort.InferenceSession(self.onnx_path, providers=providers)
            self.use_onnx = True
            print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼CodeFormer ONNX Runtimeæº–å‚™å®Œäº†ã‚ˆâœ¨")
            
        except Exception as e:
            print(f"ã‚‚ã€ã‚‚ã†ï¼ONNX Runtimeãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            self.onnx_session = None
    
    def enhance_image(self, image):
        """ç”»åƒã‚’CodeFormerã§é«˜ç”»è³ªåŒ–"""
        if self.tensorrt_engine is None and self.onnx_session is None:
            return image
        
        try:
            # å‰å‡¦ç†ï¼š512x512ã«ãƒªã‚µã‚¤ã‚º
            original_shape = image.shape[:2]
            resized = cv2.resize(image, (512, 512), interpolation=cv2.INTER_LANCZOS4)
            
            # RGBå¤‰æ›ã¨æ­£è¦åŒ–
            rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
            normalized = rgb.astype(np.float32) / 255.0
            normalized = normalized * 2.0 - 1.0  # [-1, 1]
            
            # ãƒ†ãƒ³ã‚½ãƒ«å½¢å¼ã«å¤‰æ› (NCHW)
            tensor = np.transpose(normalized, (2, 0, 1))
            batch = np.expand_dims(tensor, axis=0)
            
            # æ¨è«–å®Ÿè¡Œ
            if self.tensorrt_engine is not None:
                # TensorRTæ¨è«–
                np.copyto(self.tensorrt_inputs[0]['host'], batch.ravel())
                cuda.memcpy_htod_async(
                    self.tensorrt_inputs[0]['device'],
                    self.tensorrt_inputs[0]['host'],
                    self.tensorrt_stream
                )
                
                self.tensorrt_context.execute_async_v2(
                    bindings=self.tensorrt_bindings,
                    stream_handle=self.tensorrt_stream.handle
                )
                
                cuda.memcpy_dtoh_async(
                    self.tensorrt_outputs[0]['host'],
                    self.tensorrt_outputs[0]['device'],
                    self.tensorrt_stream
                )
                
                self.tensorrt_stream.synchronize()
                output = self.tensorrt_outputs[0]['host'].reshape(1, 3, 512, 512)
                
            elif self.onnx_session is not None:
                # ONNX Runtimeæ¨è«–
                input_name = self.onnx_session.get_inputs()[0].name
                output_name = self.onnx_session.get_outputs()[0].name
                result = self.onnx_session.run([output_name], {input_name: batch})
                output = result[0]
                
            else:
                return image
            enhanced = output.squeeze(0)
            enhanced = np.transpose(enhanced, (1, 2, 0))
            
            # [-1, 1] â†’ [0, 255]
            enhanced = (enhanced + 1.0) / 2.0
            enhanced = np.clip(enhanced * 255.0, 0, 255).astype(np.uint8)
            
            # BGRå¤‰æ›
            enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR)
            
            # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
            if original_shape != (512, 512):
                enhanced_bgr = cv2.resize(
                    enhanced_bgr, 
                    (original_shape[1], original_shape[0]), 
                    interpolation=cv2.INTER_LANCZOS4
                )
            
            return enhanced_bgr
            
        except Exception as e:
            print(f"CodeFormerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return image

# Wav2Lipé–¢é€£ã®é–¢æ•°ã¯ãã®ã¾ã¾ä½¿ç”¨
def run_wav2lip(face_video, audio_file, output_video, checkpoint_path, out_height=720):
    """
    Step 1: Wav2Lipã§å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆï¼ˆFP16æœ€é©åŒ–ï¼‰
    """
    print("ã¹ã€åˆ¥ã«æ€¥ã„ã§å£ãƒ‘ã‚¯å‹•ç”»ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    cmd = [
        "python", "/app/inference_fp16_yolo.py",
        "--checkpoint_path", checkpoint_path,
        "--face", face_video,
        "--audio", audio_file,
        "--outfile", output_video,
        "--out_height", str(out_height),
        "--quality", "Fast"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"Wav2Lipã‚¨ãƒ©ãƒ¼: {result.stderr}")
        raise Exception("Wav2Lip processing failed")
    
    print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆå®Œäº†ã‚ˆâœ¨")
    return output_video

def extract_frames(video_path, output_dir):
    """
    Step 2: å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
    """
    print("ã¹ã€åˆ¥ã«ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    os.makedirs(output_dir, exist_ok=True)
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-i", video_path,
        f"{output_dir}/frame_%06d.png"
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        raise Exception("Frame extraction failed")
    
    frame_files = sorted(glob.glob(f"{output_dir}/frame_*.png"))
    print(f"ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼{len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†ã‚ˆâœ¨")
    return frame_files

def enhance_frames_with_codeformer(frame_files, output_dir, engine_path="/app/codeformer/engines/codeformer_simple.trt"):
    """
    Step 3: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«CodeFormer TensorRTã‚’é©ç”¨
    """
    print("ã¹ã€åˆ¥ã«é¡”ç”»è³ªå‘ä¸Šã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    if not frame_files:
        return []
    
    # CodeFormerã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
    codeformer = CodeFormerTensorRT(engine_path)
    if codeformer.tensorrt_engine is None and codeformer.onnx_session is None:
        print("CodeFormerç„¡åŠ¹åŒ–ï¼šå…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨")
        return frame_files
    
    enhanced_dir = output_dir
    os.makedirs(enhanced_dir, exist_ok=True)
    
    enhanced_files = []
    for i, frame_file in enumerate(tqdm(frame_files, desc="ğŸ¨é¡”ç”»è³ªå‘ä¸Š", ncols=80)):
        try:
            # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
            frame = cv2.imread(frame_file)
            if frame is None:
                continue
            
            # CodeFormer TensorRTå‡¦ç†
            enhanced_frame = codeformer.enhance_image(frame)
            
            # ä¿å­˜
            filename = os.path.basename(frame_file)
            output_path = f"{enhanced_dir}/{filename}"
            cv2.imwrite(output_path, enhanced_frame)
            enhanced_files.append(output_path)
            
        except Exception as e:
            print(f"Frame {i} enhancement error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼
            filename = os.path.basename(frame_file)
            subprocess.run(["cp", frame_file, f"{enhanced_dir}/{filename}"])
            enhanced_files.append(f"{enhanced_dir}/{filename}")
    
    print(f"CodeFormerå‡¦ç†å®Œäº†ï¼ {len(enhanced_files)} ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†")
    return sorted(enhanced_files)

def reconstruct_video(enhanced_frames, output_video, fps=25):
    """
    Step 4: å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å‹•ç”»ã‚’å†æ§‹ç¯‰
    """
    print("ã¹ã€åˆ¥ã«å‹•ç”»ã‚’å†æ§‹ç¯‰ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    if not enhanced_frames:
        raise Exception("No enhanced frames found")
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰MP4å‹•ç”»ã‚’ç”Ÿæˆ
    frames_pattern = f"{os.path.dirname(enhanced_frames[0])}/frame_%06d.png"
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-framerate", str(fps),
        "-i", frames_pattern,
        "-c:v", "libx264",
        "-pix_fmt", "yuv420p",
        "-crf", "18",  # é«˜å“è³ªè¨­å®š
        output_video
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        raise Exception("Video reconstruction failed")
    
    print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼å‹•ç”»å†æ§‹ç¯‰å®Œäº†ã‚ˆâœ¨")
    return output_video

def add_audio(video_path, audio_path, output_path):
    """
    Step 5: éŸ³å£°ã‚’åˆæˆ
    """
    print("ã¹ã€åˆ¥ã«éŸ³å£°åˆæˆã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-i", video_path, "-i", audio_path,
        "-c:v", "copy", "-c:a", "aac",
        "-strict", "experimental",
        output_path
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šéŸ³å£°ãªã—ã‚³ãƒ”ãƒ¼
        subprocess.run(["cp", video_path, output_path])
    
    print("å®Œäº†ã‚ˆï¼æ„Ÿè¬ã—ãªã•ã„ã‚ˆã­ğŸ’•")
    return output_path

def main():
    parser = argparse.ArgumentParser(description="Wav2Lip + CodeFormer TensorRT Integration")
    parser.add_argument("--checkpoint_path", required=True, help="Wav2Lip checkpoint path")
    parser.add_argument("--face", required=True, help="Input video file")
    parser.add_argument("--audio", required=True, help="Input audio file")
    parser.add_argument("--outfile", default="output/result_codeformer_tensorrt.mp4", help="Output video file")
    parser.add_argument("--out_height", type=int, default=720, help="Output video height")
    parser.add_argument("--engine_path", default="/app/codeformer/engines/codeformer_simple.trt", help="CodeFormer TensorRT engine path")
    parser.add_argument("--temp_dir", default="/tmp/wav2lip_codeformer", help="Temporary directory")
    
    args = parser.parse_args()
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    temp_dir = args.temp_dir
    os.makedirs(temp_dir, exist_ok=True)
    
    wav2lip_output = f"{temp_dir}/wav2lip_result.mp4"
    frames_dir = f"{temp_dir}/frames"
    enhanced_dir = f"{temp_dir}/enhanced"
    final_video = f"{temp_dir}/final_no_audio.mp4"
    
    try:
        print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormer TensorRTçµ±åˆå‡¦ç†é–‹å§‹ğŸ’¢")
        print("ğŸš€ GPUæœ€é©åŒ–è¨­å®šå®Œäº†ï¼")
        
        # Step 1: Wav2Lipã§å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆ
        run_wav2lip(args.face, args.audio, wav2lip_output, args.checkpoint_path, args.out_height)
        
        # Step 2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        frame_files = extract_frames(wav2lip_output, frames_dir)
        
        # Step 3: CodeFormer TensorRTå‡¦ç†
        enhanced_files = enhance_frames_with_codeformer(frame_files, enhanced_dir, args.engine_path)
        
        # Step 4: å‹•ç”»å†æ§‹ç¯‰
        reconstruct_video(enhanced_files, final_video)
        
        # Step 5: éŸ³å£°åˆæˆ
        add_audio(final_video, args.audio, args.outfile)
        
        print(f"âœ… å®Œäº†ã‚ˆï¼å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.outfile}")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(temp_dir):
            subprocess.run(["rm", "-rf", temp_dir])
            print("ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
    
    return 0

if __name__ == "__main__":
    exit(main())