#!/usr/bin/env python3
"""
ğŸš€ ãƒ„ãƒ³ãƒ‡ãƒ¬ONNX GFPGANãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ONNX GFPGANé«˜é€ŸåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢
"""

import cv2
import numpy as np
import onnxruntime as ort
import torch
import os
import time
from enhance import upscale, load_sr

# ONNX Providersè¨­å®š
providers = [
    ('CUDAExecutionProvider', {
        'device_id': 0,
        'arena_extend_strategy': 'kNextPowerOfTwo',
        'gpu_mem_limit': 6 * 1024 * 1024 * 1024,  # 6GBåˆ¶é™
    }),
    'CPUExecutionProvider'
]

def preprocess_frame_gfpgan(frame):
    """GFPGAN ONNXç”¨å‰å‡¦ç†"""
    # (512, 512)ã«ãƒªã‚µã‚¤ã‚º
    frame_resized = cv2.resize(frame, (512, 512))
    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
    frame_normalized = frame_rgb.astype(np.float32) / 255.0
    frame_tensor = np.transpose(frame_normalized, (2, 0, 1))  # HWC â†’ CHW
    return np.expand_dims(frame_tensor, axis=0)  # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 

def postprocess_gfpgan(output, original_shape):
    """GFPGANå‡ºåŠ›å¾Œå‡¦ç†"""
    # æœ€åˆã®å‡ºåŠ›ï¼ˆãƒ¡ã‚¤ãƒ³çµæœï¼‰ã‚’ä½¿ç”¨
    if isinstance(output, list) and len(output) > 0:
        main_output = output[0]
    else:
        main_output = output
    
    # CHW â†’ HWC
    output_frame = np.transpose(main_output[0], (1, 2, 0))
    # æ­£è¦åŒ–è§£é™¤
    output_frame = (output_frame * 255.0).clip(0, 255).astype(np.uint8)
    # RGB â†’ BGR
    output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)
    # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
    output_frame = cv2.resize(output_frame, (original_shape[1], original_shape[0]))
    return output_frame

def test_onnx_gfpgan():
    """ONNX GFPGANæ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬ONNX GFPGANãƒ†ã‚¹ãƒˆé–‹å§‹ğŸ’¢")
    
    # ãƒ†ã‚¹ãƒˆç”»åƒèª­ã¿è¾¼ã¿
    test_image_path = "input/target_video.mp4"
    if not os.path.exists(test_image_path):
        print("âŒ ãƒ†ã‚¹ãƒˆå‹•ç”»ãŒè¦‹ã¤ã‹ã‚‰ãªã„")
        return
    
    # å‹•ç”»ã‹ã‚‰1ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
    cap = cv2.VideoCapture(test_image_path)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
        return
    
    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º: {frame.shape}")
    
    # åˆ©ç”¨å¯èƒ½ãªONNXãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ
    onnx_models = [
        "onnx_models/gfpgan_512x512_type_fixed.onnx",
        "onnx_models/gfpgan_512x512_working.onnx",
        "onnx_models/gfpgan_512x512_opset11.onnx"
    ]
    
    for model_path in onnx_models:
        if not os.path.exists(model_path):
            continue
            
        print(f"\nğŸš€ ãƒ†ã‚¹ãƒˆä¸­: {model_path}")
        
        try:
            # ONNX Runtime ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
            session = ort.InferenceSession(model_path, providers=providers)
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            
            # å…¥åŠ›åç¢ºèª
            input_name = session.get_inputs()[0].name
            print(f"å…¥åŠ›å: {input_name}")
            
            # å‰å‡¦ç†
            input_tensor = preprocess_frame_gfpgan(frame)
            print(f"å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: {input_tensor.shape}")
            
            # æ¨è«–å®Ÿè¡Œï¼ˆæ™‚é–“æ¸¬å®šï¼‰
            start_time = time.time()
            outputs = session.run(None, {input_name: input_tensor})
            inference_time = time.time() - start_time
            
            print(f"âœ… æ¨è«–æˆåŠŸï¼ å‡¦ç†æ™‚é–“: {inference_time:.3f}ç§’")
            print(f"å‡ºåŠ›æ•°: {len(outputs)}")
            for i, output in enumerate(outputs):
                print(f"å‡ºåŠ›{i}å½¢çŠ¶: {output.shape}")
            
            # å¾Œå‡¦ç†
            enhanced_frame = postprocess_gfpgan(outputs, frame.shape[:2])
            
            # çµæœä¿å­˜
            output_path = f"output/onnx_test_{os.path.basename(model_path).replace('.onnx', '')}.png"
            cv2.imwrite(output_path, enhanced_frame)
            print(f"âœ… çµæœä¿å­˜: {output_path}")
            
            print("ğŸš€ ONNX GFPGANæˆåŠŸã‚ˆï¼ğŸ’•")
            return True  # æœ€åˆã«æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«ã§çµ‚äº†
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    # å…¨ONNXå¤±æ•—æ™‚ã¯PyTorchç‰ˆã§æ¯”è¼ƒ
    print("\nğŸ’¢ å…¨ONNXãƒ¢ãƒ‡ãƒ«å¤±æ•—...PyTorchç‰ˆã§æ¯”è¼ƒãƒ†ã‚¹ãƒˆã‚ˆ")
    try:
        run_params = load_sr()
        start_time = time.time()
        enhanced_frame = upscale(frame, run_params)
        pytorch_time = time.time() - start_time
        
        print(f"PyTorchç‰ˆå‡¦ç†æ™‚é–“: {pytorch_time:.3f}ç§’")
        cv2.imwrite("output/pytorch_gfpgan_test.png", enhanced_frame)
        print("PyTorchç‰ˆçµæœä¿å­˜: output/pytorch_gfpgan_test.png")
        
    except Exception as e:
        print(f"PyTorchç‰ˆã‚‚ã‚¨ãƒ©ãƒ¼: {e}")
    
    return False

if __name__ == "__main__":
    test_onnx_gfpgan()