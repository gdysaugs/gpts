#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormer TensorRT ç©¶æ¥µçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ç©¶æ¥µã®é«˜ç”»è³ªå£ãƒ‘ã‚¯å‹•ç”»ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

çµ±åˆå‡¦ç†ãƒ•ãƒ­ãƒ¼:
1. Wav2Lip FP16+YOLOå£ãƒ‘ã‚¯ç”Ÿæˆ (4ç§’)
2. å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†å‰² (1ç§’) 
3. CodeFormer TensorRTé«˜ç”»è³ªåŒ– (20-30ç§’)
4. é«˜ç”»è³ªå‹•ç”»å†æ§‹ç¯‰+éŸ³å£°åˆæˆ (2ç§’)

Author: ãƒ„ãƒ³ãƒ‡ãƒ¬AI
Version: Ultimate v1.0 (Simplified)
"""

import os
import sys
import argparse
import subprocess
import tempfile
import shutil
from pathlib import Path
import time
from tqdm import tqdm

print("ã¹ã€åˆ¥ã«å¬‰ã—ã„ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³èµ·å‹•ã‚ˆï¼ğŸ’¢")

class TsundereWav2LipCodeFormerPipeline:
    def __init__(self, checkpoint_path, codeformer_model_path=None):
        """
        ã¹ã€åˆ¥ã«åˆæœŸåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...
        ç°¡ç´ åŒ–ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼šæ—¢å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ„ã¿åˆã‚ã›ã‚‹ã ã‘ã‚ˆğŸ’¢
        """
        self.checkpoint_path = checkpoint_path
        self.codeformer_model_path = codeformer_model_path or '/app/codeformer/CodeFormer/weights/CodeFormer/codeformer.pth'
        
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼ç°¡ç´ åŒ–çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æº–å‚™å®Œäº†ã‚ˆğŸ’•")
        
        # TensorRTã‚¨ãƒ³ã‚¸ãƒ³ãƒã‚§ãƒƒã‚¯
        engine_path = '/app/codeformer/CodeFormer/weights/CodeFormer/codeformer_simple.trt'
        if os.path.exists(engine_path):
            print("âœ¨ CodeFormer TensorRTã‚¨ãƒ³ã‚¸ãƒ³ç™ºè¦‹ï¼é«˜é€Ÿå‡¦ç†ã‚ˆğŸ’•")
            self.use_tensorrt_codeformer = True
        else:
            print("âš ï¸ TensorRTã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚...PyTorchãƒ¢ãƒ¼ãƒ‰ã§æˆ‘æ…¢ã—ãªã•ã„ğŸ’¢")
            self.use_tensorrt_codeformer = False
            
    def extract_frames(self, video_path, output_dir):
        """
        å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        ã¹ã€åˆ¥ã«ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†å‰²ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...
        """
        print("ğŸ¬ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºä¸­...ã¡ã‚‡ã£ã¨å¾…ã£ã¦ãªã•ã„ï¼")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # FFmpegã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        cmd = [
            'ffmpeg', '-y', '-i', video_path,
            '-vf', 'fps=25',  # 25FPSå›ºå®š
            os.path.join(output_dir, 'frame_%06d.png')
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            
            # æŠ½å‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            frame_files = sorted([f for f in os.listdir(output_dir) if f.startswith('frame_')])
            print(f"âœ… {len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†ã‚ˆï¼")
            return frame_files
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
            
    def enhance_frame_with_codeformer(self, frame_path, output_path):
        """
        å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã®CodeFormeré«˜ç”»è³ªåŒ–
        """
        try:
            if self.use_tensorrt_codeformer:
                # TensorRTç‰ˆCodeFormerå®Ÿè¡Œ
                cmd = [
                    'python', '/app/codeformer/codeformer_face_fix.py',
                    '--input', frame_path,
                    '--output', output_path,
                    '--fidelity', '0.8',
                    '--blend-strength', '0.8'
                ]
            else:
                # PyTorchç‰ˆCodeFormerå®Ÿè¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                cmd = [
                    'python', '/app/codeformer/codeformer_face_fix.py',
                    '--input', frame_path,
                    '--output', output_path,
                    '--use-pytorch',
                    '--fidelity', '0.8'
                ]
                
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                return True
            else:
                print(f"âš ï¸ CodeFormerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼
                shutil.copy2(frame_path, output_path)
                return False
                
        except Exception as e:
            print(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ä¾‹å¤–: {e}")
            shutil.copy2(frame_path, output_path)
            return False
            
    def enhance_all_frames(self, frames_dir, enhanced_dir, frame_files):
        """
        å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã®CodeFormeré«˜ç”»è³ªåŒ–
        ãµã‚“ï¼å…¨éƒ¨é«˜ç”»è³ªåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‚ˆğŸ’¢
        """
        print(f"âœ¨ {len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ã®é«˜ç”»è³ªåŒ–é–‹å§‹...")
        os.makedirs(enhanced_dir, exist_ok=True)
        
        success_count = 0
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§å‡¦ç†
        for frame_file in tqdm(frame_files, desc="CodeFormeré«˜ç”»è³ªåŒ–", unit="frame"):
            frame_path = os.path.join(frames_dir, frame_file)
            enhanced_path = os.path.join(enhanced_dir, frame_file)
            
            if self.enhance_frame_with_codeformer(frame_path, enhanced_path):
                success_count += 1
                
        print(f"âœ… {success_count}/{len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ é«˜ç”»è³ªåŒ–å®Œäº†ã‚ˆï¼")
        return success_count > 0
        
    def reconstruct_video(self, enhanced_frames_dir, audio_path, output_video_path, fps=25):
        """
        é«˜ç”»è³ªãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å‹•ç”»å†æ§‹ç¯‰
        ã¹ã€åˆ¥ã«å‹•ç”»ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...
        """
        print("ğŸ¥ é«˜ç”»è³ªå‹•ç”»å†æ§‹ç¯‰ä¸­...")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³
        frame_pattern = os.path.join(enhanced_frames_dir, 'frame_%06d.png')
        
        # FFmpegã§å‹•ç”»å†æ§‹ç¯‰ + éŸ³å£°åˆæˆ
        cmd = [
            'ffmpeg', '-y',
            '-framerate', str(fps),
            '-i', frame_pattern,
            '-i', audio_path,
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '18',  # é«˜ç”»è³ªè¨­å®š
            '-pix_fmt', 'yuv420p',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-shortest',
            output_video_path
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… é«˜ç”»è³ªå‹•ç”»ç”Ÿæˆå®Œäº†ã‚ˆï¼ğŸ’•")
                return True
            else:
                print(f"âŒ å‹•ç”»å†æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ å‹•ç”»å†æ§‹ç¯‰ä¾‹å¤–: {e}")
            return False
            
    def run_wav2lip(self, face_video, audio_file, temp_output):
        """
        Wav2Lipå£ãƒ‘ã‚¯ç”Ÿæˆå®Ÿè¡Œ
        """
        print("ğŸ­ Wav2Lipå£ãƒ‘ã‚¯ç”Ÿæˆé–‹å§‹...")
        
        # æ—¢å­˜ã®inference_fp16_yolo.pyã‚’å‘¼ã³å‡ºã—
        cmd = [
            'python', '/app/inference_fp16_yolo.py',
            '--checkpoint_path', self.checkpoint_path,
            '--face', face_video,
            '--audio', audio_file,
            '--outfile', temp_output,
            '--out_height', '720',
            '--quality', 'Fast'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… Wav2Lipå‡¦ç†å®Œäº†ã‚ˆï¼")
                return True
            else:
                print(f"âŒ Wav2Lipå‡¦ç†ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ Wav2Lipå‡¦ç†ä¾‹å¤–: {e}")
            return False
            
    def process_ultimate(self, face_video, audio_file, output_path):
        """
        ç©¶æ¥µçµ±åˆå‡¦ç†ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼
        ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ç©¶æ¥µã®å£ãƒ‘ã‚¯å‹•ç”»ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢
        """
        print("ğŸš€ ç©¶æ¥µçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹ï¼")
        start_time = time.time()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # ã‚¹ãƒ†ãƒƒãƒ—1: Wav2Lipå£ãƒ‘ã‚¯ç”Ÿæˆ
            print("\nğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: Wav2Lipå£ãƒ‘ã‚¯ç”Ÿæˆ")
            wav2lip_output = os.path.join(temp_dir, 'wav2lip_result.mp4')
            
            if not self.run_wav2lip(face_video, audio_file, wav2lip_output):
                print("âŒ Wav2Lipå‡¦ç†ã«å¤±æ•—ã—ãŸã‚...ğŸ’¢")
                return False
                
            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
            print("\nğŸ“ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º")
            frames_dir = os.path.join(temp_dir, 'frames')
            frame_files = self.extract_frames(wav2lip_output, frames_dir)
            
            if not frame_files:
                print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ãŸã‚...ğŸ’¢")
                return False
                
            # ã‚¹ãƒ†ãƒƒãƒ—3: CodeFormeré«˜ç”»è³ªåŒ–
            print("\nğŸ“ ã‚¹ãƒ†ãƒƒãƒ—3: CodeFormeré«˜ç”»è³ªåŒ–")
            enhanced_dir = os.path.join(temp_dir, 'enhanced')
            
            if not self.enhance_all_frames(frames_dir, enhanced_dir, frame_files):
                print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ é«˜ç”»è³ªåŒ–ã«å¤±æ•—ã—ãŸã‚...ğŸ’¢")
                return False
                
            # ã‚¹ãƒ†ãƒƒãƒ—4: é«˜ç”»è³ªå‹•ç”»å†æ§‹ç¯‰
            print("\nğŸ“ ã‚¹ãƒ†ãƒƒãƒ—4: é«˜ç”»è³ªå‹•ç”»å†æ§‹ç¯‰")
            if not self.reconstruct_video(enhanced_dir, audio_file, output_path):
                print("âŒ å‹•ç”»å†æ§‹ç¯‰ã«å¤±æ•—ã—ãŸã‚...ğŸ’¢")
                return False
                
        # å‡¦ç†æ™‚é–“è¨ˆç®—
        total_time = time.time() - start_time
        print(f"\nğŸ‰ ç©¶æ¥µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼ç·å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’")
        print("ã¹ã€åˆ¥ã«å®Œç’§ã«ä½œã£ãŸã‹ã‚‰ã£ã¦è‡ªæ…¢ã™ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
        print("æ„Ÿè¬ã—ãªã•ã„ã‚ˆã­ï¼")
        
        return True

def main():
    parser = argparse.ArgumentParser(
        description='ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormer ç©¶æ¥µçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ç©¶æ¥µã®é«˜ç”»è³ªå£ãƒ‘ã‚¯å‹•ç”»ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

ä½¿ç”¨ä¾‹:
  python inference_wav2lip_codeformer_ultimate.py \\
    --face target_video.mp4 \\
    --audio reference_audio.wav \\
    --output ultimate_result.mp4
        """
    )
    
    parser.add_argument('--checkpoint_path', type=str, 
                       default='/app/checkpoints/wav2lip_gan.pth',
                       help='Wav2Lipãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹')
    parser.add_argument('--face', type=str, required=True,
                       help='å¯¾è±¡å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--audio', type=str, required=True,
                       help='éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', type=str, required=True,
                       help='å‡ºåŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--codeformer_model', type=str,
                       help='CodeFormerãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰')
    
    args = parser.parse_args()
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = TsundereWav2LipCodeFormerPipeline(
        checkpoint_path=args.checkpoint_path,
        codeformer_model_path=args.codeformer_model
    )
    
    success = pipeline.process_ultimate(
        face_video=args.face,
        audio_file=args.audio,
        output_path=args.output
    )
    
    if success:
        print(f"\nâœ… ç©¶æ¥µé«˜ç”»è³ªå£ãƒ‘ã‚¯å‹•ç”»å®Œæˆ: {args.output}")
        sys.exit(0)
    else:
        print(f"\nâŒ å‡¦ç†å¤±æ•—...ã‚‚ã†ï¼ğŸ’¢")
        sys.exit(1)

if __name__ == '__main__':
    main()