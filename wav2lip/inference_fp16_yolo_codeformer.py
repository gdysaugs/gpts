#!/usr/bin/env python3
"""
ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + CodeFormerï¼ˆçµ¶å¯¾æœ€é«˜ç”»è³ªç‰ˆï¼‰
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«CodeFormerç‰ˆã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢

langzizhixin/Wav2Lip-CodeFormer ã‚’å‚è€ƒã«ã—ãŸå®Ÿè£…ï¼š
1. Wav2Lipã§å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆï¼ˆFP16+YOLOæœ€é©åŒ–ï¼‰
2. ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆé«˜é€ŸåŒ–ï¼‰
3. å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«CodeFormeré©ç”¨ï¼ˆGFPGANã‚ˆã‚Šé«˜ç”»è³ªï¼‰
4. å‹•ç”»å†æ§‹ç¯‰ï¼‹éŸ³å£°åˆæˆï¼ˆæœ€çµ‚å‡ºåŠ›ï¼‰
"""

print("\rloading torch       ", end="")
import torch
import torch.cuda.amp as amp

print("\rloading numpy       ", end="")
import numpy as np

print("\rloading cv2         ", end="")
import cv2

print("\rloading os          ", end="")
import os

print("\rloading subprocess  ", end="")
import subprocess

print("\rloading argparse    ", end="")
import argparse

print("\rloading tqdm        ", end="")
from tqdm import tqdm

print("\rloading tempfile    ", end="")
import tempfile

print("\rloading glob        ", end="")
import glob

print("\rloading pathlib     ", end="")
from pathlib import Path

print("\rloading concurrent  ", end="")
from concurrent.futures import ThreadPoolExecutor
import multiprocessing

print("\rloading enhance     ", end="")

# ã¾ãšCodeFormerã‚’è©¦è¡Œï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªç«¶åˆå›é¿ã®ãŸã‚å…ˆã«èª­ã¿è¾¼ã¿ï¼‰
CODEFORMER_AVAILABLE = False
GFPGAN_AVAILABLE = False

try:
    from enhance_codeformer import enhance_with_codeformer, load_codeformer
    CODEFORMER_AVAILABLE = True
    print("CodeFormer OK!")
    
    # CodeFormeræˆåŠŸæ™‚ã¯GFPGANã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªç«¶åˆå›é¿ï¼‰
    try:
        # è»½é‡ãªGFPGANé–¢æ•°ã®ã¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªå›é¿ï¼‰
        import sys
        import importlib.util
        
        # enhance.pyã‹ã‚‰å¿…è¦ãªé–¢æ•°ã®ã¿æŠ½å‡º
        spec = importlib.util.spec_from_file_location("enhance_light", "/app/enhance.py")
        enhance_light = importlib.util.module_from_spec(spec)
        
        # BasicSRãƒ¬ã‚¸ã‚¹ãƒˆãƒªç«¶åˆã‚’å›é¿ã—ã¦GFPGANé–¢æ•°ã®ã¿ãƒ­ãƒ¼ãƒ‰
        import warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            # ã“ã“ã§GFPGANã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãªã„
            GFPGAN_AVAILABLE = False
            
        print("CodeFormerå„ªå…ˆãƒ¢ãƒ¼ãƒ‰ï¼")
        
    except Exception as fallback_error:
        print(f"GFPGANè»½é‡ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {fallback_error}")
        GFPGAN_AVAILABLE = False
    
except ImportError as e:
    print(f"CodeFormer NOT FOUND: {e}")
    CODEFORMER_AVAILABLE = False
    
    # CodeFormerå¤±æ•—æ™‚ã®ã¿GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        from enhance import upscale, load_sr
        GFPGAN_AVAILABLE = True
        print("GFPGAN Fallback OK!")
    except ImportError:
        GFPGAN_AVAILABLE = False
        print("No enhancement available!")

print("\rloading face detection", end="")
# é¡”æ¤œå‡ºã‚’ç„¡åŠ¹åŒ–ã—ã¦å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
FACE_DETECTION_AVAILABLE = False
print("Face Detection DISABLED")

print("\rimports loaded!     ")

# GPUæœ€é©åŒ–è¨­å®š
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True  # cuDNNæœ€é©åŒ–
    torch.backends.cuda.matmul.allow_tf32 = True  # TF32æœ‰åŠ¹åŒ–
    torch.cuda.empty_cache()  # åˆæœŸãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
    print("ğŸš€ GPUæœ€é©åŒ–è¨­å®šå®Œäº†ï¼")

# å…ƒã®inference_fp16_yolo.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
sys.path.append('/app/host')

def run_wav2lip(face_video, audio_file, output_path, checkpoint_path, out_height=720):
    """
    Step 1: Wav2Lipã§å£ãƒ‘ã‚¯å‹•ç”»ã‚’ç”Ÿæˆ
    """
    print("ã¹ã€åˆ¥ã«æ€¥ã„ã§å£ãƒ‘ã‚¯å‹•ç”»ã‚’ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    cmd = [
        "python", "/app/inference_fp16_yolo.py",
        "--checkpoint_path", checkpoint_path,
        "--face", face_video,
        "--audio", audio_file,
        "--outfile", output_path,
        "--out_height", str(out_height),
        "--quality", "Fast"  # å£ãƒ‘ã‚¯ä¿è¨¼ã®ãŸã‚Fastå¿…é ˆ
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"ã‚‚ã€ã‚‚ã†ï¼Wav2Lipã‚¨ãƒ©ãƒ¼: {result.stderr}")
        raise Exception(f"Wav2Lip failed: {result.stderr}")
    
    print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆå®Œäº†ã‚ˆâœ¨")
    return output_path

def extract_frames(video_path, frames_dir):
    """
    Step 2: ä¸¦åˆ—æœ€é©åŒ–ã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆé«˜é€ŸåŒ–ï¼‰
    """
    print("ã¹ã€åˆ¥ã«ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    os.makedirs(frames_dir, exist_ok=True)
    
    # FFmpegä¸¦åˆ—å‡¦ç†æœ€é©åŒ–
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-threads", "4",  # ä¸¦åˆ—å‡¦ç†
        "-i", video_path,
        "-vf", "fps=25",  # 25fpsã§æŠ½å‡º
        "-preset", "ultrafast",  # æœ€é«˜é€Ÿåº¦è¨­å®š
        f"{frames_dir}/frame_%06d.png"
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        raise Exception("Frame extraction failed")
    
    frame_files = sorted(glob.glob(f"{frames_dir}/frame_*.png"))
    print(f"ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼{len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†ã‚ˆâœ¨")
    return frame_files

def detect_faces_in_frame(frame):
    """
    å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆé¡”æ¤œå‡ºç„¡åŠ¹åŒ–ï¼‰
    """
    # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã«æˆ»ã™
    return [(0, 0, frame.shape[1], frame.shape[0])]

def upscale_batch_parallel(batch_tensor, run_params):
    """
    çœŸã®ä¸¦åˆ—ãƒãƒƒãƒGFPGANå‡¦ç†ï¼ˆGPUä¸¦åˆ—æœ€é©åŒ–ï¼‰
    """
    try:
        if run_params['type'] == 'onnx':
            # ONNX Runtimeä¸¦åˆ—å‡¦ç†
            session = run_params['session']
            batch_size = batch_tensor.shape[0]
            input_size = run_params['input_size']
            
            # ãƒãƒƒãƒãƒªã‚µã‚¤ã‚º
            resized_batch = torch.nn.functional.interpolate(
                batch_tensor, size=(input_size, input_size), 
                mode='bilinear', align_corners=False
            )
            
            # ONNXæ¨è«–ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
            input_data = resized_batch.cpu().numpy()
            output_data = session.run(None, {session.get_inputs()[0].name: input_data})[0]
            
            # çµæœã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            enhanced_batch = torch.from_numpy(output_data).cuda()
            
            return enhanced_batch
        
        elif run_params['type'] == 'pytorch':
            # PyTorch GFPGANä¸¦åˆ—å‡¦ç†
            gfpgan = run_params['gfpgan']
            enhanced_list = []
            
            # ä¸¦åˆ—å‡¦ç†ï¼ˆãƒãƒ«ãƒã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‰
            for i in range(batch_tensor.shape[0]):
                with torch.cuda.stream(torch.cuda.Stream()):
                    frame_tensor = batch_tensor[i:i+1]
                    # GFPGANå‡¦ç†ã‚’ã“ã“ã«å®Ÿè£…
                    enhanced_frame = frame_tensor  # æš«å®šï¼ˆå®Ÿéš›ã®GFPGANå‡¦ç†ã«ç½®ãæ›ãˆï¼‰
                    enhanced_list.append(enhanced_frame)
            
            # çµæœã‚’ãƒãƒƒãƒãƒ†ãƒ³ã‚½ãƒ«ã«ã‚¹ã‚¿ãƒƒã‚¯
            enhanced_batch = torch.cat(enhanced_list, dim=0)
            return enhanced_batch
        
    except Exception as e:
        print(f"ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã™
        return batch_tensor

def process_frames_with_streams(batch_frames, run_params, num_streams=4):
    """
    âš¡ CUDAã‚¹ãƒˆãƒªãƒ¼ãƒ ä¸¦åˆ—å‡¦ç†ï¼ˆè¶…é«˜é€ŸåŒ–ï¼‰
    """
    try:
        import concurrent.futures
        
        # CUDAã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
        streams = [torch.cuda.Stream() for _ in range(min(num_streams, len(batch_frames)))]
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«åˆ†æ•£
        enhanced_batch = [None] * len(batch_frames)
        
        def process_frame_on_stream(frame_idx, frame, stream_idx):
            with torch.cuda.stream(streams[stream_idx]):
                enhanced_frame = upscale(frame, run_params)
                if enhanced_frame is None:
                    enhanced_frame = frame
                return frame_idx, enhanced_frame
        
        # ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_streams) as executor:
            futures = []
            for i, frame in enumerate(batch_frames):
                stream_idx = i % num_streams
                future = executor.submit(process_frame_on_stream, i, frame, stream_idx)
                futures.append(future)
            
            # çµæœåé›†
            for future in concurrent.futures.as_completed(futures):
                frame_idx, enhanced_frame = future.result()
                enhanced_batch[frame_idx] = enhanced_frame
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ åŒæœŸ
        for stream in streams:
            stream.synchronize()
        
        return enhanced_batch
        
    except Exception as e:
        print(f"ã‚¹ãƒˆãƒªãƒ¼ãƒ ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šé †æ¬¡å‡¦ç†
        enhanced_batch = []
        for frame in batch_frames:
            enhanced_frame = upscale(frame, run_params)
            if enhanced_frame is None:
                enhanced_frame = frame
            enhanced_batch.append(enhanced_frame)
        return enhanced_batch


def enhance_frames_with_codeformer(frame_files, output_dir, target_height=720, batch_size=1, use_streams=False):
    """
    Step 3: GPUæœ€é©åŒ–ã§CodeFormeré©ç”¨ï¼ˆGFPGANä»£æ›¿ã§é«˜é€ŸåŒ–ï¼‰
    """
    print("ã¹ã€åˆ¥ã«CodeFormerã§é¡”ç”»è³ªå‘ä¸Šã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    print(f"ç›®æ¨™è§£åƒåº¦: {target_height}p ã§CodeFormeré«˜ç”»è³ªåŒ–ã™ã‚‹ã‚ã‚ˆï¼")
    print("âš¡ CodeFormer GPUæœ€é©åŒ–ã§åŠ¹ç‡çš„å‡¦ç†ã‚ˆï¼ONNXå¯¾å¿œã§è¶…é«˜é€ŸåŒ–ğŸ’•")
    
    if not CODEFORMER_AVAILABLE:
        print("ãµã‚“ï¼CodeFormerãŒä½¿ãˆãªã„ã‹ã‚‰å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã ã‘ã‚ˆ...")
        enhanced_dir = output_dir
        os.makedirs(enhanced_dir, exist_ok=True)
        for frame_file in frame_files:
            filename = os.path.basename(frame_file)
            subprocess.run(["cp", frame_file, f"{enhanced_dir}/{filename}"])
        return sorted(glob.glob(f"{enhanced_dir}/frame_*.png"))
    
    try:
        if CODEFORMER_AVAILABLE:
            run_params = load_codeformer()
            print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼CodeFormeræº–å‚™å®Œäº†ã‚ˆâœ¨")
        elif GFPGAN_AVAILABLE:
            # GFPGANãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªç«¶åˆå›é¿ï¼‰
            print("CodeFormeråˆ©ç”¨ä¸å¯ã®ãŸã‚å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—")
            return frame_files
        else:
            print("ç”»è³ªå‘ä¸Šãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return frame_files
    except Exception as e:
        print(f"ã‚‚ã€ã‚‚ã†ï¼ç”»è³ªå‘ä¸Šãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return frame_files
    
    enhanced_dir = output_dir
    os.makedirs(enhanced_dir, exist_ok=True)
    
    # GFPGANåˆæœŸåŒ–
    run_params = load_sr()
    
    # ãƒãƒƒãƒå‡¦ç†ï¼ˆé«˜é€ŸåŒ–ï¼‰
    enhanced_files = []
    print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º{batch_size}ã§å‡¦ç†ã™ã‚‹ã‚ã‚ˆğŸ’¢")
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒãƒƒãƒã«åˆ†å‰²
    for batch_start in tqdm(range(0, len(frame_files), batch_size), desc=f"GPUæœ€é©åŒ–GFPGAN(batch{batch_size})", ncols=80):
        batch_end = min(batch_start + batch_size, len(frame_files))
        batch_files = frame_files[batch_start:batch_end]
        
        try:
            # GPU ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            if batch_start % (10 * batch_size) == 0:  # å®šæœŸçš„ã«ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                torch.cuda.empty_cache()
            
            # ãƒãƒƒãƒå‡¦ç†
            batch_frames = []
            valid_files = []
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
            for frame_file in batch_files:
                frame = cv2.imread(frame_file)
                if frame is not None:
                    batch_frames.append(frame)
                    valid_files.append(frame_file)
            
            if not batch_frames:
                continue
            
            # çœŸã®ä¸¦åˆ—ãƒãƒƒãƒGFPGANå‡¦ç†ï¼ˆGPUä¸¦åˆ—æœ€é©åŒ–ï¼‰
            enhanced_batch = []
            with torch.cuda.amp.autocast():
                with torch.no_grad():  # å‹¾é…è¨ˆç®—ç„¡åŠ¹åŒ–
                    if len(batch_frames) == 1:
                        # ã‚·ãƒ³ã‚°ãƒ«å‡¦ç†ï¼ˆæœ€é©åŒ–ï¼‰
                        if CODEFORMER_AVAILABLE:
                            enhanced_frame = enhance_with_codeformer(batch_frames[0], run_params, fidelity_weight)
                        else:
                            # CodeFormeråˆ©ç”¨ä¸å¯æ™‚ã¯ãƒ•ãƒ¬ãƒ¼ãƒ ãã®ã¾ã¾
                            enhanced_frame = batch_frames[0]
                        
                        if enhanced_frame is None:
                            enhanced_frame = batch_frames[0]
                        enhanced_batch.append(enhanced_frame)
                    else:
                        # ç¢ºå®Ÿãªé †æ¬¡å‡¦ç†ï¼ˆæœ€å®‰å®šï¼‰
                        print("ãƒãƒƒãƒå‡¦ç†å†…ã§é †æ¬¡ç”»è³ªå‘ä¸Šå‡¦ç†ã‚’å®Ÿè¡ŒğŸ’¢")
                        for frame in batch_frames:
                            if CODEFORMER_AVAILABLE:
                                enhanced_frame = enhance_with_codeformer(frame, run_params, fidelity_weight)
                            else:
                                # CodeFormeråˆ©ç”¨ä¸å¯æ™‚ã¯ãƒ•ãƒ¬ãƒ¼ãƒ ãã®ã¾ã¾
                                enhanced_frame = frame
                            
                            if enhanced_frame is None:
                                enhanced_frame = frame
                            enhanced_batch.append(enhanced_frame)
            
            # ãƒãƒƒãƒçµæœã‚’ä¿å­˜
            for i, (enhanced_frame, frame_file) in enumerate(zip(enhanced_batch, valid_files)):
                # ç›®æ¨™è§£åƒåº¦ã«ãƒªã‚µã‚¤ã‚º
                if target_height and target_height > 0:
                    current_height = enhanced_frame.shape[0]
                    if current_height != target_height:
                        scale_factor = target_height / current_height
                        new_width = int(enhanced_frame.shape[1] * scale_factor)
                        # FFmpegå¯¾å¿œï¼šå¶æ•°å¹…ã«èª¿æ•´
                        if new_width % 2 != 0:
                            new_width += 1
                        enhanced_frame = cv2.resize(enhanced_frame, (new_width, target_height), interpolation=cv2.INTER_LANCZOS4)
                
                # ä¿å­˜
                filename = os.path.basename(frame_file)
                output_path = f"{enhanced_dir}/{filename}"
                cv2.imwrite(output_path, enhanced_frame)
                enhanced_files.append(output_path)
            
        except Exception as e:
            print(f"Batch {batch_start}-{batch_end} enhancement error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼
            for frame_file in batch_files:
                filename = os.path.basename(frame_file)
                subprocess.run(["cp", frame_file, f"{enhanced_dir}/{filename}"])
                enhanced_files.append(f"{enhanced_dir}/{filename}")
    
    print(f"CodeFormerå‡¦ç†å®Œäº†ï¼ {len(enhanced_files)} ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†")
    return sorted(enhanced_files)

def reconstruct_video(enhanced_frames, output_video, fps=25):
    """
    Step 4: ä¸¦åˆ—æœ€é©åŒ–ã§å‹•ç”»å†æ§‹ç¯‰ï¼ˆé«˜é€ŸåŒ–ï¼‰
    """
    print("ã¹ã€åˆ¥ã«å‹•ç”»ã‚’å†æ§‹ç¯‰ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
    
    if not enhanced_frames:
        raise Exception("No enhanced frames found")
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰MP4å‹•ç”»ã‚’ç”Ÿæˆï¼ˆä¸¦åˆ—æœ€é©åŒ–ï¼‰
    frames_pattern = f"{os.path.dirname(enhanced_frames[0])}/frame_%06d.png"
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-threads", "4",  # ä¸¦åˆ—å‡¦ç†
        "-framerate", str(fps),
        "-i", frames_pattern,
        "-c:v", "libx264",
        "-preset", "faster",  # é«˜é€Ÿã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        "-tune", "fastdecode",  # ãƒ‡ã‚³ãƒ¼ãƒ‰æœ€é©åŒ–
        "-pix_fmt", "yuv420p",
        "-crf", "18",  # é«˜å“è³ªè¨­å®š
        output_video
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        raise Exception("Video reconstruction failed")
    
    print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼å‹•ç”»å†æ§‹ç¯‰å®Œäº†ã‚ˆâœ¨")
    return output_video

def add_audio(video_path, audio_path, output_path):
    """
    Step 5: éŸ³å£°ã‚’åˆæˆ
    """
    print("ã¹ã€åˆ¥ã«éŸ³å£°åˆæˆã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
    
    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-i", video_path, "-i", audio_path,
        "-c:v", "copy", "-c:a", "aac",
        "-strict", "experimental",
        output_path
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šéŸ³å£°ãªã—ã‚³ãƒ”ãƒ¼
        subprocess.run(["cp", video_path, output_path])
    
    print("å®Œäº†ã‚ˆï¼æ„Ÿè¬ã—ãªã•ã„ã‚ˆã­ğŸ’•")
    return output_path

def main():
    parser = argparse.ArgumentParser(description="Wav2Lip + CodeFormer Integration (Ultimate Quality Pipeline)")
    parser.add_argument("--checkpoint_path", required=True, help="Wav2Lip checkpoint path")
    parser.add_argument("--face", required=True, help="Input video file")
    parser.add_argument("--audio", required=True, help="Input audio file")
    parser.add_argument("--outfile", default="output/result_codeformer_ultimate.mp4", help="Output video file")
    parser.add_argument("--fidelity_weight", type=float, default=0.7, help="CodeFormer fidelity weight (0-1, higher=more fidelity)")
    parser.add_argument("--out_height", type=int, default=720, help="Final output video height")
    parser.add_argument("--wav2lip_height", type=int, default=720, help="Wav2Lip processing height (for quality)")
    parser.add_argument("--enable_codeformer", action="store_true", default=True, help="Enable CodeFormer enhancement")
    parser.add_argument("--batch_size", type=int, default=1, help="GFPGAN batch size for speed optimization")
    parser.add_argument("--use_streams", action="store_true", help="Use CUDA streams for parallel processing")
    parser.add_argument("--temp_dir", default="/tmp/wav2lip_gfpgan", help="Temporary directory")
    
    args = parser.parse_args()
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    temp_dir = args.temp_dir
    os.makedirs(temp_dir, exist_ok=True)
    
    wav2lip_output = f"{temp_dir}/wav2lip_result.mp4"
    frames_dir = f"{temp_dir}/frames"
    enhanced_dir = f"{temp_dir}/enhanced"
    final_video = f"{temp_dir}/final_no_audio.mp4"
    
    try:
        print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬Wav2Lip + GFPGANçµ±åˆå‡¦ç†é–‹å§‹ğŸ’¢")
        
        # Step 1: Wav2Lipã§å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆï¼ˆä½è§£åƒåº¦ã§é«˜é€Ÿå‡¦ç†ï¼‰
        print(f"ã¹ã€åˆ¥ã«{args.wav2lip_height}pã®é«˜ç”»è³ªã§å£ãƒ‘ã‚¯å‡¦ç†ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢")
        run_wav2lip(args.face, args.audio, wav2lip_output, args.checkpoint_path, args.wav2lip_height)
        
        # Step 2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        frame_files = extract_frames(wav2lip_output, frames_dir)
        
        # Step 3: CodeFormerå‡¦ç†ï¼ˆGFPGANä»£æ›¿ã§é«˜é€Ÿé«˜ç”»è³ªåŒ–ï¼‰
        if args.enable_codeformer and CODEFORMER_AVAILABLE:
            print(f"ã¹ã€åˆ¥ã«CodeFormerã§{args.out_height}pé«˜ç”»è³ªåŒ–ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’•")
            enhanced_files = enhance_frames_with_codeformer(frame_files, enhanced_dir, args.out_height, args.batch_size, args.use_streams)
        else:
            print("CodeFormerç„¡åŠ¹åŒ–ï¼šå…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨")
            enhanced_files = frame_files
        
        # Step 4: å‹•ç”»å†æ§‹ç¯‰
        reconstruct_video(enhanced_files, final_video)
        
        # Step 5: éŸ³å£°åˆæˆ
        add_audio(final_video, args.audio, args.outfile)
        
        print(f"\nâœ… ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼CodeFormerçµ¶å¯¾æœ€é«˜ç”»è³ªå®Œæˆã‚ˆâœ¨")
        print(f"ğŸ¬ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.outfile}")
        print(f"ğŸ“Š Fidelity Weight: {args.fidelity_weight} (0-1, é«˜ã„ã»ã©åŸç”»å¿ å®Ÿ)")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        try:
            import shutil
            shutil.rmtree(temp_dir)
            print("ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†ï¼ˆCodeFormerå‡¦ç†çµ‚äº†ï¼‰")
        except:
            pass
    
    return 0

if __name__ == "__main__":
    exit(main())