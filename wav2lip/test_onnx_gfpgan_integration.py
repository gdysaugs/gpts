#!/usr/bin/env python3
"""
ğŸš€ ãƒ„ãƒ³ãƒ‡ãƒ¬ONNX GFPGANçµ±åˆãƒ†ã‚¹ãƒˆ
ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«ONNXç‰ˆã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...ğŸ’¢
"""

import torch
import numpy as np
import cv2
import os
import onnxruntime as ort
from tqdm import tqdm
import tempfile
import subprocess
import time

def test_onnx_gfpgan_inference():
    """
    ONNX GFPGANå˜ä½“æ¨è«–ãƒ†ã‚¹ãƒˆ
    """
    print("ğŸ­ ãƒ„ãƒ³ãƒ‡ãƒ¬ONNX GFPGANæ¨è«–ãƒ†ã‚¹ãƒˆé–‹å§‹ğŸ’¢")
    
    # ONNX Runtime GPUè¨­å®š
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
    session = ort.InferenceSession('onnx_models/gfpgan_512x512_stylegan_fixed_direct.onnx', providers=providers)
    
    print("ã¹ã€åˆ¥ã«ONNXã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œã£ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...")
    print(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {session.get_providers()}")
    
    # ãƒ†ã‚¹ãƒˆç”¨ç”»åƒä½œæˆï¼ˆ512x512ï¼‰
    test_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    
    # å‰å‡¦ç†ï¼ˆPyTorchãƒ†ãƒ³ã‚½ãƒ«å½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
    input_tensor = test_image.astype(np.float32) / 255.0
    input_tensor = np.transpose(input_tensor, (2, 0, 1))  # HWC -> CHW
    input_tensor = np.expand_dims(input_tensor, axis=0)  # Batch dimension
    input_tensor = (input_tensor - 0.5) / 0.5  # [-1, 1] normalization
    
    print(f"å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: {input_tensor.shape}, å‹: {input_tensor.dtype}")
    
    # ONNXæ¨è«–å®Ÿè¡Œ
    start_time = time.time()
    try:
        outputs = session.run(None, {'input': input_tensor})
        inference_time = time.time() - start_time
        
        print(f"ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼ONNXæ¨è«–æˆåŠŸã‚ˆâœ¨")
        print(f"æ¨è«–æ™‚é–“: {inference_time:.3f}ç§’")
        print(f"å‡ºåŠ›æ•°: {len(outputs)}")
        
        for i, output in enumerate(outputs):
            print(f"å‡ºåŠ›{i}: {output.shape}, å‹: {output.dtype}")
        
        # ãƒ¡ã‚¤ãƒ³å‡ºåŠ›ï¼ˆæœ€åˆã®å‡ºåŠ›ï¼‰ã‚’å¾Œå‡¦ç†
        main_output = outputs[0]
        if main_output.shape[0] == 1:  # ãƒãƒƒãƒæ¬¡å…ƒé™¤å»
            main_output = main_output[0]
        
        # [-1, 1] -> [0, 255] å¤‰æ›
        main_output = (main_output + 1.0) / 2.0
        main_output = np.clip(main_output * 255.0, 0, 255).astype(np.uint8)
        main_output = np.transpose(main_output, (1, 2, 0))  # CHW -> HWC
        
        print(f"å¾Œå‡¦ç†æ¸ˆã¿å‡ºåŠ›: {main_output.shape}")
        
        # ãƒ†ã‚¹ãƒˆç”»åƒä¿å­˜
        cv2.imwrite('output/onnx_gfpgan_test.png', main_output)
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼ãƒ†ã‚¹ãƒˆç”»åƒä¿å­˜å®Œäº†ğŸ’•")
        
        return True
        
    except Exception as e:
        print(f"ã‚‚ã€ã‚‚ã†ï¼ONNXæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def enhance_frame_with_onnx(frame, session):
    """
    å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ONNX GFPGANã§é«˜ç”»è³ªåŒ–
    """
    # 512x512ã«ãƒªã‚µã‚¤ã‚º
    h, w = frame.shape[:2]
    frame_resized = cv2.resize(frame, (512, 512), interpolation=cv2.INTER_LANCZOS4)
    
    # å‰å‡¦ç†
    input_tensor = frame_resized.astype(np.float32) / 255.0
    input_tensor = np.transpose(input_tensor, (2, 0, 1))
    input_tensor = np.expand_dims(input_tensor, axis=0)
    input_tensor = (input_tensor - 0.5) / 0.5
    
    # ONNXæ¨è«–
    try:
        outputs = session.run(None, {'input': input_tensor})
        enhanced = outputs[0][0]  # ãƒãƒƒãƒæ¬¡å…ƒé™¤å»
        
        # å¾Œå‡¦ç†
        enhanced = (enhanced + 1.0) / 2.0
        enhanced = np.clip(enhanced * 255.0, 0, 255).astype(np.uint8)
        enhanced = np.transpose(enhanced, (1, 2, 0))
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        enhanced = cv2.resize(enhanced, (w, h), interpolation=cv2.INTER_LANCZOS4)
        return enhanced
        
    except Exception as e:
        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return frame

def test_video_processing():
    """
    å®Ÿéš›ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã§ONNX GFPGANå‡¦ç†ãƒ†ã‚¹ãƒˆ
    """
    print("ğŸ¬ å®Ÿå‹•ç”»ONNX GFPGANå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹ğŸ’¢")
    
    # ONNX ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
    session = ort.InferenceSession('onnx_models/gfpgan_512x512_stylegan_fixed_direct.onnx', providers=providers)
    
    # ãƒ†ã‚¹ãƒˆå‹•ç”»é¸æŠ
    test_video = 'input/target_video.mp4'
    if not os.path.exists(test_video):
        print(f"ãƒ†ã‚¹ãƒˆå‹•ç”»ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {test_video}")
        return False
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs('output', exist_ok=True)
    temp_dir = tempfile.mkdtemp()
    frames_dir = f"{temp_dir}/frames"
    enhanced_dir = f"{temp_dir}/enhanced"
    os.makedirs(frames_dir, exist_ok=True)
    os.makedirs(enhanced_dir, exist_ok=True)
    
    try:
        # Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆæœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ãƒ†ã‚¹ãƒˆï¼‰
        print("ã¹ã€åˆ¥ã«ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...")
        cmd = [
            "ffmpeg", "-y", "-loglevel", "warning",
            "-i", test_video,
            "-frames:v", "10",  # æœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿
            "-vf", "fps=25",
            f"{frames_dir}/frame_%06d.png"
        ]
        subprocess.run(cmd, check=True)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        import glob
        frame_files = sorted(glob.glob(f"{frames_dir}/frame_*.png"))
        print(f"æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(frame_files)}")
        
        # Step 2: ONNX GFPGANå‡¦ç†
        print("ã‚„ã£ãŸã˜ã‚ƒãªã„ï¼ONNX GFPGANå‡¦ç†é–‹å§‹ã‚ˆâœ¨")
        start_time = time.time()
        
        for i, frame_file in enumerate(tqdm(frame_files, desc="ONNX GFPGAN")):
            frame = cv2.imread(frame_file)
            if frame is None:
                continue
            
            enhanced = enhance_frame_with_onnx(frame, session)
            
            # ä¿å­˜
            output_path = f"{enhanced_dir}/frame_{i+1:06d}.png"
            cv2.imwrite(output_path, enhanced)
        
        processing_time = time.time() - start_time
        print(f"ONNXå‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’ ({len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ )")
        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ãŸã‚Š: {processing_time/len(frame_files):.3f}ç§’")
        
        # Step 3: å‹•ç”»å†æ§‹ç¯‰
        print("å‹•ç”»å†æ§‹ç¯‰ä¸­...")
        output_video = 'output/onnx_gfpgan_test_video.mp4'
        cmd = [
            "ffmpeg", "-y", "-loglevel", "warning",
            "-framerate", "25",
            "-i", f"{enhanced_dir}/frame_%06d.png",
            "-c:v", "libx264",
            "-preset", "fast",
            "-pix_fmt", "yuv420p",
            "-crf", "18",
            output_video
        ]
        subprocess.run(cmd, check=True)
        
        print(f"âœ… ONNX GFPGANå‹•ç”»å‡¦ç†å®Œäº†ï¼")
        print(f"å‡ºåŠ›: {output_video}")
        
        # çµ±è¨ˆæƒ…å ±
        original_size = os.path.getsize(test_video) / (1024*1024)
        output_size = os.path.getsize(output_video) / (1024*1024)
        print(f"å…ƒå‹•ç”»: {original_size:.1f}MB")
        print(f"å‡¦ç†å¾Œ: {output_size:.1f}MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        import shutil
        try:
            shutil.rmtree(temp_dir)
        except:
            pass

if __name__ == "__main__":
    print("ğŸš€ ãƒ„ãƒ³ãƒ‡ãƒ¬ONNX GFPGANçµ±åˆãƒ†ã‚¹ãƒˆğŸ’¢")
    
    # Test 1: å˜ä½“æ¨è«–ãƒ†ã‚¹ãƒˆ
    print("\n=== Test 1: ONNXæ¨è«–ãƒ†ã‚¹ãƒˆ ===")
    if test_onnx_gfpgan_inference():
        print("âœ… ONNXæ¨è«–ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    else:
        print("âŒ ONNXæ¨è«–ãƒ†ã‚¹ãƒˆå¤±æ•—")
        exit(1)
    
    # Test 2: å®Ÿå‹•ç”»å‡¦ç†ãƒ†ã‚¹ãƒˆ
    print("\n=== Test 2: å®Ÿå‹•ç”»å‡¦ç†ãƒ†ã‚¹ãƒˆ ===") 
    if test_video_processing():
        print("âœ… å®Ÿå‹•ç”»å‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
        print("\nã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«å®Œç’§ãªONNXãƒ†ã‚¹ãƒˆã—ã¦ã‚ã’ãŸã‚ã‘ã˜ã‚ƒãªã„ã‹ã‚‰ã­ï¼ğŸ’•")
        print("ã§ã‚‚...ã¡ã‚ƒã‚“ã¨å‹•ä½œç¢ºèªã§ããŸã‹ã‚‰æ„Ÿè¬ã—ãªã•ã„ã‚ˆâœ¨")
    else:
        print("âŒ å®Ÿå‹•ç”»å‡¦ç†ãƒ†ã‚¹ãƒˆå¤±æ•—")
        exit(1)