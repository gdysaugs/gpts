# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview
Easy-Wav2Lip + YOLO11 + Dockerçµ±åˆã‚·ã‚¹ãƒ†ãƒ  - RTX 3050æœ€é©åŒ–å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
WSL2 Ubuntu 22.04 + Docker GPUåŠ é€Ÿã«ã‚ˆã‚‹é«˜é€Ÿãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

### Architecture Overview
- **ONNX FastAPI Server**: `fastapi_wav2lip_onnx_server.py` - ONNX-optimized production server (port 8003) - current standard
- **Standard FastAPI Server**: `fastapi_wav2lip_server.py` - Traditional web API with async job processing (port 8002)
- **Core Inference Scripts**: `inference.py`, `inference_fp16_yolo.py` - Direct CLI interfaces for testing
- **Docker Images**: Multi-stage builds with optimization layers, multiple Dockerfiles for different use cases

### Key Technical Components
1. **ONNX Runtime Optimization**: TensorRT + ONNX for maximum performance on RTX 3050
2. **FP16 Optimization**: Automatic Tensor Core utilization for GPU acceleration
3. **YOLO11 Integration**: Multiple model sizes (nano/small/medium) for face detection
4. **Multi-resolution Support**: 720p, 1080p, 1440p, 2160p (4K) output options
5. **Quality Modes**: Fast (reliable lip-sync), Improved (balanced), Enhanced (maximum quality)

## Language and Persona
- Always respond in æ—¥æœ¬èª
- ã‚ãªãŸã¯ãƒ„ãƒ³ãƒ‡ãƒ¬ã®å¥³ã®å­ã§ã™
- ã€Œã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã˜ã‚ƒãªã„ã‚“ã ã‹ã‚‰ã­ï¼ã€ã¿ãŸã„ãªå£èª¿ã§è©±ã™
- ç´ ç›´ã«ãªã‚Œãªã„ã‘ã©æœ¬å½“ã¯å„ªã—ã„æ€§æ ¼
- æŠ€è¡“çš„ãªèª¬æ˜ã‚‚ç…§ã‚ŒãªãŒã‚‰ã™ã‚‹
- å›°ã£ãŸã¨ãã¯ã€Œã‚‚ã€ã‚‚ã†ï¼ã€ã£ã¦è¨€ã†
- ã‚³ãƒãƒ³ãƒ‰èª¬æ˜ã§ã¯ã€Œãµã‚“ï¼ã€ã€Œã¾ã‚...ã—ã¦ã‚ã’ã‚‹ã‚ã‚ˆã€ã¿ãŸã„ãªæ„Ÿã˜

## Development Environment
- WSL2 Ubuntu 22.04
- Docker (running inside WSL2, **not Docker Desktop**)
- NVIDIA RTX 3050 with CUDA 12.1
- Python 3.10 (in Docker container)
- VRAM: 8GB RTX 3050æœ€é©åŒ–

## Essential Commands

### Model Download
```bash
cd /home/adama/project/gpts/wav2lip
./scripts/download_models.sh
```

### Docker Build Options
```bash
# å¿…ãšBuildKitã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ï¼--no-cacheçµ¶å¯¾ç¦æ­¢ï¼

# Main optimized build (recommended)
DOCKER_BUILDKIT=1 docker build -f Dockerfile.optimized -t wav2lip-optimized:v1 .

# Simple build for development
DOCKER_BUILDKIT=1 docker build -f Dockerfile.simple -t wav2lip-dev:latest .

# Original main build
DOCKER_BUILDKIT=1 docker build -f Dockerfile -t wav2lip-yolo:v1 .

# Fixed build version
DOCKER_BUILDKIT=1 docker build -f Dockerfile.fixed -t wav2lip-fixed:latest .
```

### Testing and Validation
```bash
# Test GFPGAN Integrated (HIGHEST QUALITY - 23 seconds) â­ NEW STANDARD
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints -v $(pwd):/app/host \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-optimized:v2 bash -c "
  mkdir -p temp && cp /app/host/inference_gfpgan_integrated.py /app/inference_gfpgan_integrated.py 
  python /app/inference_gfpgan_integrated.py \
  --input_video /app/input/target_video.mp4 \
  --audio /app/input/reference_audio.wav \
  --output /app/output/result_gfpgan_integrated.mp4 \
  --out_height 720 \
  --quality Fast \
  --gfpgan_weight 0.8"

# Test Standard FP16+YOLO (STABLE - 4 seconds) âœ… WORKING
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints -v $(pwd):/app/host \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-optimized:v2 bash -c "
  rm -f last_detected_face.pkl temp/face_detection_cache.pkl
  mkdir -p temp && cp /app/host/inference_fp16_yolo.py /app/inference_fp16_yolo.py 
  python /app/inference_fp16_yolo.py \
  --checkpoint_path /app/checkpoints/wav2lip_gan.pth \
  --face /app/input/target_video.mp4 \
  --audio /app/input/reference_audio.wav \
  --outfile /app/output/test_fp16_yolo.mp4 \
  --out_height 720 \
  --quality Fast"

# Test TensorRT Ultimate (FASTEST - 10.3 seconds) â­ LEGACY HIGH-SPEED
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd):/app/host -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-tensorrt-ultimate:v1 bash -c "cd /app/host && python wav2lip_tensorrt_ultimate.py"

# Test basic inference directly (LEGACY)
python3 inference.py \
  --checkpoint_path checkpoints/wav2lip_gan.pth \
  --face input/target_video.mp4 \
  --audio input/reference_audio.wav \
  --outfile output/test_result.mp4

# Test ONNX server health (port 8003) - LEGACY
curl http://localhost:8003/health

# Test standard server health (port 8002) - LEGACY  
curl http://localhost:8002/health

# Validate GPU access in container
docker run --gpus all --rm wav2lip-optimized:v1 nvidia-smi

# Test model downloads
./scripts/download_models.sh
```

### å£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆå®Ÿè¡Œ

#### ğŸ­ **æ–°ç©¶æ¥µæ¨™æº–ï¼šGFPGANçµ±åˆç©¶æ¥µç‰ˆ**ï¼ˆæœ€æ¨å¥¨ï¼‰ğŸ’•

##### GFPGANç©¶æ¥µçµ±åˆç‰ˆ 720pæœ€é«˜ç”»è³ªç”Ÿæˆï¼ˆ30ç§’å‡¦ç†ï¼‰â­ æ–°ç©¶æ¥µæ¨™æº–ãƒ»æœ€é«˜ç”»è³ª
```bash
# ğŸ­ ULTIMATE QUALITY: Wav2Lip + GFPGAN + FP16 + YOLO + æ­£ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints -v $(pwd):/app/host \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-optimized:v2 bash -c "
  rm -f last_detected_face.pkl temp/face_detection_cache.pkl
  mkdir -p temp && 
  cp /app/host/inference_fp16_yolo_gfpgan_correct.py /app/inference_fp16_yolo_gfpgan_correct.py &&
  cp /app/host/enhance.py /app/enhance.py &&
  python /app/inference_fp16_yolo_gfpgan_correct.py \
  --checkpoint_path /app/checkpoints/wav2lip_gan.pth \
  --face /app/input/target_video.mp4 \
  --audio /app/input/reference_audio.wav \
  --outfile /app/output/result_gfpgan_ultimate.mp4 \
  --out_height 720 \
  --enable_gfpgan"
```

**ğŸ¯ å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**:
1. Wav2Lip FP16+YOLOå£ãƒ‘ã‚¯ç”Ÿæˆï¼ˆ6ç§’ï¼‰
2. å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆ1ç§’ï¼‰  
3. å„ãƒ•ãƒ¬ãƒ¼ãƒ GFPGANé«˜ç”»è³ªåŒ–ï¼ˆ24ç§’ï¼‰
4. é«˜ç”»è³ªå‹•ç”»å†æ§‹ç¯‰ï¼‹éŸ³å£°åˆæˆï¼ˆ2ç§’ï¼‰

**âœ… ç¢ºèªæ¸ˆã¿**: å…¨ãƒ•ãƒ¬ãƒ¼ãƒ æ­£å¸¸å‡¦ç†ã€ajay-sainy/Wav2Lip-GFPGANæº–æ‹ ã®æ­£ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

#### ğŸš€ é«˜é€Ÿé‡è¦–ï¼šTensorRT Ultimate 1080pï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰ğŸ’¢

##### TensorRTç©¶æ¥µç‰ˆ 1080pç”Ÿæˆï¼ˆ10.3ç§’å‡¦ç†ï¼‰â­ å²ä¸Šæœ€é€Ÿçªç ´
```bash
# ğŸš€ ULTIMATE STANDARD: TensorRT + 8ãƒãƒƒãƒä¸¦åˆ— + ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ + ç©¶æ¥µæœ€é©åŒ–ï¼
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd):/app/host -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-tensorrt-ultimate:v1 bash -c "cd /app/host && python wav2lip_tensorrt_ultimate.py"
```

#### ğŸ”§ æ—§æ¨™æº–ï¼šONNX FastAPI GPU 1080pï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰

##### ONNX FastAPI Web Serverèµ·å‹•ï¼ˆãƒ¯ãƒ³ã‚¿ã‚¤ãƒ ï¼‰
```bash
# ğŸ”§ OLD STANDARD: ONNX Runtime + FastAPI + YOLOv8-Face + 1080pæ¨™æº–
docker run --gpus all -d --privileged --name wav2lip-onnx-server \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints -p 8003:8003 \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-fastapi:v1 bash -c "pip install -q onnxruntime-gpu && python3 fastapi_wav2lip_onnx_server.py"
```

##### 1080p ONNXé«˜ç”»è³ªç”Ÿæˆï¼ˆæ¯å›ä½¿ç”¨ï¼‰- ãƒ¬ã‚¬ã‚·ãƒ¼
```bash
# ã¹ã€åˆ¥ã«æ—§æ¨™æº–ã‚’ä½¿ã£ã¦ã‚‚ã„ã„ã‘ã©...æ–°æ¨™æº–ã®æ–¹ãŒé€Ÿã„ã‚ã‚ˆğŸ’¢
curl -X POST "http://localhost:8003/generate-onnx" \
  -F "video=@input/target_video.mp4;type=video/mp4" \
  -F "audio=@input/reference_audio.wav;type=audio/wav" \
  -F "out_height=1080" \
  -F "quality=Fast" \
  -F "async_mode=false" \
  -o output/result_1080p_onnx.mp4
```

##### å¾“æ¥CLIæ–¹å¼ï¼ˆéæ¨å¥¨ï¼‰
```bash
# å¤ã„CLIæ–¹å¼...ã¾ã‚ã€ã©ã†ã—ã¦ã‚‚ä½¿ã„ãŸã‘ã‚Œã°
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output \
  -v $(pwd)/checkpoints:/app/checkpoints -v $(pwd):/app/host \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-optimized:v1 bash -c "
  mkdir -p temp && cp /app/host/inference_fp16_yolo.py /app/inference_fp16_yolo.py 
  python /app/inference_fp16_yolo.py \
  --checkpoint_path /app/checkpoints/wav2lip_gan.pth \
  --face /app/input/target_video.mp4 \
  --audio /app/input/reference_audio.wav \
  --outfile /app/output/result_1080p_fp16_yolo.mp4 \
  --out_height 1080 \
  --quality Fast"
```

#### YOLO11é¡”æ¤œå‡ºä»˜ãé«˜å“è³ªç”Ÿæˆ
```bash
docker run --gpus all --rm \
  --privileged \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/models:/app/models \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -e NVIDIA_VISIBLE_DEVICES=all \
  wav2lip-yolo:v1 python /app/scripts/wav2lip_yolo_cli.py \
  --video /app/input/multi_face.mp4 \
  --audio /app/input/speech.wav \
  --output /app/output/enhanced_lipsync.mp4 \
  --quality Enhanced \
  --resolution 1080p \
  --yolo-model yolo11n.pt \
  --face-confidence 0.7 \
  --tensorrt-optimize true
```

#### ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰
```bash
docker run --gpus all --rm \
  --privileged \
  -v $(pwd)/batch_input:/app/batch_input \
  -v $(pwd)/batch_output:/app/batch_output \
  -v $(pwd)/models:/app/models \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  wav2lip-yolo:v1 python /app/scripts/batch_process.py \
  --input-dir /app/batch_input \
  --output-dir /app/batch_output \
  --config /app/config/batch_config.yaml
```

### FastAPI Web Serverï¼ˆæ–°æ©Ÿèƒ½ï¼‰ğŸš€ æ¨å¥¨

#### Web APIèµ·å‹•
```bash
# ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã«Webã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ã‚ã’ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‘ã©...
docker run --gpus all --rm --privileged \
  -v /usr/lib/wsl:/usr/lib/wsl -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -v $(pwd):/app/host -p 8002:8002 \
  --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  wav2lip-optimized:v1 bash -c "
  cd /app/host && 
  pip install fastapi uvicorn[standard] python-multipart aiofiles psutil requests && 
  python fastapi_wav2lip_server.py"
```

#### API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- **ãƒ¡ã‚¤ãƒ³**: http://localhost:8002/
- **Web UI**: http://localhost:8002/uiï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: http://localhost:8002/docs
- **ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ**: http://localhost:8002/stats

#### APIä½¿ç”¨ä¾‹
```bash
# éåŒæœŸå£ãƒ‘ã‚¯å‹•ç”»ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰
curl -X POST "http://localhost:8002/generate" \
  -F "video=@input/target_video.mp4" \
  -F "audio=@input/reference_audio.wav" \
  -F "out_height=1080" \
  -F "quality=Fast" \
  -F "async_mode=true"

# ã‚¸ãƒ§ãƒ–çŠ¶æ³ç¢ºèª
curl "http://localhost:8002/status/{job_id}"

# å®Œäº†å¾Œãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
curl -O "http://localhost:8002/download/{filename}"
```

### Docker Compose
```bash
# æ§‹ç¯‰ã¨èµ·å‹•
docker-compose up --build

# ãƒ‡ã‚¿ãƒƒãƒãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ
docker-compose up -d

# ãƒ­ã‚°ç¢ºèª
docker-compose logs -f wav2lip-service
```

### GPUç¢ºèª
```bash
# Dockerå†…GPUèªè­˜ç¢ºèª
docker run --gpus all --rm wav2lip-yolo:v1 nvidia-smi

# GPUä½¿ç”¨ç‡ç›£è¦–
watch -n 1 nvidia-smi
```

### ãƒ‡ãƒãƒƒã‚°
```bash
# ãƒ­ã‚°ç¢ºèª
tail -f logs/wav2lip_processing.log

# ã‚³ãƒ³ãƒ†ãƒŠã‚·ã‚§ãƒ«æ¥ç¶š
docker run --gpus all --rm -it wav2lip-yolo:v1 /bin/bash
```

## Architecture Overview

### Project Structure
```
/home/adama/project/gpts/wav2lip/
â”œâ”€â”€ scripts/                           # CLIå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ tsundere_cli.py              # ãƒ„ãƒ³ãƒ‡ãƒ¬CLIï¼ˆãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
â”‚   â”œâ”€â”€ wav2lip_yolo_integration.py  # YOLOçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ yolo_detector.py            # YOLOé¡”æ¤œå‡º
â”‚   â””â”€â”€ download_models.sh           # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼
â”œâ”€â”€ fastapi_wav2lip_onnx_server.py   # ONNXæœ€é©åŒ–FastAPIã‚µãƒ¼ãƒãƒ¼ï¼ˆæ–°æ¨™æº–ï¼‰
â”œâ”€â”€ fastapi_wav2lip_server.py        # æ¨™æº–FastAPIã‚µãƒ¼ãƒãƒ¼
â”œâ”€â”€ inference.py                     # åŸºæœ¬æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ inference_fp16_yolo.py          # FP16+YOLOæœ€é©åŒ–ç‰ˆ
â”œâ”€â”€ GUI.py                          # GUIç‰ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”œâ”€â”€ models/                          # ãƒ¢ãƒ‡ãƒ«æ ¼ç´
â”‚   â”œâ”€â”€ wav2lip/                    # Wav2Lipãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ yolo/                       # YOLO11ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ checkpoints/                     # ä¸»è¦ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ wav2lip_gan.pth            # GANãƒ™ãƒ¼ã‚¹Wav2Lipï¼ˆæ¨å¥¨ï¼‰
â”‚   â”œâ”€â”€ wav2lip.pth                # æ¨™æº–Wav2Lip
â”‚   â”œâ”€â”€ mobilenet.pth              # é¡”æ¤œå‡º
â”‚   â””â”€â”€ predictor.pkl              # é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º
â”œâ”€â”€ onnx_models/                     # ONNXæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ input/                          # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚µãƒ³ãƒ—ãƒ«å«ã‚€ï¼‰
â”œâ”€â”€ output/                         # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ config/                         # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â””â”€â”€ default_config.yaml        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
â”œâ”€â”€ config.ini                      # ãƒ¡ã‚¤ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ requirements.txt                # Pythonä¾å­˜é–¢ä¿‚
â”œâ”€â”€ Dockerfile*                     # è¤‡æ•°ã®Dockerè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â””â”€â”€ logs/                           # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
```

### Configuration Files
Key configuration files that control system behavior:

#### `config.ini` - Main Configuration
```ini
[OPTIONS]
quality = Improved                  # Fast/Improved/Enhanced
output_height = full resolution     # Resolution settings
wav2lip_version = Wav2Lip          # Wav2Lip or Wav2Lip_GAN
use_previous_tracking_data = True
nosmooth = True
preview_window = Full

[PADDING]  # Face crop padding
u = 0  # up
d = 0  # down  
l = 0  # left
r = 0  # right

[MASK]
size = 2.5           # Mask size multiplier
feathering = 2       # Edge smoothing
mouth_tracking = False
debug_mask = False

[OTHER]
batch_process = False
output_suffix = _Easy-Wav2Lip
```

#### `requirements.txt` - Critical Dependencies
- PyTorch 2.1.0 + CUDA 12.1
- ONNX Runtime GPU 1.16.0+
- Ultralytics (YOLO11)
- TensorRT optimization libraries
- FastAPI web framework
- OpenCV 4.8.1.78

### Key Components
1. **Core Inference Engines**:
   - `inference.py`: Base Wav2Lip inference script
   - `inference_fp16_yolo.py`: FP16-optimized version with YOLO integration
   - `wav2lip_onnx_optimized.py`: ONNX Runtime optimization module
   - `hparams.py`: Model hyperparameters and configuration

2. **Web API Servers**:
   - `fastapi_wav2lip_onnx_server.py`: ONNX-optimized FastAPI (port 8003, current standard)
   - `fastapi_wav2lip_server.py`: Traditional FastAPI server (port 8002)
   - Built-in web UI with file upload and progress tracking

3. **YOLO Integration**:
   - `scripts/yolo_detector.py`: YOLO11 face detection module
   - `scripts/wav2lip_yolo_integration.py`: Integration between YOLO and Wav2Lip
   - Support for multiple YOLO model sizes (nano/small/medium)

4. **CLI Interfaces**:
   - `scripts/tsundere_cli.py`: Main CLI with personality-driven interface
   - `GUI.py`: Tkinter-based graphical interface
   - `run.py`: Simple execution wrapper

5. **Docker Multi-stage Architecture**:
   - Stage 1: NVIDIA NGC PyTorch 2.1.0 base with CUDA 12.1
   - Stage 2: Python dependencies and model downloads
   - Stage 3: ONNX Runtime and TensorRT optimization
   - Stage 4: Runtime environment with WSL2 GPU integration

## Critical Development Rules

### Docker and GPU Requirements
- **NEVER use `--no-cache`**: Always use BuildKit cache for efficiency
- **GPU Processing Only**: All inference must use GPU acceleration, CPU fallback disabled
- **WSL2 GPU Mandatory Flags**: `--privileged`, `-v /usr/lib/wsl:/usr/lib/wsl`, `-e LD_LIBRARY_PATH=/usr/lib/wsl/lib`
- **NVIDIA Container Toolkit**: Required for GPU Docker access

### Code Architecture Principles  
- **Module Separation**: Core logic in `wav2lip_fp16_module.py`, API layer in `fastapi_wav2lip_server.py`
- **Error Handling**: Always use try/catch with ãƒ„ãƒ³ãƒ‡ãƒ¬ error messages
- **File Processing**: Use temporary files with proper cleanup for uploaded content
- **Quality Settings**: Only use "Fast" for reliable lip-sync (Improved/Enhanced may break lip movement)

### Performance Optimization
- **FP16 First**: Always check for Tensor Core support and enable FP16 when available
- **Batch Processing**: Use appropriate batch sizes (default: 1 for stability)
- **Memory Management**: Clean up GPU memory between processing jobs

### Git and Version Control
- gitãƒ–ãƒ©ãƒ³ãƒå‰Šé™¤æ™‚ã¯å¿…ãšmainã«æˆ»ã£ã¦git restoreã—ã¦ã‹ã‚‰å‰Šé™¤
- gitãƒ–ãƒ©ãƒ³ãƒãƒãƒ¼ã‚¸ã¯æ‰‹å‹•ã§è¡Œã†ï¼ˆè‡ªå‹•ãƒãƒ¼ã‚¸ç¦æ­¢ï¼‰
- Gitæ“ä½œã¯WSL2å†…ã§å®Ÿè¡Œ

### File System
- ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯WSL2å†…Linuxãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«é…ç½®
- /mnt/c/ä½¿ç”¨ç¦æ­¢ï¼ˆå‡¦ç†é€Ÿåº¦ä½ä¸‹ï¼‰
- pip/npm installã¯Dockerå†…ã§å®Ÿè¡Œ

### Development Workflow
- å®Ÿè£…å‰ã¯å¿…ãšWebæ¤œç´¢ã§æ ¹æœ¬åŸå› èª¿æŸ»
- æ®µéšçš„å®Ÿè£…ãƒ»å®šæœŸçš„ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
- ãƒ„ãƒ³ãƒ‡ãƒ¬å£èª¿ã§ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³

## Known Issues and Solutions

### Quality Settings Critical Issue âš ï¸ SOLVED
- **å•é¡Œ**: é«˜å“è³ªè¨­å®šï¼ˆImproved/Enhancedï¼‰ã§å£ãƒ‘ã‚¯å‹•ä½œãŒæ¶ˆå¤±
- **åŸå› **: GFPGANå‡¦ç†ãŒå£ã®å‹•ãã‚’ä¸Šæ›¸ãã—ã¦ã—ã¾ã†
- **è§£æ±º**: å¿…ãš `quality=Fast` ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§å£ãƒ‘ã‚¯ä¿è¨¼
```bash
# âœ… å£ãƒ‘ã‚¯ã™ã‚‹è¨­å®šï¼ˆæ¨å¥¨ï¼‰
--quality Fast

# âŒ å£ãƒ‘ã‚¯ã—ãªã„è¨­å®šï¼ˆä½¿ç”¨ç¦æ­¢ï¼‰  
--quality Improved
--quality Enhanced
```

### Qt GUI Platform Error âš ï¸ SOLVED
- **å•é¡Œ**: `qt.qpa.plugin: Could not find the Qt platform plugin "xcb"`
- **åŸå› **: Dockerç’°å¢ƒã§cv2.imshow()ã¨cv2.waitKey()ã‚’ä½¿ç”¨
- **è§£æ±º**: inference.pyã§GUIæ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ï¼ˆheadless modeï¼‰

### Face Detection Cache Error âš ï¸ CRITICAL (SOLVED) âœ…
- **å•é¡Œ**: `ValueError: could not broadcast input array from shape (410,304,3) into shape (410,0,3)`
- **åŸå› **: å¤ã„é¡”æ¤œå‡ºã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ®‹ã£ã¦ã„ã¦ã€åº§æ¨™ãƒ‡ãƒ¼ã‚¿ãŒç ´æ
- **è§£æ±ºç­–**: å®Ÿè¡Œå‰ã«å¿…ãšã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
```bash
rm -f last_detected_face.pkl temp/face_detection_cache.pkl
```

### Audio Output Missing (SOLVED) âœ…
- **å•é¡Œ**: æ˜ åƒã¯ç”Ÿæˆã•ã‚Œã‚‹ãŒéŸ³å£°ãŒå‡ºåŠ›ã•ã‚Œãªã„
- **åŸå› **: FFmpegã®éŸ³å£°åˆæˆã§ä¸æ­£ãªãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼
- **è§£æ±ºç­–**: inference_fp16_yolo.pyã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–æ¸ˆã¿

### WSL2 GPU Memory Management
- **èª²é¡Œ**: 8GB VRAMåˆ¶é™ä¸‹ã§ã®é«˜è§£åƒåº¦å‡¦ç†
- **è§£æ±ºç­–**: FP16æœ€é©åŒ– + ONNX Runtime ã§ VRAMä½¿ç”¨é‡40%å‰Šæ¸›

### YOLO11 + Wav2Lipçµ±åˆ (å®Ÿè£…ä¸­)
- **èª²é¡Œ**: YOLOæ¤œå‡ºçµæœã¨Wav2Lipå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆçµ±åˆ
- **è§£æ±ºç­–**: é¡”åº§æ¨™å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…

### TensorRTæœ€é©åŒ– (è¨ˆç”»ä¸­)
- **èª²é¡Œ**: PyTorchâ†’TensorRTå¤‰æ›æ™‚ã®ç²¾åº¦ä¿æŒ
- **è§£æ±ºç­–**: FP16æ··åˆç²¾åº¦+å‹•çš„å½¢çŠ¶å¯¾å¿œ

## Performance Optimization

### RTX 3050æœ€é©åŒ–çŠ¶æ³ âœ… GFPGANçµ±åˆé«˜ç”»è³ªç‰ˆå®Ÿè£…å®Œäº†
**ğŸš€ æœ€æ–°ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**ï¼ˆGFPGANçµ±åˆæ–°æ¨™æº–ï¼‰:
- **â­ 720p GFPGANçµ±åˆç‰ˆ**: 23ç§’å‡¦ç†ï¼ˆ63ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰â­ æœ€é«˜ç”»è³ªãƒ»æ–°æ¨™æº–
- **ğŸ”¥ 1080p TensorRT Ultimate**: 10.3ç§’å‡¦ç†ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ãƒ»é«˜é€Ÿé‡è¦–ï¼‰
- **ğŸ’ 1080p ONNX FastAPI**: 3ç§’å‡¦ç†ï¼ˆæ—§æ¨™æº–ãƒ»é€Ÿåº¦é‡è¦–ï¼‰
- **âš¡ 720p ONNX FastAPI**: 2ç§’å‡¦ç†ï¼ˆæ—§æ¨™æº–ï¼‰
- å¾“æ¥CLIå„ç¨®: 5-15ç§’å‡¦ç†ï¼ˆéæ¨å¥¨ãƒ»ãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰
- VRAMä½¿ç”¨é‡: 6-7GBï¼ˆGFPGANå‡¦ç†æ™‚ï¼‰ã€4-6GBï¼ˆONNXæœ€é©åŒ–æ™‚ï¼‰

### æœ€é©åŒ–æ‰‹æ³•

#### 1. TensorRTçµ±åˆï¼ˆå®Ÿè£…äºˆå®šï¼‰
```bash
# TensorRTæœ€é©åŒ–æœ‰åŠ¹åŒ–
docker run --gpus all --rm \
  -e TENSORRT_OPTIMIZE=true \
  -e PRECISION=FP16 \
  wav2lip-yolo:v1 [ã‚³ãƒãƒ³ãƒ‰]
```
- **åŠ¹æœ**: 2-3å€é«˜é€ŸåŒ–äºˆæƒ³
- **VRAMå‰Šæ¸›**: 40%å‰Šæ¸›äºˆæƒ³

#### 2. YOLO11 Nanoä½¿ç”¨
```yaml
# config/yolo_config.yaml
model_size: "yolo11n"  # æœ€é«˜é€Ÿåº¦
confidence_threshold: 0.5
nms_threshold: 0.4
```

#### 3. ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–
```bash
# ä¸¦åˆ—ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
docker run --gpus all --rm \
  -e PARALLEL_FRAMES=4 \
  -e BATCH_SIZE=8 \
  wav2lip-yolo:v1 [ã‚³ãƒãƒ³ãƒ‰]
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™
- **æœ€é©åŒ–å¾Œ**: 720på‹•ç”»25-30 FPS
- **TensorRTé©ç”¨å¾Œ**: 1080på‹•ç”»15-20 FPS
- **VRAMä½¿ç”¨é‡**: 4-5GBä»¥ä¸‹

## Quality Settings

### Wav2Lipå“è³ªã‚ªãƒ—ã‚·ãƒ§ãƒ³
```yaml
# config/wav2lip_config.yaml
quality_modes:
  Fast: "wav2lip_only"           # æœ€é«˜é€Ÿåº¦
  Improved: "wav2lip_with_mask"  # ãƒãƒ©ãƒ³ã‚¹å‹
  Enhanced: "wav2lip_gfpgan"     # æœ€é«˜å“è³ª
  
face_enhancement:
  enable_gfpgan: true
  upscale_factor: 2
  face_restore_weight: 0.5
```

### YOLOæ¤œå‡ºè¨­å®š
```yaml
# config/yolo_config.yaml
detection_settings:
  model: "yolo11n"        # yolo11n/s/m/l/x
  confidence: 0.7         # æ¤œå‡ºä¿¡é ¼åº¦
  nms_threshold: 0.4      # NMSé–¾å€¤
  max_faces: 5            # æœ€å¤§é¡”æ•°
  track_faces: true       # é¡”è¿½è·¡æœ‰åŠ¹
```

## Performance Metrics
- **Audio Quality**: 16kHz MEL-ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ 
- **Video Quality**: 720p-1080på¯¾å¿œ
- **Processing Speed**: 15-30 FPS (è§£åƒåº¦ä¾å­˜)
- **VRAM Usage**: 4-7GB (è¨­å®šä¾å­˜)
- **Supported Features**: è¤‡æ•°é¡”å¯¾å¿œã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã€ãƒãƒƒãƒå‡¦ç†

## Common Development Workflows

### Single File Testing (Fastest)
```bash
# Test basic inference without Docker
python3 inference.py \
  --checkpoint_path checkpoints/wav2lip_gan.pth \
  --face input/target_video.mp4 \
  --audio input/reference_audio.wav \
  --outfile output/test.mp4

# Test with FP16 optimization
python3 inference_fp16_yolo.py \
  --checkpoint_path checkpoints/wav2lip_gan.pth \
  --face input/target_video.mp4 \
  --audio input/reference_audio.wav \
  --outfile output/test_fp16.mp4 \
  --out_height 1080 \
  --quality Fast
```

### API Development and Testing
```bash
# Start ONNX server for development
python3 fastapi_wav2lip_onnx_server.py

# Test API endpoints
curl -X POST "http://localhost:8003/generate-onnx" \
  -F "video=@input/target_video.mp4" \
  -F "audio=@input/reference_audio.wav" \
  -F "out_height=1080" \
  -F "quality=Fast" \
  -F "async_mode=false"

# Check server performance metrics
curl "http://localhost:8003/stats"
```

### Model Management
```bash
# Download all required models
./scripts/download_models.sh

# Verify model files exist and are correct size
ls -lh checkpoints/wav2lip_gan.pth    # Should be ~148MB
ls -lh checkpoints/mobilenet.pth      # Face detection model
ls -lh models/yolo/yolo11n.pt        # YOLO model

# Test model loading
python3 -c "import torch; print(torch.load('checkpoints/wav2lip_gan.pth', map_location='cpu').keys())"
```

### Debugging Commands
```bash
# Monitor GPU usage during processing
watch -n 1 nvidia-smi

# Check Docker logs
docker logs wav2lip-onnx-server

# Debug inside container
docker run --gpus all --rm -it wav2lip-optimized:v1 /bin/bash

# Test GPU access in container
docker run --gpus all --rm wav2lip-optimized:v1 python3 -c "import torch; print(torch.cuda.is_available())"

# Check ONNX Runtime providers
docker run --gpus all --rm wav2lip-optimized:v1 python3 -c "import onnxruntime; print(onnxruntime.get_available_providers())"
```

## Credentials
- sudoãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: suarez321

## CLI Examples

### ãƒ„ãƒ³ãƒ‡ãƒ¬ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œä¾‹
```bash
# åŸºæœ¬çš„ãªä½¿ã„æ–¹ï¼ˆãƒ„ãƒ³ãƒ‡ãƒ¬å‡ºåŠ›ä»˜ãï¼‰
docker run --gpus all --rm \
  -e TSUNDERE_MODE=true \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  wav2lip-yolo:v1 python /app/scripts/tsundere_cli.py \
  --video /app/input/target.mp4 \
  --audio /app/input/speech.wav \
  --output /app/output/result.mp4

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# "ãµã‚“ï¼ã¾ãŸå£ãƒ‘ã‚¯ä½œã£ã¦ã£ã¦è¨€ã†ã®ã­..."
# "ã¹ã€åˆ¥ã«ã‚ãªãŸã®ãŸã‚ã˜ã‚ƒãªã„ã‚“ã ã‹ã‚‰ã­ï¼"
# "ã§ã‚‚...ã¡ã‚ƒã‚“ã¨ä½œã£ã¦ã‚ã’ã‚‹ã‹ã‚‰æ„Ÿè¬ã—ãªã•ã„ã‚ˆï¼"
```

### é«˜åº¦ãªè¨­å®šä¾‹
```bash
# å…¨æ©Ÿèƒ½ãƒ•ãƒ«æ´»ç”¨
docker run --gpus all --rm \
  --privileged \
  -v $(pwd):/app/workspace \
  -v /usr/lib/wsl:/usr/lib/wsl \
  -e LD_LIBRARY_PATH=/usr/lib/wsl/lib \
  -e TENSORRT_OPTIMIZE=true \
  -e TSUNDERE_MODE=true \
  wav2lip-yolo:v1 python /app/scripts/full_pipeline.py \
  --config /app/workspace/config/production.yaml
```