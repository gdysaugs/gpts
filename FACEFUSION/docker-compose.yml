version: '3.8'

services:
  facefusion:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: facefusion:3.3.0
    container_name: facefusion-cli
    runtime: nvidia
    privileged: true
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - LD_LIBRARY_PATH=/usr/lib/wsl/lib:$LD_LIBRARY_PATH
      - FACEFUSION_SKIP_DOWNLOAD=1
      - FACEFUSION_PROCESSORS=face_swapper
    volumes:
      # WSL2 GPU support
      - /usr/lib/wsl:/usr/lib/wsl
      # Input/Output
      - ./input:/app/input
      - ./output:/app/output
      - ./temp:/app/temp
      # Scripts
      - ./scripts:/app/scripts
      # Models (if pre-downloaded)
      - ./models:/app/.assets/models
      # Cache
      - facefusion-cache:/root/.cache
    shm_size: '8gb'
    ulimits:
      memlock:
        soft: -1
        hard: -1
      stack:
        soft: 67108864
        hard: 67108864
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python", "facefusion.py", "--help"]
    stdin_open: true
    tty: true

  # Optional: API server service
  facefusion-api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: facefusion:3.3.0
    container_name: facefusion-api
    runtime: nvidia
    privileged: true
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - LD_LIBRARY_PATH=/usr/lib/wsl/lib:$LD_LIBRARY_PATH
      - FACEFUSION_SKIP_DOWNLOAD=1
      - FACEFUSION_PROCESSORS=face_swapper
    volumes:
      # WSL2 GPU support
      - /usr/lib/wsl:/usr/lib/wsl
      # Input/Output
      - ./input:/app/input
      - ./output:/app/output
      - ./temp:/app/temp
      # Scripts
      - ./scripts:/app/scripts
      # Models (if pre-downloaded)
      - ./models:/app/.assets/models
      # Cache
      - facefusion-cache:/root/.cache
    shm_size: '8gb'
    ulimits:
      memlock:
        soft: -1
        hard: -1
      stack:
        soft: 67108864
        hard: 67108864
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - "7860:7860"  # Gradio UI port
    command: ["python", "facefusion.py", "--ui-layouts", "default", "--server-port", "7860"]
    profiles:
      - api

volumes:
  facefusion-cache:
    driver: local