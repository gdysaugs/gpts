#!/usr/bin/env python3
"""
SadTalker FastAPI ã‚µãƒ¼ãƒãƒ¼
æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§é«˜é€Ÿãªå‹•ç”»ç”Ÿæˆã‚’æä¾›
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import FileResponse, JSONResponse
import os
import sys
import shutil
import tempfile
import time
from pathlib import Path
import torch
import subprocess

# SadTalkerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹è¿½åŠ 
sys.path.insert(0, './src')

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.utils.preprocess import CropAndExtract
from src.test_audio2coeff import Audio2Coeff
from src.facerender.animate import AnimateFromCoeff
from src.generate_batch import get_data
from src.generate_facerender_batch import get_facerender_data
from src.utils.init_path import init_path

# CUDAæœ€é©åŒ–è¨­å®š
torch.backends.cudnn.benchmark = True
torch.backends.cuda.matmul.allow_tf32 = True

# FastAPIã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = FastAPI(title="SadTalker API", version="1.0.0")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
device = "cuda"
checkpoint_dir = "./checkpoints"
config_dir = "./src/config"
size = 256
old_version = False

# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘å®Ÿè¡Œï¼‰
print("ğŸ”„ SadTalkerãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
try:
    sadtalker_paths = init_path(checkpoint_dir, config_dir, size, old_version, "crop")
    preprocess_model = CropAndExtract(sadtalker_paths, device)
    audio_to_coeff = Audio2Coeff(sadtalker_paths, device)
    animate_from_coeff = AnimateFromCoeff(sadtalker_paths, device)
    print("âœ… SadTalkerãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
except Exception as e:
    print(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
    preprocess_model = None
    audio_to_coeff = None
    animate_from_coeff = None

@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"message": "SadTalker API", "status": "running"}

@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    if all([preprocess_model, audio_to_coeff, animate_from_coeff]):
        return {"status": "healthy", "models": "loaded"}
    else:
        raise HTTPException(status_code=500, detail="Models not loaded")

@app.post("/generate")
async def generate_video(
    image: UploadFile = File(..., description="ã‚½ãƒ¼ã‚¹ç”»åƒ (JPG/PNG)"),
    audio: UploadFile = File(..., description="ã‚½ãƒ¼ã‚¹éŸ³å£° (WAV/MP3)"),
    expression_scale: float = Form(0.7, description="è¡¨æƒ…ã‚¹ã‚±ãƒ¼ãƒ« (0.0-2.0)"),
    still_mode: bool = Form(True, description="é™æ­¢ãƒ¢ãƒ¼ãƒ‰"),
    use_gfpgan: bool = Form(True, description="GFPGANå“è³ªå‘ä¸Š"),
    preprocess: str = Form("crop", description="å‰å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ (crop/full)")
):
    """
    ç”»åƒã¨éŸ³å£°ã‹ã‚‰å£ãƒ‘ã‚¯å‹•ç”»ã‚’ç”Ÿæˆ
    
    æœ€é©åŒ–æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - expression_scale: 0.7 (è‡ªç„¶ãªè¡¨æƒ…)
    - still_mode: True (æ§ãˆã‚ãªå‹•ã)
    - preprocess: crop (é«˜é€Ÿå‡¦ç†)
    - batch_size: 3 (RTX 3050ç”¨)
    """
    if not all([preprocess_model, audio_to_coeff, animate_from_coeff]):
        raise HTTPException(status_code=500, detail="SadTalker models not loaded")
    
    # å‡¦ç†é–‹å§‹æ™‚åˆ»
    start_time = time.time()
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            image_path = temp_path / f"input_{int(time.time())}.jpg"
            audio_path = temp_path / f"audio_{int(time.time())}.wav"
            
            with open(image_path, "wb") as f:
                shutil.copyfileobj(image.file, f)
            
            with open(audio_path, "wb") as f:
                shutil.copyfileobj(audio.file, f)
            
            print(f"ğŸ“ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†")
            
            # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            save_dir = temp_path / "results"
            save_dir.mkdir(exist_ok=True)
            
            # 1. å‰å‡¦ç†
            first_frame_dir = save_dir / 'first_frame_dir'
            first_frame_dir.mkdir(exist_ok=True)
            
            print("ğŸ”„ å‰å‡¦ç†é–‹å§‹...")
            preprocess_start = time.time()
            
            first_coeff_path, crop_pic_path, crop_info = preprocess_model.generate(
                str(image_path), str(first_frame_dir), preprocess, 
                source_image_flag=True, pic_size=size
            )
            
            preprocess_time = time.time() - preprocess_start
            print(f"âœ… å‰å‡¦ç†å®Œäº†: {preprocess_time:.1f}ç§’")
            
            if first_coeff_path is None:
                raise HTTPException(status_code=400, detail="é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            # 2. éŸ³å£°è§£æ
            print("ğŸ”„ éŸ³å£°è§£æé–‹å§‹...")
            audio_start = time.time()
            
            batch = get_data(first_coeff_path, str(audio_path), device, 
                           ref_eyeblink_coeff_path=None, still=still_mode)
            
            coeff_path = audio_to_coeff.generate(batch, str(save_dir), 0, None)
            
            audio_time = time.time() - audio_start
            print(f"âœ… éŸ³å£°è§£æå®Œäº†: {audio_time:.1f}ç§’")
            
            # 3. å‹•ç”»ç”Ÿæˆ
            print("ğŸ”„ å‹•ç”»ç”Ÿæˆé–‹å§‹...")
            render_start = time.time()
            
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯3ã‚’ç¶­æŒï¼ˆRTX 3050ç”¨ï¼‰
            batch_size = 3
            
            # æœ€é©åŒ–æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ‡ãƒ¼ã‚¿æº–å‚™
            data = get_facerender_data(
                coeff_path, crop_pic_path, first_coeff_path, str(audio_path),
                batch_size, None, None, None,
                expression_scale=expression_scale,
                still_mode=still_mode,
                preprocess=preprocess,
                img_size=size
            )
            
            # GFPGANè¨­å®š
            enhancer = "gfpgan" if use_gfpgan else None
            
            # å‹•ç”»ç”Ÿæˆ
            result_path = animate_from_coeff.generate(
                data, str(save_dir), str(image_path), crop_info,
                enhancer=enhancer, background_enhancer=None,
                preprocess=preprocess, img_size=size
            )
            
            render_time = time.time() - render_start
            print(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {render_time:.1f}ç§’")
            
            # åˆè¨ˆå‡¦ç†æ™‚é–“
            total_time = time.time() - start_time
            
            # çµæœç¢ºèª
            if result_path and os.path.exists(result_path):
                file_size = os.path.getsize(result_path)
                print(f"ğŸ‰ æˆåŠŸ! å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’, ã‚µã‚¤ã‚º: {file_size} bytes")
                
                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
                output_dir = Path("output")
                output_dir.mkdir(exist_ok=True)
                
                # æ¨©é™ä¿®æ­£ï¼ˆDockerç”¨ï¼‰
                subprocess.run([
                    "docker", "run", "--rm", "-v", f"{os.getcwd()}:/work",
                    "busybox", "chown", "-R", f"{os.getuid()}:{os.getgid()}", "/work/output"
                ], capture_output=True)
                
                timestamp = int(time.time())
                final_path = output_dir / f"sadtalker_api_{timestamp}.mp4"
                shutil.copy2(result_path, final_path)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ã‚¹ãƒãƒ³ã‚¹
                return FileResponse(
                    path=str(final_path),
                    media_type='video/mp4',
                    filename=f"sadtalker_result_{timestamp}.mp4",
                    headers={
                        "X-Processing-Time": f"{total_time:.1f}",
                        "X-File-Size": str(file_size)
                    }
                )
            else:
                raise HTTPException(status_code=500, detail="å‹•ç”»ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        except HTTPException:
            raise
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")

@app.get("/info")
async def get_info():
    """APIæƒ…å ±å–å¾—"""
    return {
        "version": "1.0.0",
        "models_loaded": all([preprocess_model, audio_to_coeff, animate_from_coeff]),
        "device": device,
        "optimizations": {
            "cudnn_benchmark": torch.backends.cudnn.benchmark,
            "tf32_enabled": torch.backends.cuda.matmul.allow_tf32,
            "default_expression_scale": 0.7,
            "default_still_mode": True,
            "default_preprocess": "crop",
            "batch_size": 3
        }
    }

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ SadTalker FastAPI ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­...")
    uvicorn.run(app, host="0.0.0.0", port=8000)