#!/usr/bin/env python3
"""
Gradio GPT-SoVITS éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚° Web UI
FastAPIç‰ˆã®å…¨æ©Ÿèƒ½ã‚’Gradio 3ç³»ã«ç§»è¡Œ
åˆæœŸåŒ–1å›ã®ã¿ã€å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ2-3ç§’ã§é«˜é€Ÿå¿œç­”
"""

import os
import sys
import time
import logging
import asyncio
import threading
from pathlib import Path
from typing import Optional, Tuple, Any
import uuid
import tempfile
import urllib.request
import numpy as np
import soundfile as sf

# Gradio 3ç³»
import gradio as gr

# GPT-SoVITS
os.chdir('/app')
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/GPT_SoVITS')

import torch

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
MODELS_LOADED = False
CUSTOM_SOVITS_PATH = None
PRELOADED_LANGDETECT = None
CACHE_DIR = "/app/cache"

# GPUæ’ä»–åˆ¶å¾¡ç”¨
gpu_lock = threading.Lock()

def setup_torch_optimizations():
    """Torchæœ€é©åŒ–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.cuda.empty_cache()
        logger.info("ğŸš€ RTX 3050 TensorCoreæœ€é©åŒ–æœ‰åŠ¹")
    
    torch.set_float32_matmul_precision('medium')
    torch.set_num_threads(8)
    logger.info("âœ… PyTorchæœ€é©åŒ–å®Œäº†")

def comprehensive_monkey_patch():
    """ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒé©ç”¨"""
    from GPT_SoVITS import inference_webui
    
    original_load_sovits = inference_webui.load_sovits_new
    original_change_sovits = inference_webui.change_sovits_weights
    
    def custom_load_sovits_new(sovits_path):
        global CUSTOM_SOVITS_PATH
        if CUSTOM_SOVITS_PATH and os.path.exists(CUSTOM_SOVITS_PATH):
            actual_path = CUSTOM_SOVITS_PATH
        else:
            actual_path = sovits_path
        
        if actual_path.endswith('.ckpt'):
            checkpoint = torch.load(actual_path, map_location='cpu')
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            dict_s2 = {
                'weight': state_dict,
                'config': {
                    'model': {
                        'version': 'v2',
                        'semantic_frame_rate': '25hz',
                        'inter_channels': 192,
                        'hidden_channels': 192,
                        'filter_channels': 768,
                        'n_heads': 2,
                        'n_layers': 6,
                        'kernel_size': 3,
                        'p_dropout': 0.1,
                        'ssl_dim': 768,
                        'n_speakers': 300
                    },
                    'data': {
                        'sampling_rate': 32000,
                        'filter_length': 2048,
                        'hop_length': 640,
                        'win_length': 2048,
                        'n_speakers': 300,
                        'cleaned_text': True,
                        'add_blank': True,
                        'n_symbols': 178
                    }
                }
            }
            return dict_s2
        else:
            return original_load_sovits(actual_path)
    
    def custom_change_sovits_weights(sovits_path, prompt_language=None, text_language=None):
        global CUSTOM_SOVITS_PATH
        if CUSTOM_SOVITS_PATH:
            sovits_path = "/app/GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth"
        return original_change_sovits(sovits_path, prompt_language, text_language)
    
    inference_webui.load_sovits_new = custom_load_sovits_new
    inference_webui.change_sovits_weights = custom_change_sovits_weights
    logger.info("ğŸ”§ ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒé©ç”¨å®Œäº†")

def apply_torch_compile_optimization():
    """Torch.compileæœ€é©åŒ–é©ç”¨"""
    try:
        if not hasattr(torch, 'compile'):
            logger.warning("âš ï¸ PyTorch 2.0+ãŒå¿…è¦ï¼ˆTorch.compileéå¯¾å¿œï¼‰")
            return
        
        from GPT_SoVITS import inference_webui
        
        # SoVITSãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
        if hasattr(inference_webui, 'vq_model') and inference_webui.vq_model is not None:
            logger.info("ğŸ”¥ SoVITSãƒ¢ãƒ‡ãƒ«compileæœ€é©åŒ–ä¸­...")
            inference_webui.vq_model = torch.compile(
                inference_webui.vq_model,
                mode="max-autotune",
                dynamic=True,
                backend="inductor"
            )
        
        # GPTãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
        if hasattr(inference_webui, 't2s_model') and inference_webui.t2s_model is not None:
            logger.info("ğŸ”¥ GPTãƒ¢ãƒ‡ãƒ«compileæœ€é©åŒ–ä¸­...")
            inference_webui.t2s_model = torch.compile(
                inference_webui.t2s_model,
                mode="max-autotune",
                dynamic=True,
                backend="inductor"
            )
        
        # HuBERTãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
        if hasattr(inference_webui, 'hubert_model') and inference_webui.hubert_model is not None:
            logger.info("ğŸ”¥ HuBERTãƒ¢ãƒ‡ãƒ«compileæœ€é©åŒ–ä¸­...")
            inference_webui.hubert_model = torch.compile(
                inference_webui.hubert_model,
                mode="reduce-overhead",
                dynamic=True,
                backend="inductor"
            )
        
        logger.info("ğŸš€ Torch.compileæœ€é©åŒ–å®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ Torch.compileæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

def initialize_models():
    """ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚1å›ã®ã¿ï¼‰"""
    global MODELS_LOADED, CUSTOM_SOVITS_PATH
    
    if MODELS_LOADED:
        return
    
    logger.info("ğŸš€ === ã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–é–‹å§‹ ===")
    init_start = time.time()
    
    try:
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹è¨­å®š
        CUSTOM_SOVITS_PATH = "/app/GPT_SoVITS/pretrained_models/gpt-sovits-ja-h/hscene-e17.ckpt"
        
        # æœ€é©åŒ–è¨­å®š
        setup_torch_optimizations()
        comprehensive_monkey_patch()
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        from GPT_SoVITS.inference_webui import change_sovits_weights
        default_path = "/app/GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth"
        change_sovits_weights(default_path)
        
        # Warm-upæ¨è«–
        logger.info("ğŸ”¥ Warm-upæ¨è«–å®Ÿè¡Œä¸­...")
        from GPT_SoVITS.inference_webui import get_tts_wav
        
        dummy_gen = get_tts_wav(
            ref_wav_path="/app/input/reference_5sec.wav",
            prompt_text="ã“ã‚“ã«ã¡ã¯",
            prompt_language="Japanese",
            text="ãƒ†ã‚¹ãƒˆ",
            text_language="Japanese",
            how_to_cut="ä¸åˆ‡",
            top_k=5,
            top_p=1.0,
            temperature=1.0,
            ref_free=True
        )
        
        # ä¸€ã¤ã ã‘ç”Ÿæˆã—ã¦Warm-upå®Œäº†
        for i, item in enumerate(dummy_gen):
            if i == 0:
                break
        
        # Torch.compileæœ€é©åŒ–
        apply_torch_compile_optimization()
        
        # CUDAã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
        if torch.cuda.is_available():
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
        
        MODELS_LOADED = True
        init_time = time.time() - init_start
        
        logger.info(f"âœ… === ã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–å®Œäº†: {init_time:.2f}ç§’ ===")
        logger.info("ğŸ¯ ä»¥é™ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯2-3ç§’ã§å¿œç­”äºˆå®š")
        
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        raise

def preload_all_dependencies():
    """å…¨ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    global PRELOADED_LANGDETECT
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(CACHE_DIR, exist_ok=True)
    
    # 1. è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    logger.info("ğŸ”¥ è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    try:
        langdetect_model_path = f"{CACHE_DIR}/lid.176.bin"
        if not os.path.exists(langdetect_model_path):
            logger.info("ğŸ“¥ è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            urllib.request.urlretrieve(
                "https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin",
                langdetect_model_path
            )
            logger.info("âœ… è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        else:
            logger.info("âœ… è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨")
            
        # ç’°å¢ƒå¤‰æ•°ã§ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š
        os.environ["FASTTEXT_MODEL_PATH"] = langdetect_model_path
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«ãƒ­ãƒ¼ãƒ‰
        import fast_langdetect
        from fast_langdetect import detect
        
        # å¼·åˆ¶çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        detect("Hello", low_memory=False)
        detect("ã“ã‚“ã«ã¡ã¯", low_memory=False)
        PRELOADED_LANGDETECT = True
        
        logger.info("âœ… è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†")
    except Exception as e:
        logger.warning(f"âš ï¸ è¨€èªæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
    
    # 2. Open JTalkè¾æ›¸ã®äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    logger.info("ğŸ”¥ Open JTalkè¾æ›¸äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    try:
        jtalk_dict_path = f"{CACHE_DIR}/open_jtalk_dic_utf_8-1.11.tar.gz"
        if not os.path.exists(jtalk_dict_path):
            logger.info("ğŸ“¥ Open JTalkè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            urllib.request.urlretrieve(
                "https://github.com/r9y9/open_jtalk/releases/download/v1.11.1/open_jtalk_dic_utf_8-1.11.tar.gz",
                jtalk_dict_path
            )
            logger.info("âœ… Open JTalkè¾æ›¸ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        else:
            logger.info("âœ… Open JTalkè¾æ›¸æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨")
            
        # ç’°å¢ƒå¤‰æ•°ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ã‚¹ã‚’è¨­å®š
        os.environ["OPEN_JTALK_DICT_PATH"] = jtalk_dict_path
        
        logger.info("âœ… Open JTalkè¾æ›¸ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†")
    except Exception as e:
        logger.warning(f"âš ï¸ Open JTalkè¾æ›¸ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
    
    # 3. ãã®ä»–ã®ä¾å­˜é–¢ä¿‚ã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
    logger.info("ğŸ”¥ ãã®ä»–ä¾å­˜é–¢ä¿‚ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ä¸­...")
    try:
        # jiebaè¾æ›¸ã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
        import jieba
        jieba.initialize()
        
        # TorchAudioå‘¨ã‚Šã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
        import torchaudio
        torchaudio.set_audio_backend("sox_io")
        
        logger.info("âœ… ãã®ä»–ä¾å­˜é–¢ä¿‚ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†")
    except Exception as e:
        logger.warning(f"âš ï¸ ãã®ä»–ä¾å­˜é–¢ä¿‚ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

def ensure_text_length(text: str, min_length: int = 20) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆãŒæŒ‡å®šæ–‡å­—æ•°æœªæº€ã®å ´åˆã€è‡ªç„¶ã«å»¶é•·ã™ã‚‹"""
    if len(text) >= min_length:
        return text
    
    # çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã®å»¶é•·ãƒ‘ã‚¿ãƒ¼ãƒ³
    extensions = [
        "ã¨ã¦ã‚‚è‰¯ã„éŸ³å£°ã§ã™ã­ã€‚",
        "ç´ æ™´ã‚‰ã—ã„çµæœã ã¨æ€ã„ã¾ã™ã€‚",
        "éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã®æŠ€è¡“ã¯å‡„ã„ã§ã™ã€‚",
        "ã“ã‚Œã¯é«˜å“è³ªãªéŸ³å£°ç”Ÿæˆã§ã™ã€‚",
        "æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚"
    ]
    
    # æ–‡æœ«ã«å¥ç‚¹ãŒãªã„å ´åˆã¯è¿½åŠ 
    if not text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')):
        text += "ã€‚"
    
    # 20æ–‡å­—ä»¥ä¸Šã«ãªã‚‹ã¾ã§å»¶é•·
    while len(text) < min_length:
        # ä¸€ç•ªé©å½“ãªå»¶é•·ã‚’é¸æŠï¼ˆå¥ç‚¹ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        extension = extensions[len(text) % len(extensions)]
        text += extension
    
    logger.info(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆè‡ªå‹•å»¶é•·: {len(text)}æ–‡å­— â†’ {text}")
    return text

def generate_voice_with_uploaded_ref(ref_audio_path: str, ref_text: str, target_text: str, 
                                   temperature: float = 1.0) -> Tuple[str, str]:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‚ç…§éŸ³å£°ã§éŸ³å£°ç”Ÿæˆï¼ˆGradioç”¨ï¼‰"""
    
    if not MODELS_LOADED:
        return None, "âŒ ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    # GPUæ’ä»–åˆ¶å¾¡
    with gpu_lock:
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’20æ–‡å­—ä»¥ä¸Šã«è‡ªå‹•å»¶é•·
            target_text = ensure_text_length(target_text, 20)
            
            generation_start = time.time()
            
            from GPT_SoVITS.inference_webui import get_tts_wav
            
            # éŸ³å£°ç”Ÿæˆå®Ÿè¡Œ
            result_generator = get_tts_wav(
                ref_wav_path=ref_audio_path,
                prompt_text=ref_text,
                prompt_language="Japanese",
                text=target_text,
                text_language="Japanese",
                how_to_cut="ä¸åˆ‡",
                top_k=5,
                top_p=1.0,
                temperature=temperature,
                ref_free=True
            )
            
            # çµæœå‡¦ç†
            audio_segments = []
            for i, item in enumerate(result_generator):
                if isinstance(item, tuple) and len(item) == 2:
                    sample_rate, audio_data = item
                    audio_segments.append(audio_data)
            
            if not audio_segments:
                return None, "âŒ éŸ³å£°ç”Ÿæˆå¤±æ•—"
            
            # éŸ³å£°é€£çµ
            if len(audio_segments) > 1:
                final_audio = np.concatenate(audio_segments)
            else:
                final_audio = audio_segments[0]
            
            generation_time = time.time() - generation_start
            audio_duration = len(final_audio) / 32000
            realtime_factor = audio_duration / generation_time
            
            # éŸ³å£°å“è³ªçµ±è¨ˆ
            audio_rms = float(np.sqrt(np.mean(final_audio ** 2)))
            non_silence_ratio = float(np.sum(np.abs(final_audio) > np.max(np.abs(final_audio)) * 0.01) / len(final_audio))
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_target = target_text.replace(' ', '_').replace('ï¼', '').replace('ï¼Ÿ', '')[:30]
            output_path = f"/app/output/gradio_{timestamp}_{safe_target}.wav"
            
            sf.write(output_path, final_audio, 32000)
            
            # çµ±è¨ˆæƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            stats_message = f"""
            âœ… éŸ³å£°ç”Ÿæˆå®Œäº†ï¼
            
            ğŸ“Š **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ**
            - ç”Ÿæˆæ™‚é–“: {generation_time:.2f}ç§’
            - éŸ³å£°é•·: {audio_duration:.2f}ç§’
            - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿‚æ•°: {realtime_factor:.2f}x
            - éŸ³å£°å“è³ª (RMS): {audio_rms:.4f}
            - éç„¡éŸ³ç‡: {non_silence_ratio:.2f}
            
            ğŸ¯ **ç”Ÿæˆè¨­å®š**
            - å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ: {ref_text}
            - ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ: {target_text}
            - æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {temperature}
            
            ğŸ“ **ä¿å­˜å ´æ‰€**: {output_path}
            """
            
            logger.info(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {generation_time:.2f}ç§’, ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿‚æ•°: {realtime_factor:.2f}x")
            
            return output_path, stats_message
            
        except Exception as e:
            logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None, f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

def generate_voice_with_default_ref(ref_text: str, target_text: str, 
                                  temperature: float = 1.0) -> Tuple[str, str]:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§éŸ³å£°ã§éŸ³å£°ç”Ÿæˆï¼ˆGradioç”¨ï¼‰"""
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§éŸ³å£°ã‚’ä½¿ç”¨
    default_ref_path = "/app/input/reference_5sec.wav"
    
    if not os.path.exists(default_ref_path):
        return None, f"âŒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {default_ref_path}"
    
    return generate_voice_with_uploaded_ref(default_ref_path, ref_text, target_text, temperature)

def create_gradio_interface():
    """Gradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ"""
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    custom_css = """
    #main_title {
        text-align: center;
        color: #2E8B57;
        font-weight: bold;
        margin-bottom: 20px;
    }
    #stats_output {
        font-family: monospace;
        font-size: 12px;
        white-space: pre-wrap;
    }
    """
    
    # 2ã¤ã®ã‚¿ãƒ–ã‚’æŒã¤ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    with gr.Blocks(css=custom_css, title="GPT-SoVITS éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°") as demo:
        
        gr.Markdown("# ğŸ¤ GPT-SoVITS éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ", elem_id="main_title")
        gr.Markdown("### æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ | é«˜é€Ÿç”Ÿæˆ | æ„Ÿæƒ…è±Šã‹ãªéŸ³å£°")
        
        with gr.Tabs():
            # ã‚¿ãƒ–1: éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç‰ˆ
            with gr.TabItem("ğŸ“ éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"):
                gr.Markdown("### ğŸµ ã‚ãªãŸã®éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãã®å£°è³ªã§ä»»æ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã¾ã™")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        ref_audio_input = gr.Audio(
                            label="ğŸ“¤ å‚ç…§éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                            type="filepath",
                            value=None
                        )
                        ref_text_input = gr.Textbox(
                            label="ğŸ“ å‚ç…§éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆ",
                            placeholder="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸéŸ³å£°ã§è©±ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                            lines=2,
                            value="ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚"
                        )
                        target_text_input = gr.Textbox(
                            label="ğŸ¯ ç”Ÿæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆ",
                            placeholder="ã“ã®å£°è³ªã§èª­ã¿ä¸Šã’ãŸã„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                            lines=3,
                            value="éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã¯ç´ æ™´ã‚‰ã—ã„é€²æ­©ã‚’é‚ã’ã¦ã„ã¾ã™ã€‚"
                        )
                        temperature_input = gr.Slider(
                            label="ğŸŒ¡ï¸ æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (å‰µé€ æ€§)",
                            minimum=0.5,
                            maximum=2.0,
                            step=0.1,
                            value=1.0
                        )
                        generate_btn = gr.Button("ğŸš€ éŸ³å£°ç”Ÿæˆ", variant="primary")
                    
                    with gr.Column(scale=1):
                        output_audio = gr.Audio(
                            label="ğŸµ ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°",
                            type="filepath"
                        )
                        output_stats = gr.Textbox(
                            label="ğŸ“Š ç”Ÿæˆçµ±è¨ˆ",
                            lines=15,
                            elem_id="stats_output"
                        )
                
                generate_btn.click(
                    fn=generate_voice_with_uploaded_ref,
                    inputs=[ref_audio_input, ref_text_input, target_text_input, temperature_input],
                    outputs=[output_audio, output_stats]
                )
            
            # ã‚¿ãƒ–2: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§éŸ³å£°ç‰ˆ
            with gr.TabItem("âš¡ ã‚¯ã‚¤ãƒƒã‚¯ç”Ÿæˆ"):
                gr.Markdown("### ğŸ¯ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§éŸ³å£°ã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿç”Ÿæˆ")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        quick_ref_text = gr.Textbox(
                            label="ğŸ“ å‚ç…§éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆ",
                            placeholder="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§éŸ³å£°ã®å†…å®¹",
                            lines=1,
                            value="ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"
                        )
                        quick_target_text = gr.Textbox(
                            label="ğŸ¯ ç”Ÿæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆ",
                            placeholder="ã“ã®å£°è³ªã§èª­ã¿ä¸Šã’ãŸã„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                            lines=3,
                            value="ä»Šæ—¥ã¯ç¾ã—ã„å¤©æ°—ã§ã™ã­ã€‚æ•£æ­©ã«å‡ºã‹ã‘ã¾ã—ã‚‡ã†ã€‚"
                        )
                        quick_temperature = gr.Slider(
                            label="ğŸŒ¡ï¸ æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (å‰µé€ æ€§)",
                            minimum=0.5,
                            maximum=2.0,
                            step=0.1,
                            value=1.0
                        )
                        quick_generate_btn = gr.Button("âš¡ é«˜é€Ÿç”Ÿæˆ", variant="primary")
                    
                    with gr.Column(scale=1):
                        quick_output_audio = gr.Audio(
                            label="ğŸµ ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°",
                            type="filepath"
                        )
                        quick_output_stats = gr.Textbox(
                            label="ğŸ“Š ç”Ÿæˆçµ±è¨ˆ",
                            lines=15,
                            elem_id="stats_output"
                        )
                
                quick_generate_btn.click(
                    fn=generate_voice_with_default_ref,
                    inputs=[quick_ref_text, quick_target_text, quick_temperature],
                    outputs=[quick_output_audio, quick_output_stats]
                )
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        gr.Markdown("""
        ---
        ### ğŸ”§ **ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±**
        - **ãƒ¢ãƒ‡ãƒ«**: AkitoP/GPT-SoVITS-JA-H (650æ™‚é–“å­¦ç¿’æ¸ˆã¿)
        - **æœ€é©åŒ–**: PyTorch 2.0 + Torch.compile + TensorCore
        - **æ¨å®šå¿œç­”æ™‚é–“**: 2-7ç§’ (åˆå›ã¯äº‹å‰ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿)
        - **å¯¾å¿œè¨€èª**: æ—¥æœ¬èªç‰¹åŒ– (è‹±èªæŠ€è¡“ç”¨èªå¯¾å¿œ)
        """)
    
    return demo

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        # åˆæœŸåŒ–
        logger.info("ğŸš€ Gradio GPT-SoVITS ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­...")
        
        # äº‹å‰ãƒ­ãƒ¼ãƒ‰
        preload_all_dependencies()
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        initialize_models()
        
        # Gradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ
        demo = create_gradio_interface()
        
        # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        logger.info("ğŸŒ Gradio ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            debug=False,
            inbrowser=False,
            show_error=True,
            quiet=False
        )
        
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == "__main__":
    main()