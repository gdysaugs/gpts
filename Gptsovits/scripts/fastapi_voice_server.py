#!/usr/bin/env python3
"""
FastAPI GPT-SoVITS å¸¸é§éŸ³å£°ç”Ÿæˆã‚µãƒ¼ãƒãƒ¼
åˆæœŸåŒ–1å›ã®ã¿ã€å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ2-3ç§’ã§é«˜é€Ÿå¿œç­”
"""

import os
import sys
import time
import logging
import asyncio
from pathlib import Path
from typing import Optional
import uuid
import tempfile
import base64

# FastAPI
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# GPT-SoVITS
os.chdir('/app')
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/GPT_SoVITS')

import torch
import soundfile as sf
import numpy as np

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
app = FastAPI(title="GPT-SoVITS Voice Cloning API", version="1.0.0")
MODELS_LOADED = False
CUSTOM_SOVITS_PATH = None

# CORSè¨­å®šï¼ˆé–‹ç™ºç”¨ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªã§ã¯é©åˆ‡ã«è¨­å®š
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
class VoiceCloneRequest(BaseModel):
    ref_text: str
    target_text: str
    ref_audio_base64: Optional[str] = None  # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰éŸ³å£°
    temperature: float = 1.0
    top_k: int = 5
    top_p: float = 1.0

class VoiceCloneResponse(BaseModel):
    success: bool
    message: str
    audio_base64: Optional[str] = None
    generation_time: float
    audio_duration: float
    realtime_factor: float

def setup_torch_optimizations():
    """Torchæœ€é©åŒ–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.cuda.empty_cache()
        logger.info("ğŸš€ RTX 3050 TensorCoreæœ€é©åŒ–æœ‰åŠ¹")
    
    torch.set_float32_matmul_precision('medium')
    torch.set_num_threads(8)
    logger.info("âœ… PyTorchæœ€é©åŒ–å®Œäº†")

def comprehensive_monkey_patch():
    """ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒé©ç”¨"""
    from GPT_SoVITS import inference_webui
    
    original_load_sovits = inference_webui.load_sovits_new
    original_change_sovits = inference_webui.change_sovits_weights
    
    def custom_load_sovits_new(sovits_path):
        global CUSTOM_SOVITS_PATH
        if CUSTOM_SOVITS_PATH and os.path.exists(CUSTOM_SOVITS_PATH):
            actual_path = CUSTOM_SOVITS_PATH
        else:
            actual_path = sovits_path
        
        if actual_path.endswith('.ckpt'):
            checkpoint = torch.load(actual_path, map_location='cpu')
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            dict_s2 = {
                'weight': state_dict,
                'config': {
                    'model': {
                        'version': 'v2',
                        'semantic_frame_rate': '25hz',
                        'inter_channels': 192,
                        'hidden_channels': 192,
                        'filter_channels': 768,
                        'n_heads': 2,
                        'n_layers': 6,
                        'kernel_size': 3,
                        'p_dropout': 0.1,
                        'ssl_dim': 768,
                        'n_speakers': 300
                    },
                    'data': {
                        'sampling_rate': 32000,
                        'filter_length': 2048,
                        'hop_length': 640,
                        'win_length': 2048,
                        'n_speakers': 300,
                        'cleaned_text': True,
                        'add_blank': True,
                        'n_symbols': 178
                    }
                }
            }
            return dict_s2
        else:
            return original_load_sovits(actual_path)
    
    def custom_change_sovits_weights(sovits_path, prompt_language=None, text_language=None):
        global CUSTOM_SOVITS_PATH
        if CUSTOM_SOVITS_PATH:
            sovits_path = "/app/GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth"
        return original_change_sovits(sovits_path, prompt_language, text_language)
    
    inference_webui.load_sovits_new = custom_load_sovits_new
    inference_webui.change_sovits_weights = custom_change_sovits_weights
    logger.info("ğŸ”§ ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒé©ç”¨å®Œäº†")

def apply_torch_compile_optimization():
    """Torch.compileæœ€é©åŒ–é©ç”¨"""
    try:
        if not hasattr(torch, 'compile'):
            logger.warning("âš ï¸ PyTorch 2.0+ãŒå¿…è¦ï¼ˆTorch.compileéå¯¾å¿œï¼‰")
            return
        
        from GPT_SoVITS import inference_webui
        
        # SoVITSãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
        if hasattr(inference_webui, 'vq_model') and inference_webui.vq_model is not None:
            logger.info("ğŸ”¥ SoVITSãƒ¢ãƒ‡ãƒ«compileæœ€é©åŒ–ä¸­...")
            inference_webui.vq_model = torch.compile(
                inference_webui.vq_model,
                mode="max-autotune",
                dynamic=True,
                backend="inductor"
            )
        
        # GPTãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
        if hasattr(inference_webui, 't2s_model') and inference_webui.t2s_model is not None:
            logger.info("ğŸ”¥ GPTãƒ¢ãƒ‡ãƒ«compileæœ€é©åŒ–ä¸­...")
            inference_webui.t2s_model = torch.compile(
                inference_webui.t2s_model,
                mode="max-autotune",
                dynamic=True,
                backend="inductor"
            )
        
        # HuBERTãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
        if hasattr(inference_webui, 'hubert_model') and inference_webui.hubert_model is not None:
            logger.info("ğŸ”¥ HuBERTãƒ¢ãƒ‡ãƒ«compileæœ€é©åŒ–ä¸­...")
            inference_webui.hubert_model = torch.compile(
                inference_webui.hubert_model,
                mode="reduce-overhead",
                dynamic=True,
                backend="inductor"
            )
        
        logger.info("ğŸš€ Torch.compileæœ€é©åŒ–å®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ Torch.compileæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

async def initialize_models():
    """ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚1å›ã®ã¿ï¼‰"""
    global MODELS_LOADED, CUSTOM_SOVITS_PATH
    
    if MODELS_LOADED:
        return
    
    logger.info("ğŸš€ === ã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–é–‹å§‹ ===")
    init_start = time.time()
    
    try:
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹è¨­å®š
        CUSTOM_SOVITS_PATH = "/app/GPT_SoVITS/pretrained_models/gpt-sovits-ja-h/hscene-e17.ckpt"
        
        # æœ€é©åŒ–è¨­å®š
        setup_torch_optimizations()
        comprehensive_monkey_patch()
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        from GPT_SoVITS.inference_webui import change_sovits_weights
        default_path = "/app/GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth"
        change_sovits_weights(default_path)
        
        # Warm-upæ¨è«–
        logger.info("ğŸ”¥ Warm-upæ¨è«–å®Ÿè¡Œä¸­...")
        from GPT_SoVITS.inference_webui import get_tts_wav
        
        dummy_gen = get_tts_wav(
            ref_wav_path="/app/input/reference_5sec.wav",
            prompt_text="ã“ã‚“ã«ã¡ã¯",
            prompt_language="Japanese",
            text="ãƒ†ã‚¹ãƒˆ",
            text_language="Japanese",
            how_to_cut="ä¸åˆ‡",
            top_k=5,
            top_p=1.0,
            temperature=1.0,
            ref_free=True
        )
        
        # ä¸€ã¤ã ã‘ç”Ÿæˆã—ã¦Warm-upå®Œäº†
        for i, item in enumerate(dummy_gen):
            if i == 0:
                break
        
        # Torch.compileæœ€é©åŒ–
        apply_torch_compile_optimization()
        
        # CUDAã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
        if torch.cuda.is_available():
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
        
        MODELS_LOADED = True
        init_time = time.time() - init_start
        
        logger.info(f"âœ… === ã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–å®Œäº†: {init_time:.2f}ç§’ ===")
        logger.info("ğŸ¯ ä»¥é™ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯2-3ç§’ã§å¿œç­”äºˆå®š")
        
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        raise

def ensure_text_length(text: str, min_length: int = 20) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆãŒæŒ‡å®šæ–‡å­—æ•°æœªæº€ã®å ´åˆã€è‡ªç„¶ã«å»¶é•·ã™ã‚‹"""
    if len(text) >= min_length:
        return text
    
    # çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã®å»¶é•·ãƒ‘ã‚¿ãƒ¼ãƒ³
    extensions = [
        "ã¨ã¦ã‚‚è‰¯ã„éŸ³å£°ã§ã™ã­ã€‚",
        "ç´ æ™´ã‚‰ã—ã„çµæœã ã¨æ€ã„ã¾ã™ã€‚",
        "éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã®æŠ€è¡“ã¯å‡„ã„ã§ã™ã€‚",
        "ã“ã‚Œã¯é«˜å“è³ªãªéŸ³å£°ç”Ÿæˆã§ã™ã€‚",
        "æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚"
    ]
    
    # æ–‡æœ«ã«å¥ç‚¹ãŒãªã„å ´åˆã¯è¿½åŠ 
    if not text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')):
        text += "ã€‚"
    
    # 20æ–‡å­—ä»¥ä¸Šã«ãªã‚‹ã¾ã§å»¶é•·
    while len(text) < min_length:
        # ä¸€ç•ªé©å½“ãªå»¶é•·ã‚’é¸æŠï¼ˆå¥ç‚¹ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        extension = extensions[len(text) % len(extensions)]
        text += extension
    
    logger.info(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆè‡ªå‹•å»¶é•·: {len(text)}æ–‡å­— â†’ {text}")
    return text

async def generate_voice_fast(ref_audio_path: str, ref_text: str, target_text: str, 
                             temperature: float = 1.0, top_k: int = 5, top_p: float = 1.0) -> dict:
    """é«˜é€ŸéŸ³å£°ç”Ÿæˆï¼ˆåˆæœŸåŒ–æ¸ˆã¿å‰æï¼‰"""
    
    if not MODELS_LOADED:
        raise HTTPException(status_code=500, detail="ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’20æ–‡å­—ä»¥ä¸Šã«è‡ªå‹•å»¶é•·
    target_text = ensure_text_length(target_text, 20)
    
    generation_start = time.time()
    
    try:
        from GPT_SoVITS.inference_webui import get_tts_wav
        
        # éŸ³å£°ç”Ÿæˆå®Ÿè¡Œ
        result_generator = get_tts_wav(
            ref_wav_path=ref_audio_path,
            prompt_text=ref_text,
            prompt_language="Japanese",
            text=target_text,
            text_language="Japanese",
            how_to_cut="ä¸åˆ‡",
            top_k=top_k,
            top_p=top_p,
            temperature=temperature,
            ref_free=True
        )
        
        # çµæœå‡¦ç†
        audio_segments = []
        for i, item in enumerate(result_generator):
            if isinstance(item, tuple) and len(item) == 2:
                sample_rate, audio_data = item
                audio_segments.append(audio_data)
        
        if not audio_segments:
            raise Exception("éŸ³å£°ç”Ÿæˆå¤±æ•—")
        
        # éŸ³å£°é€£çµ
        if len(audio_segments) > 1:
            final_audio = np.concatenate(audio_segments)
        else:
            final_audio = audio_segments[0]
        
        generation_time = time.time() - generation_start
        audio_duration = len(final_audio) / 32000
        realtime_factor = audio_duration / generation_time
        
        # éŸ³å£°å“è³ªçµ±è¨ˆ
        audio_rms = float(np.sqrt(np.mean(final_audio ** 2)))
        non_silence_ratio = float(np.sum(np.abs(final_audio) > np.max(np.abs(final_audio)) * 0.01) / len(final_audio))
        
        return {
            'audio_data': final_audio,
            'sample_rate': 32000,
            'generation_time': generation_time,
            'audio_duration': audio_duration,
            'realtime_factor': realtime_factor,
            'audio_rms': audio_rms,
            'non_silence_ratio': non_silence_ratio
        }
        
    except Exception as e:
        logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"éŸ³å£°ç”Ÿæˆå¤±æ•—: {str(e)}")

# === FastAPI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.on_event("startup")
async def startup_event():
    """ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚åˆæœŸåŒ–"""
    await initialize_models()

@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "message": "GPT-SoVITS Voice Cloning API",
        "models_loaded": MODELS_LOADED,
        "gpu_available": torch.cuda.is_available(),
        "gpu_name": torch.cuda.get_device_name() if torch.cuda.is_available() else None
    }

@app.post("/clone-voice", response_model=VoiceCloneResponse)
async def clone_voice_endpoint(
    ref_text: str = Form(...),
    target_text: str = Form(...),
    temperature: float = Form(1.0),
    top_k: int = Form(5),
    top_p: float = Form(1.0),
    ref_audio: UploadFile = File(...)
):
    """éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°API"""
    
    try:
        # å‚ç…§éŸ³å£°ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        temp_audio_path = f"/tmp/{uuid.uuid4()}.wav"
        
        with open(temp_audio_path, "wb") as f:
            f.write(await ref_audio.read())
        
        # éŸ³å£°ç”Ÿæˆ
        result = await generate_voice_fast(
            ref_audio_path=temp_audio_path,
            ref_text=ref_text,
            target_text=target_text,
            temperature=temperature,
            top_k=top_k,
            top_p=top_p
        )
        
        # ç”ŸæˆéŸ³å£°ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_path = f"/tmp/{uuid.uuid4()}_output.wav"
        sf.write(output_path, result['audio_data'], result['sample_rate'])
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with open(output_path, "rb") as f:
            audio_base64 = base64.b64encode(f.read()).decode('utf-8')
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        os.remove(temp_audio_path)
        os.remove(output_path)
        
        return VoiceCloneResponse(
            success=True,
            message="éŸ³å£°ç”ŸæˆæˆåŠŸ",
            audio_base64=audio_base64,
            generation_time=result['generation_time'],
            audio_duration=result['audio_duration'],
            realtime_factor=result['realtime_factor']
        )
        
    except Exception as e:
        logger.error(f"âŒ API ã‚¨ãƒ©ãƒ¼: {e}")
        return VoiceCloneResponse(
            success=False,
            message=f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
            generation_time=0,
            audio_duration=0,
            realtime_factor=0
        )

@app.get("/clone-voice-simple")
async def clone_voice_simple(
    ref_text: str,
    target_text: str,
    temperature: float = 1.0,
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå›ºå®šå‚ç…§éŸ³å£°ï¼‰"""
    
    try:
        result = await generate_voice_fast(
            ref_audio_path="/app/input/reference_5sec.wav",
            ref_text=ref_text,
            target_text=target_text,
            temperature=temperature
        )
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        temp_output_path = f"/tmp/{uuid.uuid4()}_output.wav"
        sf.write(temp_output_path, result['audio_data'], result['sample_rate'])
        
        # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚æ°¸ç¶šä¿å­˜
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_target = target_text.replace(' ', '_').replace('ï¼', '').replace('ï¼Ÿ', '')[:30]
        permanent_path = f"/app/output/fastapi_{timestamp}_{safe_target}.wav"
        sf.write(permanent_path, result['audio_data'], result['sample_rate'])
        
        # é€ä¿¡å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã«è¿½åŠ 
        background_tasks.add_task(os.remove, temp_output_path)
        
        return FileResponse(
            temp_output_path,
            media_type="audio/wav",
            filename="generated_voice.wav"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    uvicorn.run(
        "fastapi_voice_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )